{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' !git clone https://github.com/Han-JaeHoon/QRNN-for-Sequential-Classification.git\n",
        "!pip install pykan\n",
        "!pip install pennylane\n",
        "%cd QRNN-for-Sequential-Classification '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3yUJB9sbKg0m"
      },
      "outputs": [],
      "source": [
        "# Quantum\n",
        "import pennylane as qml\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# Numpy, Pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Layer\n",
        "from kan import KAN\n",
        "from RNN_block import RNN_block\n",
        "# Data processing\n",
        "from fucntions import data_seq, train_seq\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Quantum User-Def Classes\n",
        "from utils import my_utils\n",
        "from NQE_class import NQE\n",
        "from NQE_train_class import NQE_Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data uploading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "locations = ['Adelaide', 'Albany', 'Albury', 'AliceSprings', 'BadgerysCreek', 'Ballarat', 'Bendigo', 'Brisbane', 'Cairns', 'Canberra', 'Cobar', 'CoffsHarbour', 'Dartmoor', 'Darwin', 'GoldCoast', 'Hobart', 'Katherine', 'Launceston', 'Melbourne', 'MelbourneAirport', 'Mildura', 'Moree', 'MountGambier', 'MountGinini', 'Newcastle', 'Nhil', 'NorahHead', 'NorfolkIsland', 'Nuriootpa', 'PearceRAAF', 'Penrith', 'Perth', 'PerthAirport', 'Portland', 'Richmond', 'Sale', 'SalmonGums', 'Sydney', 'SydneyAirport', 'Townsville', 'Tuggeranong', 'Uluru', 'WaggaWagga', 'Walpole', 'Watsonia', 'Williamtown', 'Witchcliffe', 'Wollongong', 'Woomera']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "nqe_train = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adelaide\n",
            "Albany\n",
            "Albury\n",
            "AliceSprings\n",
            "BadgerysCreek\n",
            "Ballarat\n",
            "Bendigo\n",
            "Brisbane\n",
            "Cairns\n",
            "Canberra\n",
            "Cobar\n",
            "CoffsHarbour\n",
            "Dartmoor\n",
            "Darwin\n",
            "GoldCoast\n",
            "Hobart\n",
            "Katherine\n",
            "Launceston\n",
            "Melbourne\n",
            "MelbourneAirport\n",
            "Mildura\n",
            "Moree\n",
            "MountGambier\n",
            "MountGinini\n",
            "Newcastle\n",
            "Nhil\n",
            "NorahHead\n",
            "NorfolkIsland\n",
            "Nuriootpa\n",
            "PearceRAAF\n",
            "Penrith\n",
            "Perth\n",
            "PerthAirport\n",
            "Portland\n",
            "Richmond\n",
            "Sale\n",
            "SalmonGums\n",
            "Sydney\n",
            "SydneyAirport\n",
            "Townsville\n",
            "Tuggeranong\n",
            "Uluru\n",
            "WaggaWagga\n",
            "Walpole\n",
            "Watsonia\n",
            "Williamtown\n",
            "Witchcliffe\n",
            "Wollongong\n",
            "Woomera\n"
          ]
        }
      ],
      "source": [
        "train_data_dict = dict()\n",
        "label_data_dict = dict()\n",
        "for e in locations:\n",
        "    print(e)\n",
        "    train_df = pd.read_csv(\"./data/train_data_\" + e + \".csv\")\n",
        "    label_df = pd.read_csv(\"./data/label_data_\" + e + \".csv\")\n",
        "    train_data_dict[e] = torch.tensor(train_df[[\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"Humidity3pm\",\"Pressure3pm\"]].to_numpy()[:nqe_train]).to(torch.float)\n",
        "    label_data_dict[e] = torch.tensor(label_df['RainTomorrow'].to_numpy()[:nqe_train]).to(torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7564\\3772276789.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
            "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7564\\3772276789.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "nqe_x_train = train_data_dict[locations[0]]\n",
        "nqe_y_train = label_data_dict[locations[0]]\n",
        "\n",
        "\n",
        "non_zero = (nqe_y_train != 0).nonzero()\n",
        "\n",
        "nqe_x_train = torch.squeeze(train_data_dict[locations[0]][non_zero])\n",
        "nqe_y_train = torch.squeeze(label_data_dict[locations[0]][non_zero])\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(nqe_x_train, nqe_y_train, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Tensor로 변환\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 603729, 5])\n",
            "torch.Size([2, 603729])\n",
            "torch.Size([2, 38025, 5])\n",
            "torch.Size([2, 38025])\n",
            "torch.Size([603729, 2, 5])\n",
            "torch.Size([603729, 2])\n",
            "torch.Size([38025, 2, 5])\n",
            "torch.Size([38025, 2])\n"
          ]
        }
      ],
      "source": [
        "nqe_train_list = []\n",
        "nqe_train_label_list = []\n",
        "nqe_test_list = []\n",
        "nqe_test_label_list = []\n",
        "\n",
        "for i in range(len(X_train_tensor)):\n",
        "    nqe_train_data = torch.stack([X_train_tensor, torch.concat([X_train_tensor[(i + 1) : ], X_train_tensor[ : (i + 1)]])])\n",
        "    nqe_train_list.append(nqe_train_data)\n",
        "    nqe_label_data = torch.stack([y_train_tensor,torch.concat([y_train_tensor[(i + 1) :],y_train_tensor[: (i + 1)]])])\n",
        "    nqe_train_label_list.append(nqe_label_data)\n",
        "  \n",
        "for i in range(len(X_test_tensor)):\n",
        "    nqe_test_data = torch.stack([X_test_tensor, torch.concat([X_test_tensor[(i + 1) : ], X_test_tensor[ : (i + 1)]])])\n",
        "    nqe_test_list.append(nqe_test_data)\n",
        "    nqe_label_data = torch.stack([y_test_tensor,torch.concat([y_test_tensor[(i + 1) :],y_test_tensor[: (i + 1)]])])\n",
        "    nqe_test_label_list.append(nqe_label_data)\n",
        "\n",
        "nqe_train_data = torch.concat(nqe_train_list, dim = 1)\n",
        "nqe_train_label = torch.concat(nqe_train_label_list, dim = 1)\n",
        "nqe_test_data = torch.concat(nqe_test_list, dim = 1)\n",
        "nqe_test_label = torch.concat(nqe_test_label_list, dim = 1)\n",
        "\n",
        "\n",
        "print(nqe_train_data.shape)\n",
        "print(nqe_train_label.shape)\n",
        "print(nqe_test_data.shape)\n",
        "print(nqe_test_label.shape)\n",
        "\n",
        "\n",
        "nqe_train_data = nqe_train_data.permute(1,0,2)\n",
        "nqe_test_data = nqe_test_data.permute(1,0,2)\n",
        "nqe_train_label = nqe_train_label.permute(1,0)\n",
        "nqe_test_label = nqe_test_label.permute(1,0)\n",
        "\n",
        "print(nqe_train_data.shape)\n",
        "print(nqe_train_label.shape)\n",
        "print(nqe_test_data.shape)\n",
        "print(nqe_test_label.shape)\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "train_dataset = TensorDataset(nqe_train_data, nqe_train_label)\n",
        "test_dataset = TensorDataset(nqe_test_data, nqe_test_label)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1., -1.],\n",
              "        [-1., -1.],\n",
              "        [-1., -1.],\n",
              "        ...,\n",
              "        [ 1.,  1.],\n",
              "        [-1., -1.],\n",
              "        [-1., -1.]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nqe_train_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NQE Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "def criterion(pred, label):\n",
        "    '''\n",
        "        pred : inner product of two states\n",
        "        label : label data\n",
        "    '''\n",
        "    # print(pred.shape)\n",
        "    # print(label.shape)\n",
        "    loss = torch.sum(((pred) - 0.5 * (label[:, 0] * label[:, 1] + 1)) ** 2 ) / len(pred)\n",
        "    return loss\n",
        "\n",
        "def accuarcy(pred, label):\n",
        "    '''\n",
        "        pred : inner product of two states\n",
        "        label : label data\n",
        "    '''\n",
        "    acc = torch.sum((torch.round(pred) == torch.round(0.5 * (label[:, 0] * label[:, 1] + 1)))) / len(pred)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nqe1.load_state_dict(torch.load(\"./models/nqe_fc_loss284.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_qu = 5 # number of features\n",
        "nqe1 = NQE(n_qu, 'FC')\n",
        "nqe_train1 = NQE_Train(nqe1, criterion, train_loader,test_loader,[accuarcy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " loss : 0.06449 metric0 : 0.94118\n",
            "\n",
            " train_loss : 0.06449 test_loss : 0.27944 train_metric : 0.94118 test_metric : 0.68032\n",
            "\n",
            " loss : 0.00270 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00270 test_loss : 0.23277 train_metric : 1.00000 test_metric : 0.73333\n",
            "\n",
            " loss : 0.05036 metric0 : 0.88235\n",
            "\n",
            " train_loss : 0.05036 test_loss : 0.22562 train_metric : 0.88235 test_metric : 0.74496\n",
            "\n",
            " loss : 0.15122 metric0 : 0.82353\n",
            "\n",
            " train_loss : 0.15122 test_loss : 0.24203 train_metric : 0.82353 test_metric : 0.72082\n",
            "\n",
            " loss : 0.05250 metric0 : 0.94118\n",
            "\n",
            " train_loss : 0.05250 test_loss : 0.24449 train_metric : 0.94118 test_metric : 0.70619\n",
            "\n",
            " loss : 0.09443 metric0 : 0.88235\n",
            "\n",
            " train_loss : 0.09443 test_loss : 0.22301 train_metric : 0.88235 test_metric : 0.73449\n",
            "\n",
            " loss : 0.11897 metric0 : 0.88235\n",
            "\n",
            " train_loss : 0.11897 test_loss : 0.22020 train_metric : 0.88235 test_metric : 0.74012\n",
            "\n",
            " loss : 0.00382 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00382 test_loss : 0.23783 train_metric : 1.00000 test_metric : 0.73260\n",
            "\n",
            " loss : 0.05970 metric0 : 0.94118\n",
            "\n",
            " train_loss : 0.05970 test_loss : 0.23978 train_metric : 0.94118 test_metric : 0.73286\n",
            "\n",
            " loss : 0.00474 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00474 test_loss : 0.24742 train_metric : 1.00000 test_metric : 0.70651\n",
            "\n",
            " loss : 0.17013 metric0 : 0.82353\n",
            "\n",
            " train_loss : 0.17013 test_loss : 0.22147 train_metric : 0.82353 test_metric : 0.75343\n",
            "\n",
            " loss : 0.06704 metric0 : 0.94118\n",
            "\n",
            " train_loss : 0.06704 test_loss : 0.27432 train_metric : 0.94118 test_metric : 0.67416\n",
            "\n",
            " loss : 0.10714 metric0 : 0.88235\n",
            "\n",
            " train_loss : 0.10714 test_loss : 0.24182 train_metric : 0.88235 test_metric : 0.71897\n",
            "\n",
            " loss : 0.06672 metric0 : 0.94118\n",
            "\n",
            " train_loss : 0.06672 test_loss : 0.23723 train_metric : 0.94118 test_metric : 0.72639\n",
            "\n",
            " loss : 0.09241 metric0 : 0.88235\n",
            "\n",
            " train_loss : 0.09241 test_loss : 0.22050 train_metric : 0.88235 test_metric : 0.74638\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trained_nqe = nqe_train1.train(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(trained_nqe.state_dict(), \"./models/nqe_fc_loss220.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "nqe2 = NQE(n_qu, 'KAN')\n",
        "nqe_train2 = NQE_Train(nqe2, criterion, train_loader, test_loader, [accuarcy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " loss : 0.19757 metric0 : 0.71875"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 101376 bytes.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_nqe2 \u001b[38;5;241m=\u001b[39m \u001b[43mnqe_train2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(trained_nqe2\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/nqe_kan_0815.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32md:\\ALL\\아주대학교\\비교과\\2024-여름\\Quantum Break\\QRNN-for-Sequential-Classification\\NQE_train_class.py:24\u001b[0m, in \u001b[0;36mNQE_Train.train\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch):\n\u001b[0;32m     23\u001b[0m     nqe_seq \u001b[38;5;241m=\u001b[39m train_seq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnqe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader)\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mnqe_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnqe\n",
            "File \u001b[1;32md:\\ALL\\아주대학교\\비교과\\2024-여름\\Quantum Break\\QRNN-for-Sequential-Classification\\fucntions.py:79\u001b[0m, in \u001b[0;36mtrain_seq.train\u001b[1;34m(self, epochs, optimizer, criterion, metrics, seq_first)\u001b[0m\n\u001b[0;32m     76\u001b[0m     label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 79\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m## Forward 사용\u001b[39;00m\n\u001b[0;32m     80\u001b[0m pred_list\u001b[38;5;241m.\u001b[39mappend(pred)\n\u001b[0;32m     81\u001b[0m label_list\u001b[38;5;241m.\u001b[39mappend(label)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\ALL\\아주대학교\\비교과\\2024-여름\\Quantum Break\\QRNN-for-Sequential-Classification\\NQE_class.py:71\u001b[0m, in \u001b[0;36mNQE.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_FC(inputs)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKAN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_KAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\ALL\\아주대학교\\비교과\\2024-여름\\Quantum Break\\QRNN-for-Sequential-Classification\\NQE_class.py:62\u001b[0m, in \u001b[0;36mNQE.forward_KAN\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     60\u001b[0m input1 \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     61\u001b[0m input2 \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 62\u001b[0m input1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m input2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(input2)\n\u001b[0;32m     64\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantum_layer(input1, input2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_qu)[ : , \u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kan\\KAN.py:311\u001b[0m, in \u001b[0;36mKAN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts\u001b[38;5;241m.\u001b[39mappend(x)  \u001b[38;5;66;03m# acts shape: (batch, width[l])\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m--> 311\u001b[0m     x_numerical, preacts, postacts_numerical, postspline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fun\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m         x_symbolic, postacts_symbolic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_fun[l](x)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kan\\KANLayer.py:173\u001b[0m, in \u001b[0;36mKANLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    171\u001b[0m preacts \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mreshape(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n\u001b[0;32m    172\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun(x)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (batch, size)\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcoef2curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_sharing\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_sharing\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape (size, batch)\u001b[39;00m\n\u001b[0;32m    174\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (batch, size)\u001b[39;00m\n\u001b[0;32m    175\u001b[0m postspline \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mreshape(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kan\\spline.py:102\u001b[0m, in \u001b[0;36mcoef2curve\u001b[1;34m(x_eval, grid, coef, k, device)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coef\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m x_eval\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[0;32m    101\u001b[0m     coef \u001b[38;5;241m=\u001b[39m coef\u001b[38;5;241m.\u001b[39mto(x_eval\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 102\u001b[0m y_eval \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mij,ijk->ik\u001b[39m\u001b[38;5;124m'\u001b[39m, coef, \u001b[43mB_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_eval\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kan\\spline.py:60\u001b[0m, in \u001b[0;36mB_batch\u001b[1;34m(x, grid, k, extend, device)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     B_km1 \u001b[38;5;241m=\u001b[39m B_batch(x[:, \u001b[38;5;241m0\u001b[39m], grid\u001b[38;5;241m=\u001b[39mgrid[:, :, \u001b[38;5;241m0\u001b[39m], k\u001b[38;5;241m=\u001b[39mk \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, extend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 60\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB_km1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB_km1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
            "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 101376 bytes."
          ]
        }
      ],
      "source": [
        "trained_nqe2 = nqe_train2.train(10)\n",
        "torch.save(trained_nqe2.state_dict(), \"./models/nqe_kan_0815.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
            "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
            "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
            "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
          ]
        }
      ],
      "source": [
        "torch.save(trained_nqe2.state_dict(), \"./models/nqe_kan_loss291.pth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "penny_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
