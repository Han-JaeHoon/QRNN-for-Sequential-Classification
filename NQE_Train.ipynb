{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' !git clone https://github.com/Han-JaeHoon/QRNN-for-Sequential-Classification.git\n",
        "!pip install pykan\n",
        "!pip install pennylane\n",
        "%cd QRNN-for-Sequential-Classification '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3yUJB9sbKg0m"
      },
      "outputs": [],
      "source": [
        "# Quantum\n",
        "import pennylane as qml\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# Numpy, Pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Layer\n",
        "from kan import KAN\n",
        "from RNN_block import RNN_block\n",
        "# Data processing\n",
        "from fucntions import data_seq, train_seq\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Quantum User-Def Classes\n",
        "from utils import my_utils\n",
        "from NQE_class import NQE\n",
        "from NQE_train_class import NQE_Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data uploading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "locations = ['Adelaide', 'Albany', 'Albury', 'AliceSprings', 'BadgerysCreek', 'Ballarat', 'Bendigo', 'Brisbane', 'Cairns', 'Canberra', 'Cobar', 'CoffsHarbour', 'Dartmoor', 'Darwin', 'GoldCoast', 'Hobart', 'Katherine', 'Launceston', 'Melbourne', 'MelbourneAirport', 'Mildura', 'Moree', 'MountGambier', 'MountGinini', 'Newcastle', 'Nhil', 'NorahHead', 'NorfolkIsland', 'Nuriootpa', 'PearceRAAF', 'Penrith', 'Perth', 'PerthAirport', 'Portland', 'Richmond', 'Sale', 'SalmonGums', 'Sydney', 'SydneyAirport', 'Townsville', 'Tuggeranong', 'Uluru', 'WaggaWagga', 'Walpole', 'Watsonia', 'Williamtown', 'Witchcliffe', 'Wollongong', 'Woomera']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "nqe_train = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adelaide\n",
            "Albany\n",
            "Albury\n",
            "AliceSprings\n",
            "BadgerysCreek\n",
            "Ballarat\n",
            "Bendigo\n",
            "Brisbane\n",
            "Cairns\n",
            "Canberra\n",
            "Cobar\n",
            "CoffsHarbour\n",
            "Dartmoor\n",
            "Darwin\n",
            "GoldCoast\n",
            "Hobart\n",
            "Katherine\n",
            "Launceston\n",
            "Melbourne\n",
            "MelbourneAirport\n",
            "Mildura\n",
            "Moree\n",
            "MountGambier\n",
            "MountGinini\n",
            "Newcastle\n",
            "Nhil\n",
            "NorahHead\n",
            "NorfolkIsland\n",
            "Nuriootpa\n",
            "PearceRAAF\n",
            "Penrith\n",
            "Perth\n",
            "PerthAirport\n",
            "Portland\n",
            "Richmond\n",
            "Sale\n",
            "SalmonGums\n",
            "Sydney\n",
            "SydneyAirport\n",
            "Townsville\n",
            "Tuggeranong\n",
            "Uluru\n",
            "WaggaWagga\n",
            "Walpole\n",
            "Watsonia\n",
            "Williamtown\n",
            "Witchcliffe\n",
            "Wollongong\n",
            "Woomera\n"
          ]
        }
      ],
      "source": [
        "train_data_dict = dict()\n",
        "label_data_dict = dict()\n",
        "for e in locations:\n",
        "    print(e)\n",
        "    train_df = pd.read_csv(\"./data/train_data_\" + e + \".csv\")\n",
        "    label_df = pd.read_csv(\"./data/label_data_\" + e + \".csv\")\n",
        "    train_data_dict[e] = torch.tensor(train_df[[\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"Humidity3pm\",\"Pressure3pm\"]].to_numpy()[:nqe_train]).to(torch.float)\n",
        "    label_data_dict[e] = torch.tensor(label_df['RainTomorrow'].to_numpy()[:nqe_train]).to(torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_11388\\1777754041.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
            "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_11388\\1777754041.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "nqe_x_train = train_data_dict[locations[0]]\n",
        "nqe_y_train = label_data_dict[locations[0]]\n",
        "\n",
        "\n",
        "non_zero = (nqe_y_train != 0).nonzero()\n",
        "\n",
        "nqe_x_train = torch.squeeze(train_data_dict[locations[0]][non_zero])\n",
        "nqe_y_train = torch.squeeze(label_data_dict[locations[0]][non_zero])\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(nqe_x_train , nqe_y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Tensor로 변환\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 21025, 5])\n",
            "torch.Size([2, 21025])\n",
            "torch.Size([2, 1369, 5])\n",
            "torch.Size([2, 1369])\n",
            "torch.Size([21025, 2, 5])\n",
            "torch.Size([21025, 2])\n",
            "torch.Size([1369, 2, 5])\n",
            "torch.Size([1369, 2])\n"
          ]
        }
      ],
      "source": [
        "nqe_train_list = []\n",
        "nqe_train_label_list = []\n",
        "nqe_test_list = []\n",
        "nqe_test_label_list = []\n",
        "\n",
        "for i in range(len(X_train_tensor)):\n",
        "    nqe_train_data = torch.stack([X_train_tensor, torch.concat([X_train_tensor[(i + 1) : ], X_train_tensor[ : (i + 1)]])])\n",
        "    nqe_train_list.append(nqe_train_data)\n",
        "    nqe_label_data = torch.stack([y_train_tensor,torch.concat([y_train_tensor[(i + 1) :],y_train_tensor[: (i + 1)]])])\n",
        "    nqe_train_label_list.append(nqe_label_data)\n",
        "  \n",
        "for i in range(len(X_test_tensor)):\n",
        "    nqe_test_data = torch.stack([X_test_tensor, torch.concat([X_test_tensor[(i + 1) : ], X_test_tensor[ : (i + 1)]])])\n",
        "    nqe_test_list.append(nqe_test_data)\n",
        "    nqe_label_data = torch.stack([y_test_tensor,torch.concat([y_test_tensor[(i + 1) :],y_test_tensor[: (i + 1)]])])\n",
        "    nqe_test_label_list.append(nqe_label_data)\n",
        "\n",
        "nqe_train_data = torch.concat(nqe_train_list, dim = 1)\n",
        "nqe_train_label = torch.concat(nqe_train_label_list, dim = 1)\n",
        "nqe_test_data = torch.concat(nqe_test_list, dim = 1)\n",
        "nqe_test_label = torch.concat(nqe_test_label_list, dim = 1)\n",
        "\n",
        "\n",
        "print(nqe_train_data.shape)\n",
        "print(nqe_train_label.shape)\n",
        "print(nqe_test_data.shape)\n",
        "print(nqe_test_label.shape)\n",
        "\n",
        "\n",
        "nqe_train_data = nqe_train_data.permute(1,0,2)\n",
        "nqe_test_data = nqe_test_data.permute(1,0,2)\n",
        "nqe_train_label = nqe_train_label.permute(1,0)\n",
        "nqe_test_label = nqe_test_label.permute(1,0)\n",
        "\n",
        "print(nqe_train_data.shape)\n",
        "print(nqe_train_label.shape)\n",
        "print(nqe_test_data.shape)\n",
        "print(nqe_test_label.shape)\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "train_dataset = TensorDataset(nqe_train_data, nqe_train_label)\n",
        "test_dataset = TensorDataset(nqe_test_data, nqe_test_label)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1., -1.],\n",
              "        [-1., -1.],\n",
              "        [-1., -1.],\n",
              "        ...,\n",
              "        [-1., -1.],\n",
              "        [-1., -1.],\n",
              "        [-1., -1.]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nqe_train_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NQE Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "def criterion(pred, label):\n",
        "    '''\n",
        "        pred : inner product of two states\n",
        "        label : label data\n",
        "    '''\n",
        "    # print(pred.shape)\n",
        "    # print(label.shape)\n",
        "    loss = torch.sum(((pred) - 0.5 * (label[:, 0] * label[:, 1] + 1)) ** 2 ) / len(pred)\n",
        "    return loss\n",
        "\n",
        "def accuarcy(pred, label):\n",
        "    '''\n",
        "        pred : inner product of two states\n",
        "        label : label data\n",
        "    '''\n",
        "    acc = torch.sum((torch.round(pred) == torch.round(0.5 * (label[:, 0] * label[:, 1] + 1)))) / len(pred)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nqe1.load_state_dict(torch.load(\"./models/nqe_fc_loss284.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_qu = 5 # number of features\n",
        "nqe1 = NQE(n_qu, 'FC')\n",
        "nqe_train1 = NQE_Train(nqe1, criterion, train_loader,test_loader,[accuarcy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " loss : 0.01354 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.01354 test_loss : 0.28805 train_metric : 1.00000 test_metric : 0.60263\n",
            "\n",
            " loss : 0.00632 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00632 test_loss : 0.32027 train_metric : 1.00000 test_metric : 0.59240\n",
            "\n",
            " loss : 0.01885 metric0 : 0.96970\n",
            "\n",
            " train_loss : 0.01885 test_loss : 0.32144 train_metric : 0.96970 test_metric : 0.55296\n",
            "\n",
            " loss : 0.00057 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00057 test_loss : 0.36111 train_metric : 1.00000 test_metric : 0.55004\n",
            "\n",
            " loss : 0.03067 metric0 : 0.96970\n",
            "\n",
            " train_loss : 0.03067 test_loss : 0.35832 train_metric : 0.96970 test_metric : 0.54273\n",
            "\n",
            " loss : 0.00026 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00026 test_loss : 0.36900 train_metric : 1.00000 test_metric : 0.54565\n",
            "\n",
            " loss : 0.00016 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00016 test_loss : 0.37230 train_metric : 1.00000 test_metric : 0.55004\n",
            "\n",
            " loss : 0.03042 metric0 : 0.96970\n",
            "\n",
            " train_loss : 0.03042 test_loss : 0.40378 train_metric : 0.96970 test_metric : 0.50183\n",
            "\n",
            " loss : 0.00003 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00003 test_loss : 0.40431 train_metric : 1.00000 test_metric : 0.51936\n",
            "\n",
            " loss : 0.00252 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00252 test_loss : 0.38628 train_metric : 1.00000 test_metric : 0.50913\n",
            "\n",
            " loss : 0.00062 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00062 test_loss : 0.31914 train_metric : 1.00000 test_metric : 0.63039\n",
            "\n",
            " loss : 0.00004 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00004 test_loss : 0.31939 train_metric : 1.00000 test_metric : 0.62308\n",
            "\n",
            " loss : 0.00142 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00142 test_loss : 0.32027 train_metric : 1.00000 test_metric : 0.62308\n",
            "\n",
            " loss : 0.00014 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00014 test_loss : 0.32361 train_metric : 1.00000 test_metric : 0.62162\n",
            "\n",
            " loss : 0.00003 metric0 : 1.00000\n",
            "\n",
            " train_loss : 0.00003 test_loss : 0.32336 train_metric : 1.00000 test_metric : 0.61870\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trained_nqe = nqe_train1.train(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(trained_nqe.state_dict(), \"./models/nqe_fc_loss323.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "nqe2 = NQE(n_qu, 'KAN')\n",
        "nqe_train2 = NQE_Train(nqe2, criterion, train_loader, test_loader, [accuarcy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " loss : 0.17146 metric0 : 0.78788\n",
            "\n",
            " train_loss : 0.17146 test_loss : 0.24324 train_metric : 0.78788 test_metric : 0.64207\n",
            "\n",
            " loss : 0.16672 metric0 : 0.78788\n",
            "\n",
            " train_loss : 0.16672 test_loss : 0.24293 train_metric : 0.78788 test_metric : 0.65230\n",
            "\n",
            " loss : 0.11358 metric0 : 0.81818\n",
            "\n",
            " train_loss : 0.11358 test_loss : 0.25046 train_metric : 0.81818 test_metric : 0.64354\n",
            "\n",
            " loss : 0.10798 metric0 : 0.81818\n",
            "\n",
            " train_loss : 0.10798 test_loss : 0.26714 train_metric : 0.81818 test_metric : 0.57633\n",
            "\n",
            " loss : 0.15382 metric0 : 0.81818\n",
            "\n",
            " train_loss : 0.15382 test_loss : 0.27411 train_metric : 0.81818 test_metric : 0.56757\n",
            "\n",
            " loss : 0.14362 metric0 : 0.78788\n",
            "\n",
            " train_loss : 0.14362 test_loss : 0.30407 train_metric : 0.78788 test_metric : 0.60847\n",
            "\n",
            " loss : 0.07536 metric0 : 0.90909\n",
            "\n",
            " train_loss : 0.07536 test_loss : 0.31481 train_metric : 0.90909 test_metric : 0.58802\n",
            "\n",
            " loss : 0.04748 metric0 : 0.96970\n",
            "\n",
            " train_loss : 0.04748 test_loss : 0.30377 train_metric : 0.96970 test_metric : 0.58802\n",
            "\n",
            " loss : 0.04551 metric0 : 0.96970\n",
            "\n",
            " train_loss : 0.04551 test_loss : 0.29457 train_metric : 0.96970 test_metric : 0.59825\n",
            "\n",
            " loss : 0.04990 metric0 : 0.93939\n",
            "\n",
            " train_loss : 0.04990 test_loss : 0.29131 train_metric : 0.93939 test_metric : 0.60993\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trained_nqe2 = nqe_train2.train(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(trained_nqe2.state_dict(), \"./models/nqe_kan_loss291.pth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "penny_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
