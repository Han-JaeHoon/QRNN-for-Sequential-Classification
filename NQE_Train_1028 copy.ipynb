{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum\n",
    "import pennylane as qml\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Numpy, Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Layer\n",
    "from kan import KAN\n",
    "from RNN_block import RNN_block\n",
    "# Data processing\n",
    "from fucntions_1028 import data_seq, train_seq\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Quantum User-Def Classes\n",
    "from utils import my_utils\n",
    "from NQE_class import NQE\n",
    "from NQE_train_class import NQE_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 경로\n",
    "feature_path = './data/pca/pca_train_data_Perth.csv'\n",
    "label_path = './data/pca/pca_label_data_Perth.csv'\n",
    "\n",
    "# CSV 파일을 읽어 Tensor로 변환\n",
    "feature_data = torch.tensor(pd.read_csv(feature_path).values, dtype=torch.float32)\n",
    "label_data = torch.tensor(pd.read_csv(label_path).values, dtype=torch.float32)\n",
    "\n",
    "# data_seq 객체 생성\n",
    "data = data_seq(feature_data, label_data)\n",
    "train_loader, test_loader = data.split_data(test_ratio = 0.2, batch_size = 32, seq_first = False, for_nqe = True, seed = 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3193"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for t, l in test_loader:\n",
    "    print(l.shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(pred, label):\n",
    "    '''\n",
    "        pred : inner product of two states\n",
    "        label : label data\n",
    "    '''\n",
    "    print('pred : ', pred.shape)\n",
    "    print('label :', label.shape)\n",
    "    print('lbl[:, 0][-1] :', label[:, 0][-1])\n",
    "    print('2nd term :', (label[:, 0] * label[:, 1] + 1).shape)\n",
    "    loss = torch.sum(((pred) - 0.5 * (label[:, 0] * label[:, 1] + 1)) ** 2 ) / len(pred)\n",
    "    return loss\n",
    "\n",
    "def accuarcy(pred, label):\n",
    "    '''\n",
    "        pred : inner product of two states\n",
    "        label : label data\n",
    "    '''\n",
    "    acc = torch.sum((torch.round(pred) == torch.round(0.5 * (label[:, 0] * label[:, 1] + 1)))) / len(pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "for t, l in train_loader:\n",
    "    print(t.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 1 =====\n",
      "pred :  torch.Size([32])\n",
      "label : torch.Size([2, 32])\n",
      "lbl[:, 0][-1] : tensor(1.)\n",
      "2nd term : torch.Size([2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m test_nqe \u001b[38;5;241m=\u001b[39m NQE(n_feature\u001b[38;5;241m=\u001b[39mn, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_train \u001b[38;5;241m=\u001b[39m NQE_Train(test_nqe, criterion, train_loader, test_loader, [accuarcy])\n\u001b[0;32m----> 4\u001b[0m tested_nqe \u001b[38;5;241m=\u001b[39m \u001b[43mtest_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Quantum Computing/QRNN/QRNN-for-Sequential-Classification/NQE_train_class.py:24\u001b[0m, in \u001b[0;36mNQE_Train.train\u001b[0;34m(self, epoch, seq_first)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, seq_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     23\u001b[0m     nqe_seq \u001b[38;5;241m=\u001b[39m train_seq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnqe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader)\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mnqe_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnqe\n",
      "File \u001b[0;32m~/Desktop/Quantum Computing/QRNN/QRNN-for-Sequential-Classification/fucntions.py:92\u001b[0m, in \u001b[0;36mtrain_seq.train\u001b[0;34m(self, epochs, optimizer, criterion, metrics, seq_first)\u001b[0m\n\u001b[1;32m     90\u001b[0m pred_list\u001b[38;5;241m.\u001b[39mappend(pred)\n\u001b[1;32m     91\u001b[0m label_list\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m---> 92\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     94\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mcriterion\u001b[0;34m(pred, label)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbl[:, 0][-1] :\u001b[39m\u001b[38;5;124m'\u001b[39m, label[:, \u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2nd term :\u001b[39m\u001b[38;5;124m'\u001b[39m, (label[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m label[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum((\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(pred)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "test_nqe = NQE(n_feature=n, mode='FC')\n",
    "test_train = NQE_Train(test_nqe, criterion, train_loader, test_loader, [accuarcy])\n",
    "tested_nqe = test_train.train(5, seq_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fc_nqe = NQE(n_feature=n, mode='FC')\n",
    "fc_nqe_train = NQE_Train(fc_nqe, criterion, train_loader, test_loader, [accuarcy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss : 0.10792 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10792 test_loss : 0.15034 train_metric : 0.88889 test_metric : 0.81975\n",
      "\n",
      " loss : 0.14484 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14484 test_loss : 0.15750 train_metric : 0.81481 test_metric : 0.80721\n",
      "\n",
      " loss : 0.15150 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15150 test_loss : 0.15551 train_metric : 0.81481 test_metric : 0.80564\n",
      "\n",
      " loss : 0.15104 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15104 test_loss : 0.16275 train_metric : 0.77778 test_metric : 0.78213\n",
      "\n",
      " loss : 0.19727 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19727 test_loss : 0.15934 train_metric : 0.77778 test_metric : 0.81661\n",
      "\n",
      " loss : 0.10643 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10643 test_loss : 0.17221 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.08329 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08329 test_loss : 0.15080 train_metric : 0.88889 test_metric : 0.80408\n",
      "\n",
      " loss : 0.13570 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13570 test_loss : 0.15830 train_metric : 0.81481 test_metric : 0.81191\n",
      "\n",
      " loss : 0.11732 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11732 test_loss : 0.16255 train_metric : 0.85185 test_metric : 0.79937\n",
      "\n",
      " loss : 0.18250 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.18250 test_loss : 0.15586 train_metric : 0.81481 test_metric : 0.80094\n",
      "\n",
      " loss : 0.15327 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15327 test_loss : 0.16363 train_metric : 0.77778 test_metric : 0.79624\n",
      "\n",
      " loss : 0.15053 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15053 test_loss : 0.15486 train_metric : 0.81481 test_metric : 0.80251\n",
      "\n",
      " loss : 0.13893 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.13893 test_loss : 0.16404 train_metric : 0.77778 test_metric : 0.78213\n",
      "\n",
      " loss : 0.12692 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12692 test_loss : 0.16081 train_metric : 0.81481 test_metric : 0.78527\n",
      "\n",
      " loss : 0.17815 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17815 test_loss : 0.15300 train_metric : 0.81481 test_metric : 0.80564\n",
      "\n",
      " loss : 0.15643 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15643 test_loss : 0.16264 train_metric : 0.77778 test_metric : 0.78997\n",
      "\n",
      " loss : 0.23231 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.23231 test_loss : 0.15994 train_metric : 0.70370 test_metric : 0.79624\n",
      "\n",
      " loss : 0.08808 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08808 test_loss : 0.15901 train_metric : 0.88889 test_metric : 0.79154\n",
      "\n",
      " loss : 0.15150 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15150 test_loss : 0.16754 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.08121 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08121 test_loss : 0.17451 train_metric : 0.88889 test_metric : 0.77429\n",
      "\n",
      " loss : 0.11904 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11904 test_loss : 0.15669 train_metric : 0.81481 test_metric : 0.79154\n",
      "\n",
      " loss : 0.04260 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04260 test_loss : 0.15920 train_metric : 0.96296 test_metric : 0.79154\n",
      "\n",
      " loss : 0.16617 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16617 test_loss : 0.16942 train_metric : 0.74074 test_metric : 0.76646\n",
      "\n",
      " loss : 0.09093 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09093 test_loss : 0.16180 train_metric : 0.92593 test_metric : 0.77743\n",
      "\n",
      " loss : 0.12226 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12226 test_loss : 0.16737 train_metric : 0.81481 test_metric : 0.78683\n",
      "\n",
      " loss : 0.07493 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07493 test_loss : 0.16814 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.12403 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12403 test_loss : 0.15651 train_metric : 0.81481 test_metric : 0.79154\n",
      "\n",
      " loss : 0.06915 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06915 test_loss : 0.15853 train_metric : 0.92593 test_metric : 0.79624\n",
      "\n",
      " loss : 0.06691 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06691 test_loss : 0.15616 train_metric : 0.92593 test_metric : 0.79937\n",
      "\n",
      " loss : 0.17210 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17210 test_loss : 0.15953 train_metric : 0.77778 test_metric : 0.78683\n",
      "\n",
      " loss : 0.11382 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11382 test_loss : 0.16264 train_metric : 0.88889 test_metric : 0.77743\n",
      "\n",
      " loss : 0.09429 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09429 test_loss : 0.16513 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.12062 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12062 test_loss : 0.17180 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.12721 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12721 test_loss : 0.15953 train_metric : 0.85185 test_metric : 0.78370\n",
      "\n",
      " loss : 0.13127 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13127 test_loss : 0.15717 train_metric : 0.85185 test_metric : 0.79624\n",
      "\n",
      " loss : 0.12797 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12797 test_loss : 0.16692 train_metric : 0.81481 test_metric : 0.78370\n",
      "\n",
      " loss : 0.09546 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09546 test_loss : 0.17752 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.11470 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11470 test_loss : 0.16018 train_metric : 0.85185 test_metric : 0.78527\n",
      "\n",
      " loss : 0.29266 metric0 : 0.62963\n",
      "\n",
      " train_loss : 0.29266 test_loss : 0.17086 train_metric : 0.62963 test_metric : 0.77273\n",
      "\n",
      " loss : 0.06731 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06731 test_loss : 0.17650 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10067 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10067 test_loss : 0.16732 train_metric : 0.85185 test_metric : 0.78840\n",
      "\n",
      " loss : 0.08045 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08045 test_loss : 0.17156 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.04582 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04582 test_loss : 0.17950 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.06218 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06218 test_loss : 0.18041 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.10444 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10444 test_loss : 0.16378 train_metric : 0.88889 test_metric : 0.77586\n",
      "\n",
      " loss : 0.21146 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.21146 test_loss : 0.16006 train_metric : 0.74074 test_metric : 0.79154\n",
      "\n",
      " loss : 0.15671 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15671 test_loss : 0.17434 train_metric : 0.77778 test_metric : 0.76019\n",
      "\n",
      " loss : 0.08186 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08186 test_loss : 0.16682 train_metric : 0.88889 test_metric : 0.78056\n",
      "\n",
      " loss : 0.09542 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09542 test_loss : 0.15724 train_metric : 0.88889 test_metric : 0.79310\n",
      "\n",
      " loss : 0.17251 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17251 test_loss : 0.16200 train_metric : 0.81481 test_metric : 0.78683\n",
      "\n",
      " loss : 0.05333 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05333 test_loss : 0.16086 train_metric : 0.92593 test_metric : 0.78997\n",
      "\n",
      " loss : 0.16792 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.16792 test_loss : 0.16433 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.09198 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09198 test_loss : 0.16735 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.11671 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11671 test_loss : 0.16869 train_metric : 0.81481 test_metric : 0.78056\n",
      "\n",
      " loss : 0.11156 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11156 test_loss : 0.16508 train_metric : 0.88889 test_metric : 0.77900\n",
      "\n",
      " loss : 0.11103 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11103 test_loss : 0.17231 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.18678 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.18678 test_loss : 0.17581 train_metric : 0.70370 test_metric : 0.77116\n",
      "\n",
      " loss : 0.09796 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09796 test_loss : 0.16622 train_metric : 0.88889 test_metric : 0.77900\n",
      "\n",
      " loss : 0.12009 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12009 test_loss : 0.16359 train_metric : 0.81481 test_metric : 0.77900\n",
      "\n",
      " loss : 0.12951 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12951 test_loss : 0.16333 train_metric : 0.85185 test_metric : 0.78056\n",
      "\n",
      " loss : 0.07520 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07520 test_loss : 0.16435 train_metric : 0.92593 test_metric : 0.78370\n",
      "\n",
      " loss : 0.08681 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08681 test_loss : 0.16407 train_metric : 0.85185 test_metric : 0.78056\n",
      "\n",
      " loss : 0.02406 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02406 test_loss : 0.17179 train_metric : 1.00000 test_metric : 0.77743\n",
      "\n",
      " loss : 0.08597 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08597 test_loss : 0.17217 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.11160 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.11160 test_loss : 0.16839 train_metric : 0.77778 test_metric : 0.77273\n",
      "\n",
      " loss : 0.07368 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07368 test_loss : 0.16890 train_metric : 0.92593 test_metric : 0.78370\n",
      "\n",
      " loss : 0.10306 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10306 test_loss : 0.16384 train_metric : 0.81481 test_metric : 0.78527\n",
      "\n",
      " loss : 0.04100 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04100 test_loss : 0.16025 train_metric : 0.96296 test_metric : 0.78997\n",
      "\n",
      " loss : 0.12604 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12604 test_loss : 0.16659 train_metric : 0.85185 test_metric : 0.78056\n",
      "\n",
      " loss : 0.05096 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05096 test_loss : 0.16671 train_metric : 0.92593 test_metric : 0.77900\n",
      "\n",
      " loss : 0.10563 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10563 test_loss : 0.16869 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08221 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08221 test_loss : 0.16894 train_metric : 0.92593 test_metric : 0.78370\n",
      "\n",
      " loss : 0.08237 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08237 test_loss : 0.16762 train_metric : 0.85185 test_metric : 0.78370\n",
      "\n",
      " loss : 0.10969 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10969 test_loss : 0.18504 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.13343 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13343 test_loss : 0.17204 train_metric : 0.85185 test_metric : 0.77273\n",
      "\n",
      " loss : 0.18616 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18616 test_loss : 0.17022 train_metric : 0.77778 test_metric : 0.76646\n",
      "\n",
      " loss : 0.07751 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07751 test_loss : 0.16888 train_metric : 0.92593 test_metric : 0.79154\n",
      "\n",
      " loss : 0.04533 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04533 test_loss : 0.16794 train_metric : 0.92593 test_metric : 0.77900\n",
      "\n",
      " loss : 0.10264 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10264 test_loss : 0.17442 train_metric : 0.85185 test_metric : 0.77429\n",
      "\n",
      " loss : 0.09767 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09767 test_loss : 0.16766 train_metric : 0.92593 test_metric : 0.78997\n",
      "\n",
      " loss : 0.08020 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08020 test_loss : 0.16983 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.10619 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10619 test_loss : 0.16870 train_metric : 0.88889 test_metric : 0.77429\n",
      "\n",
      " loss : 0.07893 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07893 test_loss : 0.16701 train_metric : 0.92593 test_metric : 0.79467\n",
      "\n",
      " loss : 0.10347 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10347 test_loss : 0.17892 train_metric : 0.81481 test_metric : 0.77273\n",
      "\n",
      " loss : 0.12764 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12764 test_loss : 0.16847 train_metric : 0.88889 test_metric : 0.78527\n",
      "\n",
      " loss : 0.08254 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08254 test_loss : 0.16249 train_metric : 0.88889 test_metric : 0.79154\n",
      "\n",
      " loss : 0.11508 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11508 test_loss : 0.16396 train_metric : 0.88889 test_metric : 0.78997\n",
      "\n",
      " loss : 0.07848 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07848 test_loss : 0.18398 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.11020 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11020 test_loss : 0.17352 train_metric : 0.81481 test_metric : 0.79624\n",
      "\n",
      " loss : 0.11230 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11230 test_loss : 0.17261 train_metric : 0.88889 test_metric : 0.77900\n",
      "\n",
      " loss : 0.13714 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13714 test_loss : 0.17140 train_metric : 0.81481 test_metric : 0.77586\n",
      "\n",
      " loss : 0.15214 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15214 test_loss : 0.17531 train_metric : 0.77778 test_metric : 0.78527\n",
      "\n",
      " loss : 0.11522 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11522 test_loss : 0.17548 train_metric : 0.81481 test_metric : 0.77273\n",
      "\n",
      " loss : 0.11485 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11485 test_loss : 0.17559 train_metric : 0.85185 test_metric : 0.78213\n",
      "\n",
      " loss : 0.12805 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12805 test_loss : 0.17272 train_metric : 0.81481 test_metric : 0.77586\n",
      "\n",
      " loss : 0.16511 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16511 test_loss : 0.18036 train_metric : 0.77778 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09763 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09763 test_loss : 0.18792 train_metric : 0.88889 test_metric : 0.74451\n",
      "\n",
      " loss : 0.03451 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03451 test_loss : 0.16996 train_metric : 0.92593 test_metric : 0.77900\n",
      "\n",
      " loss : 0.05868 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.05868 test_loss : 0.17796 train_metric : 0.85185 test_metric : 0.77900\n",
      "\n",
      " loss : 0.11859 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11859 test_loss : 0.17453 train_metric : 0.81481 test_metric : 0.76019\n",
      "\n",
      " loss : 0.02554 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02554 test_loss : 0.17319 train_metric : 1.00000 test_metric : 0.78056\n",
      "\n",
      " loss : 0.06009 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06009 test_loss : 0.17598 train_metric : 0.96296 test_metric : 0.77900\n",
      "\n",
      " loss : 0.17307 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17307 test_loss : 0.16500 train_metric : 0.81481 test_metric : 0.78840\n",
      "\n",
      " loss : 0.13039 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13039 test_loss : 0.17070 train_metric : 0.81481 test_metric : 0.78056\n",
      "\n",
      " loss : 0.15578 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15578 test_loss : 0.17139 train_metric : 0.81481 test_metric : 0.78370\n",
      "\n",
      " loss : 0.09618 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09618 test_loss : 0.17084 train_metric : 0.92593 test_metric : 0.77429\n",
      "\n",
      " loss : 0.15492 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15492 test_loss : 0.17393 train_metric : 0.81481 test_metric : 0.78213\n",
      "\n",
      " loss : 0.13762 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13762 test_loss : 0.16467 train_metric : 0.81481 test_metric : 0.78683\n",
      "\n",
      " loss : 0.07136 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07136 test_loss : 0.18462 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.05504 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05504 test_loss : 0.16572 train_metric : 0.96296 test_metric : 0.78213\n",
      "\n",
      " loss : 0.19818 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19818 test_loss : 0.18242 train_metric : 0.77778 test_metric : 0.77273\n",
      "\n",
      " loss : 0.08351 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08351 test_loss : 0.17584 train_metric : 0.88889 test_metric : 0.77429\n",
      "\n",
      " loss : 0.13261 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13261 test_loss : 0.17482 train_metric : 0.81481 test_metric : 0.77116\n",
      "\n",
      " loss : 0.07589 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07589 test_loss : 0.17071 train_metric : 0.92593 test_metric : 0.78527\n",
      "\n",
      " loss : 0.10306 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10306 test_loss : 0.17282 train_metric : 0.88889 test_metric : 0.78527\n",
      "\n",
      " loss : 0.05228 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05228 test_loss : 0.16909 train_metric : 0.96296 test_metric : 0.77900\n",
      "\n",
      " loss : 0.09470 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09470 test_loss : 0.20252 train_metric : 0.88889 test_metric : 0.74295\n",
      "\n",
      " loss : 0.12754 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12754 test_loss : 0.18820 train_metric : 0.81481 test_metric : 0.76646\n",
      "\n",
      " loss : 0.09488 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09488 test_loss : 0.18267 train_metric : 0.85185 test_metric : 0.77429\n",
      "\n",
      " loss : 0.10879 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10879 test_loss : 0.17802 train_metric : 0.85185 test_metric : 0.77273\n",
      "\n",
      " loss : 0.14972 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.14972 test_loss : 0.17025 train_metric : 0.74074 test_metric : 0.78213\n",
      "\n",
      " loss : 0.12732 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12732 test_loss : 0.18445 train_metric : 0.81481 test_metric : 0.75235\n",
      "\n",
      " loss : 0.04902 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04902 test_loss : 0.19117 train_metric : 0.96296 test_metric : 0.74138\n",
      "\n",
      " loss : 0.09299 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09299 test_loss : 0.18651 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.15719 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15719 test_loss : 0.17263 train_metric : 0.77778 test_metric : 0.77900\n",
      "\n",
      " loss : 0.23848 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.23848 test_loss : 0.18317 train_metric : 0.66667 test_metric : 0.75862\n",
      "\n",
      " loss : 0.09211 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09211 test_loss : 0.18370 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.04337 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04337 test_loss : 0.17958 train_metric : 0.96296 test_metric : 0.78683\n",
      "\n",
      " loss : 0.05527 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05527 test_loss : 0.18798 train_metric : 0.92593 test_metric : 0.73981\n",
      "\n",
      " loss : 0.11613 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11613 test_loss : 0.17484 train_metric : 0.88889 test_metric : 0.77116\n",
      "\n",
      " loss : 0.16613 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16613 test_loss : 0.18068 train_metric : 0.81481 test_metric : 0.77429\n",
      "\n",
      " loss : 0.14281 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14281 test_loss : 0.17785 train_metric : 0.81481 test_metric : 0.78056\n",
      "\n",
      " loss : 0.09050 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09050 test_loss : 0.18642 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.15437 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15437 test_loss : 0.17456 train_metric : 0.85185 test_metric : 0.78056\n",
      "\n",
      " loss : 0.16917 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16917 test_loss : 0.19303 train_metric : 0.77778 test_metric : 0.74765\n",
      "\n",
      " loss : 0.04463 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04463 test_loss : 0.17629 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.10812 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10812 test_loss : 0.18759 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.03724 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03724 test_loss : 0.18258 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.02356 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02356 test_loss : 0.17699 train_metric : 1.00000 test_metric : 0.77900\n",
      "\n",
      " loss : 0.03895 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03895 test_loss : 0.17787 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.09359 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09359 test_loss : 0.18445 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.10345 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10345 test_loss : 0.16826 train_metric : 0.88889 test_metric : 0.77743\n",
      "\n",
      " loss : 0.19861 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19861 test_loss : 0.16889 train_metric : 0.77778 test_metric : 0.77900\n",
      "\n",
      " loss : 0.12198 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12198 test_loss : 0.17614 train_metric : 0.81481 test_metric : 0.78213\n",
      "\n",
      " loss : 0.15165 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15165 test_loss : 0.18533 train_metric : 0.81481 test_metric : 0.75705\n",
      "\n",
      " loss : 0.14069 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14069 test_loss : 0.19227 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.09459 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09459 test_loss : 0.18227 train_metric : 0.85185 test_metric : 0.77116\n",
      "\n",
      " loss : 0.03162 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03162 test_loss : 0.18329 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.14920 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14920 test_loss : 0.19740 train_metric : 0.85185 test_metric : 0.73511\n",
      "\n",
      " loss : 0.08901 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08901 test_loss : 0.17337 train_metric : 0.88889 test_metric : 0.78370\n",
      "\n",
      " loss : 0.07749 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.07749 test_loss : 0.17854 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.04738 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04738 test_loss : 0.18487 train_metric : 0.92593 test_metric : 0.77743\n",
      "\n",
      " loss : 0.10404 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10404 test_loss : 0.18514 train_metric : 0.88889 test_metric : 0.77116\n",
      "\n",
      " loss : 0.14480 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14480 test_loss : 0.18035 train_metric : 0.77778 test_metric : 0.77429\n",
      "\n",
      " loss : 0.03295 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03295 test_loss : 0.18656 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.04369 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04369 test_loss : 0.18131 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07488 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07488 test_loss : 0.18440 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.03828 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03828 test_loss : 0.17733 train_metric : 0.96296 test_metric : 0.77900\n",
      "\n",
      " loss : 0.10960 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10960 test_loss : 0.17494 train_metric : 0.85185 test_metric : 0.77116\n",
      "\n",
      " loss : 0.05036 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05036 test_loss : 0.18273 train_metric : 0.92593 test_metric : 0.78527\n",
      "\n",
      " loss : 0.04124 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04124 test_loss : 0.17785 train_metric : 0.96296 test_metric : 0.77743\n",
      "\n",
      " loss : 0.06175 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06175 test_loss : 0.18403 train_metric : 0.96296 test_metric : 0.76332\n",
      "\n",
      " loss : 0.11023 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11023 test_loss : 0.18569 train_metric : 0.81481 test_metric : 0.76019\n",
      "\n",
      " loss : 0.14602 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14602 test_loss : 0.18505 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.15416 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15416 test_loss : 0.19733 train_metric : 0.81481 test_metric : 0.74922\n",
      "\n",
      " loss : 0.12107 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12107 test_loss : 0.17679 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.09088 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09088 test_loss : 0.18661 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.05449 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05449 test_loss : 0.18740 train_metric : 0.96296 test_metric : 0.75392\n",
      "\n",
      " loss : 0.09959 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09959 test_loss : 0.18459 train_metric : 0.85185 test_metric : 0.74922\n",
      "\n",
      " loss : 0.07935 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07935 test_loss : 0.17906 train_metric : 0.92593 test_metric : 0.78213\n",
      "\n",
      " loss : 0.11869 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11869 test_loss : 0.18029 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07583 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07583 test_loss : 0.17521 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.15841 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15841 test_loss : 0.18275 train_metric : 0.81481 test_metric : 0.76803\n",
      "\n",
      " loss : 0.12654 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12654 test_loss : 0.18865 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.08981 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08981 test_loss : 0.18308 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.07598 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07598 test_loss : 0.18520 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.13697 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13697 test_loss : 0.17819 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.17837 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17837 test_loss : 0.19321 train_metric : 0.81481 test_metric : 0.73511\n",
      "\n",
      " loss : 0.09389 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09389 test_loss : 0.17977 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.06333 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06333 test_loss : 0.18079 train_metric : 0.92593 test_metric : 0.77586\n",
      "\n",
      " loss : 0.14902 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14902 test_loss : 0.18591 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05939 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05939 test_loss : 0.18183 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.08246 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.08246 test_loss : 0.18169 train_metric : 0.96296 test_metric : 0.76803\n",
      "\n",
      " loss : 0.09649 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09649 test_loss : 0.18244 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.11274 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.11274 test_loss : 0.18318 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.07909 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07909 test_loss : 0.18173 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.09845 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09845 test_loss : 0.17566 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.12868 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.12868 test_loss : 0.17654 train_metric : 0.77778 test_metric : 0.78997\n",
      "\n",
      " loss : 0.11229 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11229 test_loss : 0.17311 train_metric : 0.85185 test_metric : 0.77586\n",
      "\n",
      " loss : 0.08717 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08717 test_loss : 0.16997 train_metric : 0.85185 test_metric : 0.77586\n",
      "\n",
      " loss : 0.03596 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03596 test_loss : 0.17635 train_metric : 0.96296 test_metric : 0.78213\n",
      "\n",
      " loss : 0.02635 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02635 test_loss : 0.17378 train_metric : 1.00000 test_metric : 0.77900\n",
      "\n",
      " loss : 0.13918 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13918 test_loss : 0.17769 train_metric : 0.85185 test_metric : 0.78370\n",
      "\n",
      " loss : 0.18415 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18415 test_loss : 0.18059 train_metric : 0.74074 test_metric : 0.77900\n",
      "\n",
      " loss : 0.10688 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10688 test_loss : 0.19017 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.09851 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09851 test_loss : 0.18050 train_metric : 0.85185 test_metric : 0.77273\n",
      "\n",
      " loss : 0.08099 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08099 test_loss : 0.18469 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08476 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08476 test_loss : 0.18034 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.07959 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07959 test_loss : 0.17850 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.06274 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06274 test_loss : 0.17666 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.14481 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14481 test_loss : 0.17982 train_metric : 0.77778 test_metric : 0.76959\n",
      "\n",
      " loss : 0.11887 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11887 test_loss : 0.17635 train_metric : 0.81481 test_metric : 0.77273\n",
      "\n",
      " loss : 0.09746 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09746 test_loss : 0.18104 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.08963 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08963 test_loss : 0.18255 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.18394 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18394 test_loss : 0.18585 train_metric : 0.77778 test_metric : 0.75705\n",
      "\n",
      " loss : 0.10533 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10533 test_loss : 0.18019 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.09040 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09040 test_loss : 0.17918 train_metric : 0.85185 test_metric : 0.78997\n",
      "\n",
      " loss : 0.10589 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10589 test_loss : 0.17841 train_metric : 0.85185 test_metric : 0.77116\n",
      "\n",
      " loss : 0.04270 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04270 test_loss : 0.18062 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.03036 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03036 test_loss : 0.17766 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.12005 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12005 test_loss : 0.18247 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.10477 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10477 test_loss : 0.17189 train_metric : 0.85185 test_metric : 0.78056\n",
      "\n",
      " loss : 0.10462 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10462 test_loss : 0.17615 train_metric : 0.81481 test_metric : 0.78056\n",
      "\n",
      " loss : 0.07154 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07154 test_loss : 0.18249 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.09895 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09895 test_loss : 0.18430 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.18851 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.18851 test_loss : 0.17119 train_metric : 0.81481 test_metric : 0.77586\n",
      "\n",
      " loss : 0.07978 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07978 test_loss : 0.18824 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.02909 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02909 test_loss : 0.18475 train_metric : 1.00000 test_metric : 0.76332\n",
      "\n",
      " loss : 0.10301 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10301 test_loss : 0.17671 train_metric : 0.85185 test_metric : 0.78213\n",
      "\n",
      " loss : 0.09873 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09873 test_loss : 0.18312 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.04354 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.04354 test_loss : 0.18399 train_metric : 1.00000 test_metric : 0.75235\n",
      "\n",
      " loss : 0.12171 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12171 test_loss : 0.17188 train_metric : 0.85185 test_metric : 0.77586\n",
      "\n",
      " loss : 0.19408 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19408 test_loss : 0.17788 train_metric : 0.77778 test_metric : 0.77429\n",
      "\n",
      " loss : 0.02495 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02495 test_loss : 0.18634 train_metric : 0.96296 test_metric : 0.76803\n",
      "\n",
      " loss : 0.10776 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10776 test_loss : 0.17800 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.01807 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01807 test_loss : 0.18048 train_metric : 1.00000 test_metric : 0.75862\n",
      "\n",
      " loss : 0.01374 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01374 test_loss : 0.18139 train_metric : 1.00000 test_metric : 0.76489\n",
      "\n",
      " loss : 0.15667 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15667 test_loss : 0.18277 train_metric : 0.81481 test_metric : 0.75862\n",
      "\n",
      " loss : 0.11361 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.11361 test_loss : 0.18054 train_metric : 0.77778 test_metric : 0.76019\n",
      "\n",
      " loss : 0.11070 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11070 test_loss : 0.18268 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.06867 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06867 test_loss : 0.17259 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.09878 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.09878 test_loss : 0.17365 train_metric : 0.81481 test_metric : 0.78527\n",
      "\n",
      " loss : 0.09670 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09670 test_loss : 0.17903 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.07607 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07607 test_loss : 0.17718 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.10593 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10593 test_loss : 0.17537 train_metric : 0.85185 test_metric : 0.77900\n",
      "\n",
      " loss : 0.07878 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07878 test_loss : 0.18181 train_metric : 0.92593 test_metric : 0.77900\n",
      "\n",
      " loss : 0.14944 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14944 test_loss : 0.17868 train_metric : 0.77778 test_metric : 0.77273\n",
      "\n",
      " loss : 0.08704 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08704 test_loss : 0.17818 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.09210 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09210 test_loss : 0.18065 train_metric : 0.92593 test_metric : 0.77743\n",
      "\n",
      " loss : 0.04479 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04479 test_loss : 0.17542 train_metric : 0.96296 test_metric : 0.77586\n",
      "\n",
      " loss : 0.09739 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09739 test_loss : 0.18148 train_metric : 0.88889 test_metric : 0.78683\n",
      "\n",
      " loss : 0.07938 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07938 test_loss : 0.17680 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.12966 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12966 test_loss : 0.17246 train_metric : 0.85185 test_metric : 0.77743\n",
      "\n",
      " loss : 0.16560 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16560 test_loss : 0.17512 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.21759 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.21759 test_loss : 0.18059 train_metric : 0.70370 test_metric : 0.77273\n",
      "\n",
      " loss : 0.12109 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12109 test_loss : 0.17308 train_metric : 0.85185 test_metric : 0.78213\n",
      "\n",
      " loss : 0.12047 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12047 test_loss : 0.17211 train_metric : 0.81481 test_metric : 0.77273\n",
      "\n",
      " loss : 0.09742 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09742 test_loss : 0.18684 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.11212 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11212 test_loss : 0.17239 train_metric : 0.85185 test_metric : 0.77900\n",
      "\n",
      " loss : 0.10121 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10121 test_loss : 0.18035 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.04706 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.04706 test_loss : 0.18775 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.11138 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11138 test_loss : 0.17896 train_metric : 0.85185 test_metric : 0.78056\n",
      "\n",
      " loss : 0.06323 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06323 test_loss : 0.17615 train_metric : 0.88889 test_metric : 0.77743\n",
      "\n",
      " loss : 0.06390 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06390 test_loss : 0.17585 train_metric : 0.92593 test_metric : 0.78370\n",
      "\n",
      " loss : 0.04023 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04023 test_loss : 0.18557 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.13555 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.13555 test_loss : 0.17392 train_metric : 0.74074 test_metric : 0.77116\n",
      "\n",
      " loss : 0.11681 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11681 test_loss : 0.17565 train_metric : 0.85185 test_metric : 0.78683\n",
      "\n",
      " loss : 0.15438 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15438 test_loss : 0.18113 train_metric : 0.77778 test_metric : 0.77116\n",
      "\n",
      " loss : 0.08341 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08341 test_loss : 0.17820 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07125 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.07125 test_loss : 0.17627 train_metric : 0.96296 test_metric : 0.76176\n",
      "\n",
      " loss : 0.06696 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06696 test_loss : 0.18677 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.13927 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.13927 test_loss : 0.17538 train_metric : 0.77778 test_metric : 0.77116\n",
      "\n",
      " loss : 0.08277 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08277 test_loss : 0.17475 train_metric : 0.85185 test_metric : 0.78213\n",
      "\n",
      " loss : 0.08541 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08541 test_loss : 0.18192 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.05817 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05817 test_loss : 0.17476 train_metric : 0.92593 test_metric : 0.77743\n",
      "\n",
      " loss : 0.10755 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10755 test_loss : 0.18626 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05611 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05611 test_loss : 0.17835 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.05211 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05211 test_loss : 0.17726 train_metric : 0.96296 test_metric : 0.77273\n",
      "\n",
      " loss : 0.05028 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.05028 test_loss : 0.18395 train_metric : 1.00000 test_metric : 0.76803\n",
      "\n",
      " loss : 0.20957 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20957 test_loss : 0.17542 train_metric : 0.74074 test_metric : 0.78370\n",
      "\n",
      " loss : 0.14006 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14006 test_loss : 0.17498 train_metric : 0.81481 test_metric : 0.77586\n",
      "\n",
      " loss : 0.05247 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05247 test_loss : 0.17904 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.08070 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08070 test_loss : 0.18330 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.11992 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11992 test_loss : 0.18319 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.09565 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09565 test_loss : 0.17662 train_metric : 0.85185 test_metric : 0.77116\n",
      "\n",
      " loss : 0.05792 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05792 test_loss : 0.17585 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.13494 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13494 test_loss : 0.18212 train_metric : 0.81481 test_metric : 0.77743\n",
      "\n",
      " loss : 0.17809 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.17809 test_loss : 0.17577 train_metric : 0.74074 test_metric : 0.77743\n",
      "\n",
      " loss : 0.08006 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08006 test_loss : 0.18148 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.03348 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03348 test_loss : 0.17394 train_metric : 0.96296 test_metric : 0.77429\n",
      "\n",
      " loss : 0.10388 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10388 test_loss : 0.17333 train_metric : 0.85185 test_metric : 0.77429\n",
      "\n",
      " loss : 0.03928 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03928 test_loss : 0.19061 train_metric : 0.96296 test_metric : 0.75235\n",
      "\n",
      " loss : 0.16411 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16411 test_loss : 0.17627 train_metric : 0.77778 test_metric : 0.78056\n",
      "\n",
      " loss : 0.06395 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06395 test_loss : 0.17880 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.04305 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.04305 test_loss : 0.18220 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.06402 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06402 test_loss : 0.18223 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.12946 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12946 test_loss : 0.18292 train_metric : 0.85185 test_metric : 0.77116\n",
      "\n",
      " loss : 0.02400 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02400 test_loss : 0.17747 train_metric : 1.00000 test_metric : 0.77743\n",
      "\n",
      " loss : 0.03903 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03903 test_loss : 0.18151 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.04747 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04747 test_loss : 0.17436 train_metric : 0.92593 test_metric : 0.78056\n",
      "\n",
      " loss : 0.04467 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04467 test_loss : 0.18455 train_metric : 0.96296 test_metric : 0.76176\n",
      "\n",
      " loss : 0.03285 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03285 test_loss : 0.18632 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05719 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05719 test_loss : 0.18580 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.06029 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06029 test_loss : 0.17933 train_metric : 0.92593 test_metric : 0.77429\n",
      "\n",
      " loss : 0.04399 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04399 test_loss : 0.18040 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.05318 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05318 test_loss : 0.19030 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.05015 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05015 test_loss : 0.18838 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.09995 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09995 test_loss : 0.18232 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.03388 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03388 test_loss : 0.18138 train_metric : 0.96296 test_metric : 0.78527\n",
      "\n",
      " loss : 0.07126 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07126 test_loss : 0.18877 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.07812 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07812 test_loss : 0.19091 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.07917 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07917 test_loss : 0.18848 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08403 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08403 test_loss : 0.18116 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.08099 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08099 test_loss : 0.18282 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.05253 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05253 test_loss : 0.18867 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.04494 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04494 test_loss : 0.18354 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08276 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08276 test_loss : 0.17969 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.17364 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17364 test_loss : 0.18369 train_metric : 0.77778 test_metric : 0.77116\n",
      "\n",
      " loss : 0.20543 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20543 test_loss : 0.17394 train_metric : 0.77778 test_metric : 0.78213\n",
      "\n",
      " loss : 0.12300 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12300 test_loss : 0.18593 train_metric : 0.85185 test_metric : 0.77116\n",
      "\n",
      " loss : 0.06771 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06771 test_loss : 0.18829 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.03977 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03977 test_loss : 0.18961 train_metric : 0.96296 test_metric : 0.77273\n",
      "\n",
      " loss : 0.10609 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10609 test_loss : 0.18821 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.04724 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04724 test_loss : 0.18605 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.08627 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08627 test_loss : 0.18099 train_metric : 0.88889 test_metric : 0.78840\n",
      "\n",
      " loss : 0.08285 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08285 test_loss : 0.18002 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.16728 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16728 test_loss : 0.19090 train_metric : 0.77778 test_metric : 0.75235\n",
      "\n",
      " loss : 0.08552 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08552 test_loss : 0.17855 train_metric : 0.88889 test_metric : 0.77586\n",
      "\n",
      " loss : 0.07760 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07760 test_loss : 0.18944 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.08465 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08465 test_loss : 0.18474 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.04176 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.04176 test_loss : 0.18993 train_metric : 1.00000 test_metric : 0.74608\n",
      "\n",
      " loss : 0.18752 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.18752 test_loss : 0.18975 train_metric : 0.70370 test_metric : 0.74608\n",
      "\n",
      " loss : 0.07702 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07702 test_loss : 0.18543 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.04721 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04721 test_loss : 0.19433 train_metric : 0.96296 test_metric : 0.73824\n",
      "\n",
      " loss : 0.12563 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12563 test_loss : 0.18343 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.04620 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04620 test_loss : 0.18398 train_metric : 0.92593 test_metric : 0.77429\n",
      "\n",
      " loss : 0.11106 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11106 test_loss : 0.19458 train_metric : 0.85185 test_metric : 0.74922\n",
      "\n",
      " loss : 0.06774 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06774 test_loss : 0.18684 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05074 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05074 test_loss : 0.18875 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.04861 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04861 test_loss : 0.18121 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.08103 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08103 test_loss : 0.19059 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.17145 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17145 test_loss : 0.18582 train_metric : 0.77778 test_metric : 0.77116\n",
      "\n",
      " loss : 0.11405 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11405 test_loss : 0.18613 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.11759 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11759 test_loss : 0.18495 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.04436 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04436 test_loss : 0.17928 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.26239 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.26239 test_loss : 0.18452 train_metric : 0.66667 test_metric : 0.75862\n",
      "\n",
      " loss : 0.07168 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07168 test_loss : 0.19006 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.10356 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10356 test_loss : 0.18728 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.12735 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.12735 test_loss : 0.18503 train_metric : 0.77778 test_metric : 0.75705\n",
      "\n",
      " loss : 0.04409 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04409 test_loss : 0.18671 train_metric : 0.96296 test_metric : 0.75235\n",
      "\n",
      " loss : 0.15941 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15941 test_loss : 0.18731 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.15151 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15151 test_loss : 0.19579 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.04340 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04340 test_loss : 0.19046 train_metric : 0.96296 test_metric : 0.76176\n",
      "\n",
      " loss : 0.02731 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02731 test_loss : 0.18700 train_metric : 1.00000 test_metric : 0.76803\n",
      "\n",
      " loss : 0.07667 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07667 test_loss : 0.18265 train_metric : 0.88889 test_metric : 0.77586\n",
      "\n",
      " loss : 0.08500 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08500 test_loss : 0.18524 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.07671 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07671 test_loss : 0.17889 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.17333 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.17333 test_loss : 0.18615 train_metric : 0.74074 test_metric : 0.76489\n",
      "\n",
      " loss : 0.12632 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12632 test_loss : 0.18681 train_metric : 0.81481 test_metric : 0.75705\n",
      "\n",
      " loss : 0.06449 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06449 test_loss : 0.18517 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.08090 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08090 test_loss : 0.18154 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.05923 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05923 test_loss : 0.18168 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07013 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07013 test_loss : 0.19329 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.04985 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04985 test_loss : 0.19539 train_metric : 0.96296 test_metric : 0.74451\n",
      "\n",
      " loss : 0.06828 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06828 test_loss : 0.20381 train_metric : 0.96296 test_metric : 0.74922\n",
      "\n",
      " loss : 0.07267 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07267 test_loss : 0.19191 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.12075 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12075 test_loss : 0.18684 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.09354 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09354 test_loss : 0.19006 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.11353 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11353 test_loss : 0.18286 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.04734 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04734 test_loss : 0.19286 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.10293 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10293 test_loss : 0.18866 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05937 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05937 test_loss : 0.19254 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.11663 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11663 test_loss : 0.18849 train_metric : 0.81481 test_metric : 0.75078\n",
      "\n",
      " loss : 0.22083 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.22083 test_loss : 0.18797 train_metric : 0.74074 test_metric : 0.76176\n",
      "\n",
      " loss : 0.14470 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14470 test_loss : 0.18405 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.13281 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13281 test_loss : 0.19279 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.07768 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07768 test_loss : 0.18317 train_metric : 0.88889 test_metric : 0.77429\n",
      "\n",
      " loss : 0.11924 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11924 test_loss : 0.18726 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10679 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10679 test_loss : 0.18580 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.08654 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08654 test_loss : 0.18437 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.11709 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11709 test_loss : 0.19814 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.10338 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10338 test_loss : 0.19545 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.12335 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.12335 test_loss : 0.18322 train_metric : 0.77778 test_metric : 0.76803\n",
      "\n",
      " loss : 0.09133 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09133 test_loss : 0.18956 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.09350 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09350 test_loss : 0.18178 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.13176 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13176 test_loss : 0.19176 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10057 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10057 test_loss : 0.18306 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.15899 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15899 test_loss : 0.20261 train_metric : 0.81481 test_metric : 0.72884\n",
      "\n",
      " loss : 0.07305 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07305 test_loss : 0.18787 train_metric : 0.88889 test_metric : 0.77116\n",
      "\n",
      " loss : 0.10200 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10200 test_loss : 0.19100 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.06202 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06202 test_loss : 0.19303 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08087 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08087 test_loss : 0.18612 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.06570 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06570 test_loss : 0.18420 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.08456 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08456 test_loss : 0.18513 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.03362 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03362 test_loss : 0.18272 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.04815 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04815 test_loss : 0.19189 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.07933 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07933 test_loss : 0.19635 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.07353 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07353 test_loss : 0.18613 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.16923 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16923 test_loss : 0.19946 train_metric : 0.81481 test_metric : 0.75078\n",
      "\n",
      " loss : 0.08502 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08502 test_loss : 0.18124 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.06754 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06754 test_loss : 0.18897 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.08401 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08401 test_loss : 0.19149 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.05455 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05455 test_loss : 0.18715 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.09234 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09234 test_loss : 0.18934 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.06380 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06380 test_loss : 0.18620 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07118 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07118 test_loss : 0.19037 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.12608 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12608 test_loss : 0.19181 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.08233 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08233 test_loss : 0.18896 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08216 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08216 test_loss : 0.18517 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.16990 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16990 test_loss : 0.18525 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.00728 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00728 test_loss : 0.18677 train_metric : 1.00000 test_metric : 0.75705\n",
      "\n",
      " loss : 0.02289 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02289 test_loss : 0.18819 train_metric : 0.96296 test_metric : 0.76803\n",
      "\n",
      " loss : 0.12738 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12738 test_loss : 0.17160 train_metric : 0.85185 test_metric : 0.78683\n",
      "\n",
      " loss : 0.04281 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04281 test_loss : 0.17374 train_metric : 0.96296 test_metric : 0.77273\n",
      "\n",
      " loss : 0.08067 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08067 test_loss : 0.18424 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.02035 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02035 test_loss : 0.17939 train_metric : 0.96296 test_metric : 0.77743\n",
      "\n",
      " loss : 0.10044 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10044 test_loss : 0.19112 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.04521 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04521 test_loss : 0.19155 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.04988 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04988 test_loss : 0.19158 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08434 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08434 test_loss : 0.18745 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.16421 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16421 test_loss : 0.18335 train_metric : 0.81481 test_metric : 0.76959\n",
      "\n",
      " loss : 0.09439 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09439 test_loss : 0.19139 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.10514 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10514 test_loss : 0.17813 train_metric : 0.85185 test_metric : 0.77586\n",
      "\n",
      " loss : 0.09949 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09949 test_loss : 0.18878 train_metric : 0.88889 test_metric : 0.74451\n",
      "\n",
      " loss : 0.09874 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09874 test_loss : 0.18194 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.15184 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15184 test_loss : 0.18063 train_metric : 0.81481 test_metric : 0.76959\n",
      "\n",
      " loss : 0.06543 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06543 test_loss : 0.18501 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.00986 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00986 test_loss : 0.18790 train_metric : 1.00000 test_metric : 0.76646\n",
      "\n",
      " loss : 0.04025 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04025 test_loss : 0.18994 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.09168 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09168 test_loss : 0.18060 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.15358 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15358 test_loss : 0.18402 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.14085 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14085 test_loss : 0.18462 train_metric : 0.77778 test_metric : 0.76646\n",
      "\n",
      " loss : 0.17905 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17905 test_loss : 0.19255 train_metric : 0.77778 test_metric : 0.74765\n",
      "\n",
      " loss : 0.07510 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07510 test_loss : 0.18208 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.16642 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.16642 test_loss : 0.18950 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.09179 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09179 test_loss : 0.19073 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.17730 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.17730 test_loss : 0.18482 train_metric : 0.74074 test_metric : 0.77116\n",
      "\n",
      " loss : 0.13579 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13579 test_loss : 0.18587 train_metric : 0.85185 test_metric : 0.77743\n",
      "\n",
      " loss : 0.09147 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09147 test_loss : 0.18432 train_metric : 0.92593 test_metric : 0.77429\n",
      "\n",
      " loss : 0.09375 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09375 test_loss : 0.18758 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.07426 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07426 test_loss : 0.18387 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10987 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10987 test_loss : 0.18418 train_metric : 0.81481 test_metric : 0.77273\n",
      "\n",
      " loss : 0.01550 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01550 test_loss : 0.18885 train_metric : 1.00000 test_metric : 0.75862\n",
      "\n",
      " loss : 0.10252 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10252 test_loss : 0.18507 train_metric : 0.81481 test_metric : 0.76803\n",
      "\n",
      " loss : 0.08785 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08785 test_loss : 0.18192 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.10279 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10279 test_loss : 0.19517 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.08145 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08145 test_loss : 0.18637 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10799 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10799 test_loss : 0.17953 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.09156 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09156 test_loss : 0.18514 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08174 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08174 test_loss : 0.19021 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.08998 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08998 test_loss : 0.19318 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.02183 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02183 test_loss : 0.19196 train_metric : 1.00000 test_metric : 0.75235\n",
      "\n",
      " loss : 0.12952 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12952 test_loss : 0.17833 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.15621 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15621 test_loss : 0.18717 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05430 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05430 test_loss : 0.19314 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.05631 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05631 test_loss : 0.18804 train_metric : 0.96296 test_metric : 0.76176\n",
      "\n",
      " loss : 0.06673 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06673 test_loss : 0.19432 train_metric : 0.88889 test_metric : 0.73354\n",
      "\n",
      " loss : 0.07149 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07149 test_loss : 0.19120 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.10411 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10411 test_loss : 0.18581 train_metric : 0.81481 test_metric : 0.76332\n",
      "\n",
      " loss : 0.21083 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.21083 test_loss : 0.19414 train_metric : 0.70370 test_metric : 0.73668\n",
      "\n",
      " loss : 0.09676 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09676 test_loss : 0.19534 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.08580 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08580 test_loss : 0.17824 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.12163 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12163 test_loss : 0.18337 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.12174 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12174 test_loss : 0.18166 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.09141 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09141 test_loss : 0.19265 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.02680 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02680 test_loss : 0.18655 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.13464 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13464 test_loss : 0.18590 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.07454 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07454 test_loss : 0.18925 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.08377 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08377 test_loss : 0.18570 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.05259 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05259 test_loss : 0.18137 train_metric : 0.92593 test_metric : 0.77743\n",
      "\n",
      " loss : 0.09068 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09068 test_loss : 0.19061 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07909 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07909 test_loss : 0.18613 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.04643 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04643 test_loss : 0.18561 train_metric : 0.96296 test_metric : 0.76959\n",
      "\n",
      " loss : 0.05384 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05384 test_loss : 0.18044 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09797 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09797 test_loss : 0.18618 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.08493 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08493 test_loss : 0.19445 train_metric : 0.88889 test_metric : 0.74608\n",
      "\n",
      " loss : 0.02927 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02927 test_loss : 0.19260 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05268 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05268 test_loss : 0.18910 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.11743 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11743 test_loss : 0.19019 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.03465 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03465 test_loss : 0.18362 train_metric : 0.96296 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08620 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08620 test_loss : 0.19437 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.03952 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03952 test_loss : 0.18903 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.05231 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05231 test_loss : 0.18322 train_metric : 0.92593 test_metric : 0.77429\n",
      "\n",
      " loss : 0.05959 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05959 test_loss : 0.19243 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.05172 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05172 test_loss : 0.18509 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.06601 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06601 test_loss : 0.19211 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.03435 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03435 test_loss : 0.19274 train_metric : 0.96296 test_metric : 0.74608\n",
      "\n",
      " loss : 0.06575 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06575 test_loss : 0.18903 train_metric : 0.92593 test_metric : 0.74608\n",
      "\n",
      " loss : 0.07446 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07446 test_loss : 0.19118 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.11067 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11067 test_loss : 0.17777 train_metric : 0.88889 test_metric : 0.77586\n",
      "\n",
      " loss : 0.12571 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12571 test_loss : 0.20197 train_metric : 0.85185 test_metric : 0.73668\n",
      "\n",
      " loss : 0.11396 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11396 test_loss : 0.19824 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.11617 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11617 test_loss : 0.19452 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.12597 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12597 test_loss : 0.19615 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.03264 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03264 test_loss : 0.19322 train_metric : 1.00000 test_metric : 0.76019\n",
      "\n",
      " loss : 0.03631 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03631 test_loss : 0.18942 train_metric : 1.00000 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08491 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08491 test_loss : 0.18504 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.06504 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06504 test_loss : 0.18061 train_metric : 0.92593 test_metric : 0.77429\n",
      "\n",
      " loss : 0.05685 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05685 test_loss : 0.18725 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.11922 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11922 test_loss : 0.19210 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.02012 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02012 test_loss : 0.18205 train_metric : 1.00000 test_metric : 0.77743\n",
      "\n",
      " loss : 0.08900 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08900 test_loss : 0.19235 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.11501 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11501 test_loss : 0.18997 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.09962 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09962 test_loss : 0.19555 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.03942 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03942 test_loss : 0.18302 train_metric : 0.92593 test_metric : 0.77429\n",
      "\n",
      " loss : 0.01438 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01438 test_loss : 0.20448 train_metric : 1.00000 test_metric : 0.73668\n",
      "\n",
      " loss : 0.14876 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14876 test_loss : 0.18671 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.09141 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09141 test_loss : 0.19061 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.09201 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09201 test_loss : 0.18361 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.07653 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07653 test_loss : 0.19261 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.09413 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09413 test_loss : 0.19631 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.02698 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02698 test_loss : 0.19812 train_metric : 0.96296 test_metric : 0.74295\n",
      "\n",
      " loss : 0.06718 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06718 test_loss : 0.19076 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.14924 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14924 test_loss : 0.19581 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.08511 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08511 test_loss : 0.19132 train_metric : 0.88889 test_metric : 0.74451\n",
      "\n",
      " loss : 0.08058 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08058 test_loss : 0.18517 train_metric : 0.88889 test_metric : 0.77116\n",
      "\n",
      " loss : 0.16965 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16965 test_loss : 0.18467 train_metric : 0.81481 test_metric : 0.76959\n",
      "\n",
      " loss : 0.09283 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09283 test_loss : 0.19008 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.13580 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13580 test_loss : 0.19000 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.11687 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11687 test_loss : 0.18635 train_metric : 0.85185 test_metric : 0.78370\n",
      "\n",
      " loss : 0.11233 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11233 test_loss : 0.18300 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.20309 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20309 test_loss : 0.17724 train_metric : 0.77778 test_metric : 0.76489\n",
      "\n",
      " loss : 0.08775 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08775 test_loss : 0.18610 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.06436 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06436 test_loss : 0.19472 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.14643 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14643 test_loss : 0.18274 train_metric : 0.77778 test_metric : 0.76489\n",
      "\n",
      " loss : 0.03596 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03596 test_loss : 0.18130 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.01883 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01883 test_loss : 0.18336 train_metric : 0.96296 test_metric : 0.77273\n",
      "\n",
      " loss : 0.10216 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10216 test_loss : 0.19006 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.13742 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.13742 test_loss : 0.18311 train_metric : 0.77778 test_metric : 0.77429\n",
      "\n",
      " loss : 0.15130 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15130 test_loss : 0.18347 train_metric : 0.77778 test_metric : 0.76019\n",
      "\n",
      " loss : 0.10787 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10787 test_loss : 0.19294 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.07631 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07631 test_loss : 0.18355 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.03721 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03721 test_loss : 0.17981 train_metric : 0.92593 test_metric : 0.77743\n",
      "\n",
      " loss : 0.15989 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.15989 test_loss : 0.17763 train_metric : 0.74074 test_metric : 0.77900\n",
      "\n",
      " loss : 0.00724 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00724 test_loss : 0.18973 train_metric : 1.00000 test_metric : 0.75549\n",
      "\n",
      " loss : 0.06719 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06719 test_loss : 0.17968 train_metric : 0.92593 test_metric : 0.78683\n",
      "\n",
      " loss : 0.01348 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01348 test_loss : 0.18075 train_metric : 1.00000 test_metric : 0.76959\n",
      "\n",
      " loss : 0.10221 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10221 test_loss : 0.18763 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.07025 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07025 test_loss : 0.20066 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.14614 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14614 test_loss : 0.19340 train_metric : 0.77778 test_metric : 0.76332\n",
      "\n",
      " loss : 0.20696 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20696 test_loss : 0.18688 train_metric : 0.74074 test_metric : 0.76803\n",
      "\n",
      " loss : 0.12187 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12187 test_loss : 0.18368 train_metric : 0.81481 test_metric : 0.77273\n",
      "\n",
      " loss : 0.08693 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08693 test_loss : 0.18590 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.07808 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07808 test_loss : 0.18783 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.05741 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05741 test_loss : 0.18058 train_metric : 0.92593 test_metric : 0.78213\n",
      "\n",
      " loss : 0.08068 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08068 test_loss : 0.18892 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.07998 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07998 test_loss : 0.18023 train_metric : 0.92593 test_metric : 0.77900\n",
      "\n",
      " loss : 0.10185 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10185 test_loss : 0.19046 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.03701 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03701 test_loss : 0.19294 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.05480 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05480 test_loss : 0.18137 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.06424 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06424 test_loss : 0.18912 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.13738 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13738 test_loss : 0.19392 train_metric : 0.81481 test_metric : 0.74608\n",
      "\n",
      " loss : 0.07238 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07238 test_loss : 0.18470 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.08161 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08161 test_loss : 0.19610 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.08242 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08242 test_loss : 0.19119 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.08744 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08744 test_loss : 0.18108 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.06611 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06611 test_loss : 0.19555 train_metric : 0.88889 test_metric : 0.74295\n",
      "\n",
      " loss : 0.06715 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06715 test_loss : 0.18838 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.12867 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12867 test_loss : 0.18994 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.13737 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13737 test_loss : 0.17713 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.20262 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20262 test_loss : 0.19888 train_metric : 0.74074 test_metric : 0.74295\n",
      "\n",
      " loss : 0.11950 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11950 test_loss : 0.18662 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.17352 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.17352 test_loss : 0.18170 train_metric : 0.74074 test_metric : 0.77429\n",
      "\n",
      " loss : 0.08375 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08375 test_loss : 0.19140 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.04347 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04347 test_loss : 0.18781 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.06764 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06764 test_loss : 0.18718 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.07610 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07610 test_loss : 0.18527 train_metric : 0.92593 test_metric : 0.77586\n",
      "\n",
      " loss : 0.14484 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14484 test_loss : 0.18781 train_metric : 0.81481 test_metric : 0.76646\n",
      "\n",
      " loss : 0.08386 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08386 test_loss : 0.19294 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.04940 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04940 test_loss : 0.18554 train_metric : 0.96296 test_metric : 0.77273\n",
      "\n",
      " loss : 0.02866 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02866 test_loss : 0.19639 train_metric : 1.00000 test_metric : 0.74922\n",
      "\n",
      " loss : 0.09634 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09634 test_loss : 0.18134 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.09700 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09700 test_loss : 0.18587 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.02660 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.02660 test_loss : 0.19035 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.03146 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03146 test_loss : 0.19008 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.10276 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10276 test_loss : 0.18976 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05408 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05408 test_loss : 0.19409 train_metric : 0.96296 test_metric : 0.75078\n",
      "\n",
      " loss : 0.10304 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10304 test_loss : 0.19529 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.07149 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07149 test_loss : 0.18779 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.07988 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07988 test_loss : 0.19097 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.03329 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03329 test_loss : 0.19064 train_metric : 0.96296 test_metric : 0.76959\n",
      "\n",
      " loss : 0.06985 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06985 test_loss : 0.19077 train_metric : 0.88889 test_metric : 0.74608\n",
      "\n",
      " loss : 0.08226 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08226 test_loss : 0.19085 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05354 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05354 test_loss : 0.19259 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.06872 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06872 test_loss : 0.18658 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.16335 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16335 test_loss : 0.18855 train_metric : 0.81481 test_metric : 0.76019\n",
      "\n",
      " loss : 0.12729 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12729 test_loss : 0.18677 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.06791 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06791 test_loss : 0.19221 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.11926 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11926 test_loss : 0.20080 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.07453 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07453 test_loss : 0.19898 train_metric : 0.92593 test_metric : 0.74608\n",
      "\n",
      " loss : 0.04558 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04558 test_loss : 0.19165 train_metric : 0.96296 test_metric : 0.75235\n",
      "\n",
      " loss : 0.02807 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02807 test_loss : 0.19114 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.09010 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09010 test_loss : 0.18992 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.10724 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10724 test_loss : 0.19232 train_metric : 0.88889 test_metric : 0.74138\n",
      "\n",
      " loss : 0.16786 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.16786 test_loss : 0.19518 train_metric : 0.70370 test_metric : 0.74765\n",
      "\n",
      " loss : 0.18719 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18719 test_loss : 0.19873 train_metric : 0.77778 test_metric : 0.74922\n",
      "\n",
      " loss : 0.16144 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16144 test_loss : 0.19818 train_metric : 0.81481 test_metric : 0.74922\n",
      "\n",
      " loss : 0.08817 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08817 test_loss : 0.18356 train_metric : 0.85185 test_metric : 0.77273\n",
      "\n",
      " loss : 0.05120 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05120 test_loss : 0.18285 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.08631 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08631 test_loss : 0.18797 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.13134 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13134 test_loss : 0.19321 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.11477 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11477 test_loss : 0.17706 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.05862 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05862 test_loss : 0.19071 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.11687 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11687 test_loss : 0.18045 train_metric : 0.88889 test_metric : 0.77743\n",
      "\n",
      " loss : 0.13928 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13928 test_loss : 0.18316 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.12500 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12500 test_loss : 0.18590 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09790 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09790 test_loss : 0.19774 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.07797 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07797 test_loss : 0.19148 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.14355 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14355 test_loss : 0.18382 train_metric : 0.77778 test_metric : 0.75705\n",
      "\n",
      " loss : 0.02362 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02362 test_loss : 0.18054 train_metric : 0.96296 test_metric : 0.76803\n",
      "\n",
      " loss : 0.08713 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08713 test_loss : 0.18632 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.07426 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07426 test_loss : 0.18890 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.06949 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06949 test_loss : 0.19969 train_metric : 0.88889 test_metric : 0.73824\n",
      "\n",
      " loss : 0.06903 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06903 test_loss : 0.19389 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.05408 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05408 test_loss : 0.20022 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.09617 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09617 test_loss : 0.18468 train_metric : 0.85185 test_metric : 0.78213\n",
      "\n",
      " loss : 0.04973 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04973 test_loss : 0.19652 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.04385 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.04385 test_loss : 0.19080 train_metric : 1.00000 test_metric : 0.76489\n",
      "\n",
      " loss : 0.08039 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08039 test_loss : 0.19688 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.07049 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07049 test_loss : 0.18328 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.07399 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07399 test_loss : 0.19804 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.07247 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07247 test_loss : 0.19043 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.05458 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05458 test_loss : 0.18397 train_metric : 0.96296 test_metric : 0.78213\n",
      "\n",
      " loss : 0.15397 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15397 test_loss : 0.19656 train_metric : 0.81481 test_metric : 0.75862\n",
      "\n",
      " loss : 0.13792 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13792 test_loss : 0.18399 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.08304 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08304 test_loss : 0.19595 train_metric : 0.92593 test_metric : 0.74295\n",
      "\n",
      " loss : 0.17843 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17843 test_loss : 0.19511 train_metric : 0.81481 test_metric : 0.76332\n",
      "\n",
      " loss : 0.16321 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16321 test_loss : 0.19310 train_metric : 0.74074 test_metric : 0.75705\n",
      "\n",
      " loss : 0.07379 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07379 test_loss : 0.18807 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.06699 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06699 test_loss : 0.18243 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.11010 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11010 test_loss : 0.19580 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.10555 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10555 test_loss : 0.17827 train_metric : 0.88889 test_metric : 0.77900\n",
      "\n",
      " loss : 0.07541 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07541 test_loss : 0.19406 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.05817 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05817 test_loss : 0.19374 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09048 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09048 test_loss : 0.20406 train_metric : 0.88889 test_metric : 0.74138\n",
      "\n",
      " loss : 0.06714 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06714 test_loss : 0.20433 train_metric : 0.88889 test_metric : 0.73981\n",
      "\n",
      " loss : 0.09958 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09958 test_loss : 0.20535 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.04540 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04540 test_loss : 0.19597 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.14820 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14820 test_loss : 0.19085 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.11341 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11341 test_loss : 0.19514 train_metric : 0.85185 test_metric : 0.74295\n",
      "\n",
      " loss : 0.08370 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08370 test_loss : 0.18975 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.14916 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14916 test_loss : 0.18687 train_metric : 0.77778 test_metric : 0.76332\n",
      "\n",
      " loss : 0.10943 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10943 test_loss : 0.18181 train_metric : 0.85185 test_metric : 0.78213\n",
      "\n",
      " loss : 0.02803 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02803 test_loss : 0.18300 train_metric : 1.00000 test_metric : 0.77429\n",
      "\n",
      " loss : 0.07159 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07159 test_loss : 0.18237 train_metric : 0.88889 test_metric : 0.77429\n",
      "\n",
      " loss : 0.05676 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05676 test_loss : 0.19191 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.10478 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10478 test_loss : 0.19619 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.09790 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09790 test_loss : 0.19639 train_metric : 0.92593 test_metric : 0.75235\n",
      "\n",
      " loss : 0.18917 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18917 test_loss : 0.19947 train_metric : 0.74074 test_metric : 0.74608\n",
      "\n",
      " loss : 0.11248 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11248 test_loss : 0.18280 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.22738 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.22738 test_loss : 0.18042 train_metric : 0.74074 test_metric : 0.77586\n",
      "\n",
      " loss : 0.11302 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11302 test_loss : 0.18916 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.13470 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13470 test_loss : 0.17768 train_metric : 0.85185 test_metric : 0.77273\n",
      "\n",
      " loss : 0.03498 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03498 test_loss : 0.18240 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.03960 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03960 test_loss : 0.18286 train_metric : 0.96296 test_metric : 0.77743\n",
      "\n",
      " loss : 0.13940 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13940 test_loss : 0.18457 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.08304 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08304 test_loss : 0.19873 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.12934 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12934 test_loss : 0.18746 train_metric : 0.81481 test_metric : 0.77116\n",
      "\n",
      " loss : 0.09250 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09250 test_loss : 0.19238 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.06360 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06360 test_loss : 0.19581 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.05837 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05837 test_loss : 0.18779 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.06337 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06337 test_loss : 0.20873 train_metric : 0.92593 test_metric : 0.74608\n",
      "\n",
      " loss : 0.09338 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09338 test_loss : 0.18656 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.19874 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19874 test_loss : 0.19568 train_metric : 0.77778 test_metric : 0.75078\n",
      "\n",
      " loss : 0.01779 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01779 test_loss : 0.19850 train_metric : 1.00000 test_metric : 0.76019\n",
      "\n",
      " loss : 0.05275 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05275 test_loss : 0.20279 train_metric : 0.96296 test_metric : 0.74765\n",
      "\n",
      " loss : 0.06883 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06883 test_loss : 0.19633 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.15559 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15559 test_loss : 0.18760 train_metric : 0.77778 test_metric : 0.76646\n",
      "\n",
      " loss : 0.11837 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11837 test_loss : 0.18727 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.13536 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13536 test_loss : 0.18311 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.06917 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06917 test_loss : 0.19121 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.02748 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02748 test_loss : 0.18837 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.09676 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09676 test_loss : 0.18375 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.03175 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03175 test_loss : 0.18885 train_metric : 0.96296 test_metric : 0.75235\n",
      "\n",
      " loss : 0.11024 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11024 test_loss : 0.18862 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.03450 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03450 test_loss : 0.19534 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.20314 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20314 test_loss : 0.19292 train_metric : 0.77778 test_metric : 0.75862\n",
      "\n",
      " loss : 0.04687 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04687 test_loss : 0.19480 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.21385 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.21385 test_loss : 0.19637 train_metric : 0.74074 test_metric : 0.75235\n",
      "\n",
      " loss : 0.15281 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15281 test_loss : 0.17673 train_metric : 0.85185 test_metric : 0.77900\n",
      "\n",
      " loss : 0.07339 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07339 test_loss : 0.19611 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.09639 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09639 test_loss : 0.19209 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.11235 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11235 test_loss : 0.18864 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.16524 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16524 test_loss : 0.18908 train_metric : 0.77778 test_metric : 0.75705\n",
      "\n",
      " loss : 0.12205 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12205 test_loss : 0.19592 train_metric : 0.81481 test_metric : 0.75705\n",
      "\n",
      " loss : 0.06973 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06973 test_loss : 0.19230 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.03701 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03701 test_loss : 0.19873 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.08547 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08547 test_loss : 0.19679 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.13835 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13835 test_loss : 0.20162 train_metric : 0.81481 test_metric : 0.74765\n",
      "\n",
      " loss : 0.14969 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14969 test_loss : 0.20522 train_metric : 0.81481 test_metric : 0.74295\n",
      "\n",
      " loss : 0.12642 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12642 test_loss : 0.20333 train_metric : 0.88889 test_metric : 0.74138\n",
      "\n",
      " loss : 0.03471 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03471 test_loss : 0.19671 train_metric : 0.96296 test_metric : 0.74765\n",
      "\n",
      " loss : 0.05713 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05713 test_loss : 0.20636 train_metric : 0.96296 test_metric : 0.73197\n",
      "\n",
      " loss : 0.22515 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.22515 test_loss : 0.19329 train_metric : 0.74074 test_metric : 0.75862\n",
      "\n",
      " loss : 0.06883 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06883 test_loss : 0.19324 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.08387 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08387 test_loss : 0.18617 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.04782 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04782 test_loss : 0.19629 train_metric : 0.96296 test_metric : 0.74451\n",
      "\n",
      " loss : 0.10176 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10176 test_loss : 0.20161 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.03724 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03724 test_loss : 0.18432 train_metric : 1.00000 test_metric : 0.77429\n",
      "\n",
      " loss : 0.05156 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05156 test_loss : 0.20082 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.17470 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17470 test_loss : 0.19810 train_metric : 0.77778 test_metric : 0.74765\n",
      "\n",
      " loss : 0.10165 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10165 test_loss : 0.18613 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.18467 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18467 test_loss : 0.19292 train_metric : 0.74074 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08168 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08168 test_loss : 0.19330 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.12661 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12661 test_loss : 0.20150 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.10416 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.10416 test_loss : 0.19606 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.03842 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03842 test_loss : 0.18898 train_metric : 0.96296 test_metric : 0.78056\n",
      "\n",
      " loss : 0.16795 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16795 test_loss : 0.18482 train_metric : 0.74074 test_metric : 0.75235\n",
      "\n",
      " loss : 0.02109 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02109 test_loss : 0.19800 train_metric : 1.00000 test_metric : 0.75862\n",
      "\n",
      " loss : 0.16349 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16349 test_loss : 0.19020 train_metric : 0.74074 test_metric : 0.75392\n",
      "\n",
      " loss : 0.12050 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12050 test_loss : 0.19220 train_metric : 0.81481 test_metric : 0.76332\n",
      "\n",
      " loss : 0.10173 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10173 test_loss : 0.19321 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.04956 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04956 test_loss : 0.19531 train_metric : 0.96296 test_metric : 0.74765\n",
      "\n",
      " loss : 0.16558 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16558 test_loss : 0.18961 train_metric : 0.77778 test_metric : 0.76019\n",
      "\n",
      " loss : 0.05978 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05978 test_loss : 0.18120 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.08136 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08136 test_loss : 0.18193 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.09088 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09088 test_loss : 0.18909 train_metric : 0.88889 test_metric : 0.77429\n",
      "\n",
      " loss : 0.13311 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13311 test_loss : 0.18765 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.23206 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.23206 test_loss : 0.18956 train_metric : 0.74074 test_metric : 0.76332\n",
      "\n",
      " loss : 0.10157 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10157 test_loss : 0.19334 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07265 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.07265 test_loss : 0.20332 train_metric : 0.81481 test_metric : 0.75862\n",
      "\n",
      " loss : 0.09192 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09192 test_loss : 0.18973 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.10810 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10810 test_loss : 0.20903 train_metric : 0.85185 test_metric : 0.73197\n",
      "\n",
      " loss : 0.03457 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03457 test_loss : 0.20259 train_metric : 0.96296 test_metric : 0.74451\n",
      "\n",
      " loss : 0.07699 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07699 test_loss : 0.20485 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.13362 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13362 test_loss : 0.19311 train_metric : 0.81481 test_metric : 0.76019\n",
      "\n",
      " loss : 0.05479 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05479 test_loss : 0.19568 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.09725 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09725 test_loss : 0.19641 train_metric : 0.85185 test_metric : 0.74608\n",
      "\n",
      " loss : 0.07226 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07226 test_loss : 0.19675 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.08518 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08518 test_loss : 0.18716 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.04961 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04961 test_loss : 0.19755 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.12558 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.12558 test_loss : 0.19131 train_metric : 0.77778 test_metric : 0.75549\n",
      "\n",
      " loss : 0.16553 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16553 test_loss : 0.20229 train_metric : 0.81481 test_metric : 0.75235\n",
      "\n",
      " loss : 0.09534 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09534 test_loss : 0.18438 train_metric : 0.92593 test_metric : 0.77743\n",
      "\n",
      " loss : 0.07499 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07499 test_loss : 0.19688 train_metric : 0.92593 test_metric : 0.75235\n",
      "\n",
      " loss : 0.10568 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10568 test_loss : 0.18682 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.01960 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01960 test_loss : 0.19650 train_metric : 0.96296 test_metric : 0.75078\n",
      "\n",
      " loss : 0.11857 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11857 test_loss : 0.19206 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.06470 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06470 test_loss : 0.19132 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.12489 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12489 test_loss : 0.18831 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.03857 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03857 test_loss : 0.18969 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.11877 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11877 test_loss : 0.18838 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.05824 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05824 test_loss : 0.19253 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.18773 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18773 test_loss : 0.19326 train_metric : 0.77778 test_metric : 0.75235\n",
      "\n",
      " loss : 0.19642 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.19642 test_loss : 0.19091 train_metric : 0.81481 test_metric : 0.75235\n",
      "\n",
      " loss : 0.09625 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09625 test_loss : 0.19027 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.11352 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11352 test_loss : 0.19202 train_metric : 0.81481 test_metric : 0.76332\n",
      "\n",
      " loss : 0.14487 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.14487 test_loss : 0.19580 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.07536 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07536 test_loss : 0.19146 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.12431 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12431 test_loss : 0.19225 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.13359 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13359 test_loss : 0.19353 train_metric : 0.81481 test_metric : 0.75705\n",
      "\n",
      " loss : 0.13355 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13355 test_loss : 0.18402 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.03964 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03964 test_loss : 0.19207 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.02523 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02523 test_loss : 0.19692 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.01336 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01336 test_loss : 0.18061 train_metric : 1.00000 test_metric : 0.76646\n",
      "\n",
      " loss : 0.10739 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10739 test_loss : 0.18894 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.12763 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12763 test_loss : 0.18389 train_metric : 0.85185 test_metric : 0.77116\n",
      "\n",
      " loss : 0.14617 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14617 test_loss : 0.19694 train_metric : 0.85185 test_metric : 0.74295\n",
      "\n",
      " loss : 0.16634 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16634 test_loss : 0.18975 train_metric : 0.77778 test_metric : 0.75392\n",
      "\n",
      " loss : 0.08538 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08538 test_loss : 0.19283 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.15162 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15162 test_loss : 0.18203 train_metric : 0.81481 test_metric : 0.77116\n",
      "\n",
      " loss : 0.04816 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.04816 test_loss : 0.19372 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.18206 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18206 test_loss : 0.18274 train_metric : 0.77778 test_metric : 0.77429\n",
      "\n",
      " loss : 0.12964 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12964 test_loss : 0.18329 train_metric : 0.85185 test_metric : 0.78056\n",
      "\n",
      " loss : 0.24930 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.24930 test_loss : 0.19130 train_metric : 0.74074 test_metric : 0.75078\n",
      "\n",
      " loss : 0.01692 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01692 test_loss : 0.18333 train_metric : 1.00000 test_metric : 0.77586\n",
      "\n",
      " loss : 0.12704 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12704 test_loss : 0.18321 train_metric : 0.85185 test_metric : 0.77429\n",
      "\n",
      " loss : 0.10429 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.10429 test_loss : 0.17788 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.08754 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08754 test_loss : 0.19203 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.05400 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05400 test_loss : 0.20620 train_metric : 0.88889 test_metric : 0.74765\n",
      "\n",
      " loss : 0.02877 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02877 test_loss : 0.18456 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.02322 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02322 test_loss : 0.19213 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.04664 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04664 test_loss : 0.18239 train_metric : 0.96296 test_metric : 0.76803\n",
      "\n",
      " loss : 0.06286 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06286 test_loss : 0.19344 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.09446 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09446 test_loss : 0.20379 train_metric : 0.88889 test_metric : 0.74765\n",
      "\n",
      " loss : 0.05407 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05407 test_loss : 0.19198 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.16952 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16952 test_loss : 0.18872 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.18255 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18255 test_loss : 0.19019 train_metric : 0.74074 test_metric : 0.76332\n",
      "\n",
      " loss : 0.10390 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10390 test_loss : 0.20121 train_metric : 0.88889 test_metric : 0.74138\n",
      "\n",
      " loss : 0.07851 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07851 test_loss : 0.18994 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.15510 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15510 test_loss : 0.19233 train_metric : 0.77778 test_metric : 0.75235\n",
      "\n",
      " loss : 0.03479 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03479 test_loss : 0.18122 train_metric : 0.96296 test_metric : 0.77900\n",
      "\n",
      " loss : 0.12801 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12801 test_loss : 0.18389 train_metric : 0.85185 test_metric : 0.78213\n",
      "\n",
      " loss : 0.02522 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02522 test_loss : 0.18832 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.11577 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11577 test_loss : 0.19978 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.10546 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10546 test_loss : 0.18512 train_metric : 0.85185 test_metric : 0.79154\n",
      "\n",
      " loss : 0.01161 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01161 test_loss : 0.19673 train_metric : 1.00000 test_metric : 0.76019\n",
      "\n",
      " loss : 0.02330 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02330 test_loss : 0.18112 train_metric : 1.00000 test_metric : 0.76489\n",
      "\n",
      " loss : 0.04634 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.04634 test_loss : 0.19326 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.11499 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11499 test_loss : 0.19488 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.07316 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07316 test_loss : 0.19302 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.04837 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04837 test_loss : 0.19219 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.11855 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11855 test_loss : 0.18980 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.17750 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17750 test_loss : 0.20036 train_metric : 0.81481 test_metric : 0.74922\n",
      "\n",
      " loss : 0.07440 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07440 test_loss : 0.19487 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.01908 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01908 test_loss : 0.18863 train_metric : 1.00000 test_metric : 0.76176\n",
      "\n",
      " loss : 0.03987 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03987 test_loss : 0.19255 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05075 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05075 test_loss : 0.19068 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.07842 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07842 test_loss : 0.19586 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10738 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10738 test_loss : 0.19721 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.18529 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18529 test_loss : 0.18746 train_metric : 0.77778 test_metric : 0.77116\n",
      "\n",
      " loss : 0.09395 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09395 test_loss : 0.20246 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.12916 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12916 test_loss : 0.19840 train_metric : 0.81481 test_metric : 0.74765\n",
      "\n",
      " loss : 0.08527 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08527 test_loss : 0.20122 train_metric : 0.92593 test_metric : 0.74451\n",
      "\n",
      " loss : 0.01774 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01774 test_loss : 0.20362 train_metric : 0.96296 test_metric : 0.75392\n",
      "\n",
      " loss : 0.01876 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01876 test_loss : 0.18852 train_metric : 1.00000 test_metric : 0.76019\n",
      "\n",
      " loss : 0.03349 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03349 test_loss : 0.19300 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.10910 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10910 test_loss : 0.19712 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.10257 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10257 test_loss : 0.20564 train_metric : 0.81481 test_metric : 0.73981\n",
      "\n",
      " loss : 0.08963 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08963 test_loss : 0.18474 train_metric : 0.88889 test_metric : 0.77586\n",
      "\n",
      " loss : 0.08419 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08419 test_loss : 0.19611 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.08826 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08826 test_loss : 0.19684 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.10764 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10764 test_loss : 0.20164 train_metric : 0.88889 test_metric : 0.73824\n",
      "\n",
      " loss : 0.03402 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03402 test_loss : 0.19769 train_metric : 0.96296 test_metric : 0.74608\n",
      "\n",
      " loss : 0.10184 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10184 test_loss : 0.18721 train_metric : 0.85185 test_metric : 0.78056\n",
      "\n",
      " loss : 0.14459 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14459 test_loss : 0.19333 train_metric : 0.81481 test_metric : 0.76019\n",
      "\n",
      " loss : 0.08924 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.08924 test_loss : 0.20347 train_metric : 0.81481 test_metric : 0.74451\n",
      "\n",
      " loss : 0.14449 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14449 test_loss : 0.19982 train_metric : 0.81481 test_metric : 0.74451\n",
      "\n",
      " loss : 0.06216 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06216 test_loss : 0.19583 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.14370 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14370 test_loss : 0.19136 train_metric : 0.81481 test_metric : 0.76803\n",
      "\n",
      " loss : 0.06834 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06834 test_loss : 0.20513 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.06032 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06032 test_loss : 0.18336 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.16340 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.16340 test_loss : 0.19836 train_metric : 0.70370 test_metric : 0.74295\n",
      "\n",
      " loss : 0.18834 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18834 test_loss : 0.18987 train_metric : 0.77778 test_metric : 0.76959\n",
      "\n",
      " loss : 0.05170 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05170 test_loss : 0.18877 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08898 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08898 test_loss : 0.19865 train_metric : 0.88889 test_metric : 0.74451\n",
      "\n",
      " loss : 0.09769 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09769 test_loss : 0.19156 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05536 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05536 test_loss : 0.19668 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.01783 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01783 test_loss : 0.19129 train_metric : 1.00000 test_metric : 0.76176\n",
      "\n",
      " loss : 0.07423 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07423 test_loss : 0.19022 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.10367 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10367 test_loss : 0.19428 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.03695 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03695 test_loss : 0.19428 train_metric : 0.96296 test_metric : 0.75078\n",
      "\n",
      " loss : 0.16368 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16368 test_loss : 0.19948 train_metric : 0.74074 test_metric : 0.75549\n",
      "\n",
      " loss : 0.03969 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03969 test_loss : 0.18582 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.04949 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04949 test_loss : 0.19871 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.09445 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09445 test_loss : 0.19329 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.14761 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14761 test_loss : 0.17849 train_metric : 0.81481 test_metric : 0.77273\n",
      "\n",
      " loss : 0.06672 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06672 test_loss : 0.20766 train_metric : 0.92593 test_metric : 0.73824\n",
      "\n",
      " loss : 0.11416 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11416 test_loss : 0.18955 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09152 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09152 test_loss : 0.18112 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.04471 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04471 test_loss : 0.19446 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.09180 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09180 test_loss : 0.19227 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.05722 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05722 test_loss : 0.20018 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.08299 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08299 test_loss : 0.18218 train_metric : 0.92593 test_metric : 0.78056\n",
      "\n",
      " loss : 0.11885 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11885 test_loss : 0.19477 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.04748 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04748 test_loss : 0.20206 train_metric : 0.96296 test_metric : 0.74922\n",
      "\n",
      " loss : 0.01730 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01730 test_loss : 0.19048 train_metric : 1.00000 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10170 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10170 test_loss : 0.18836 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.15184 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15184 test_loss : 0.19102 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.03712 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03712 test_loss : 0.18932 train_metric : 1.00000 test_metric : 0.76489\n",
      "\n",
      " loss : 0.06648 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06648 test_loss : 0.19278 train_metric : 0.96296 test_metric : 0.74922\n",
      "\n",
      " loss : 0.05116 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05116 test_loss : 0.18639 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.05044 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05044 test_loss : 0.18821 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.12090 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12090 test_loss : 0.18512 train_metric : 0.81481 test_metric : 0.76646\n",
      "\n",
      " loss : 0.03810 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03810 test_loss : 0.19239 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.12823 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12823 test_loss : 0.19110 train_metric : 0.81481 test_metric : 0.75078\n",
      "\n",
      " loss : 0.09680 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09680 test_loss : 0.19713 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.06762 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06762 test_loss : 0.19376 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.08751 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08751 test_loss : 0.19485 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.06014 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06014 test_loss : 0.19303 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.08733 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08733 test_loss : 0.19265 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.04888 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04888 test_loss : 0.19020 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.07937 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07937 test_loss : 0.18328 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.06111 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06111 test_loss : 0.18956 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09002 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09002 test_loss : 0.21030 train_metric : 0.92593 test_metric : 0.74608\n",
      "\n",
      " loss : 0.10378 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.10378 test_loss : 0.18286 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.03365 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03365 test_loss : 0.19689 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.05615 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05615 test_loss : 0.19329 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.10637 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10637 test_loss : 0.19713 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.04701 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04701 test_loss : 0.19239 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.06694 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06694 test_loss : 0.19070 train_metric : 0.88889 test_metric : 0.77586\n",
      "\n",
      " loss : 0.09533 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09533 test_loss : 0.18298 train_metric : 0.85185 test_metric : 0.78997\n",
      "\n",
      " loss : 0.04496 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04496 test_loss : 0.18057 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.11797 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11797 test_loss : 0.18369 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.10030 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10030 test_loss : 0.18798 train_metric : 0.85185 test_metric : 0.78527\n",
      "\n",
      " loss : 0.02899 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02899 test_loss : 0.18692 train_metric : 1.00000 test_metric : 0.76959\n",
      "\n",
      " loss : 0.09820 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09820 test_loss : 0.17608 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.04014 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04014 test_loss : 0.19396 train_metric : 0.96296 test_metric : 0.75235\n",
      "\n",
      " loss : 0.10857 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10857 test_loss : 0.18504 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.20088 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.20088 test_loss : 0.19395 train_metric : 0.81481 test_metric : 0.74295\n",
      "\n",
      " loss : 0.04727 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04727 test_loss : 0.20970 train_metric : 0.96296 test_metric : 0.74922\n",
      "\n",
      " loss : 0.12181 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12181 test_loss : 0.19282 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.13699 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13699 test_loss : 0.19275 train_metric : 0.81481 test_metric : 0.77743\n",
      "\n",
      " loss : 0.12669 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12669 test_loss : 0.20049 train_metric : 0.81481 test_metric : 0.75392\n",
      "\n",
      " loss : 0.06936 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06936 test_loss : 0.19783 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.09116 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09116 test_loss : 0.21264 train_metric : 0.88889 test_metric : 0.74608\n",
      "\n",
      " loss : 0.07037 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07037 test_loss : 0.19566 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.08482 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08482 test_loss : 0.18249 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.10384 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10384 test_loss : 0.19420 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.08460 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08460 test_loss : 0.18653 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.07809 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07809 test_loss : 0.19648 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10793 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10793 test_loss : 0.19190 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.11567 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11567 test_loss : 0.19474 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.06550 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06550 test_loss : 0.19912 train_metric : 0.92593 test_metric : 0.74608\n",
      "\n",
      " loss : 0.14125 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14125 test_loss : 0.19470 train_metric : 0.81481 test_metric : 0.75705\n",
      "\n",
      " loss : 0.10798 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10798 test_loss : 0.19791 train_metric : 0.85185 test_metric : 0.75078\n",
      "\n",
      " loss : 0.10825 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10825 test_loss : 0.20452 train_metric : 0.85185 test_metric : 0.74922\n",
      "\n",
      " loss : 0.07823 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07823 test_loss : 0.19396 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.18859 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18859 test_loss : 0.19676 train_metric : 0.77778 test_metric : 0.75235\n",
      "\n",
      " loss : 0.15361 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15361 test_loss : 0.20316 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.08508 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08508 test_loss : 0.19141 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.06302 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06302 test_loss : 0.19612 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.07510 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.07510 test_loss : 0.19104 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09042 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09042 test_loss : 0.18558 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.09882 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09882 test_loss : 0.19459 train_metric : 0.85185 test_metric : 0.74295\n",
      "\n",
      " loss : 0.06540 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06540 test_loss : 0.18823 train_metric : 0.88889 test_metric : 0.78997\n",
      "\n",
      " loss : 0.10752 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10752 test_loss : 0.19098 train_metric : 0.81481 test_metric : 0.75392\n",
      "\n",
      " loss : 0.05148 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05148 test_loss : 0.18218 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.12817 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12817 test_loss : 0.18369 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.13118 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13118 test_loss : 0.19673 train_metric : 0.81481 test_metric : 0.75392\n",
      "\n",
      " loss : 0.04322 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04322 test_loss : 0.18915 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.03620 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03620 test_loss : 0.20503 train_metric : 0.96296 test_metric : 0.75235\n",
      "\n",
      " loss : 0.07598 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07598 test_loss : 0.19091 train_metric : 0.92593 test_metric : 0.74608\n",
      "\n",
      " loss : 0.05802 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05802 test_loss : 0.19368 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.05766 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05766 test_loss : 0.18407 train_metric : 0.88889 test_metric : 0.77429\n",
      "\n",
      " loss : 0.07250 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07250 test_loss : 0.19923 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.03965 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03965 test_loss : 0.18709 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.16170 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16170 test_loss : 0.18209 train_metric : 0.81481 test_metric : 0.78056\n",
      "\n",
      " loss : 0.07770 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07770 test_loss : 0.20400 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.02204 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02204 test_loss : 0.17747 train_metric : 0.96296 test_metric : 0.77743\n",
      "\n",
      " loss : 0.03140 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03140 test_loss : 0.19077 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.04537 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04537 test_loss : 0.18946 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.04471 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04471 test_loss : 0.20097 train_metric : 0.96296 test_metric : 0.75078\n",
      "\n",
      " loss : 0.05378 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05378 test_loss : 0.18565 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.06071 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06071 test_loss : 0.19933 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.06995 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06995 test_loss : 0.19307 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.03250 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03250 test_loss : 0.19197 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.10899 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10899 test_loss : 0.18995 train_metric : 0.81481 test_metric : 0.76332\n",
      "\n",
      " loss : 0.05373 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05373 test_loss : 0.19137 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.12117 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.12117 test_loss : 0.19778 train_metric : 0.77778 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08073 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08073 test_loss : 0.18904 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.10344 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10344 test_loss : 0.18534 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.12766 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12766 test_loss : 0.19006 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.09146 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09146 test_loss : 0.18396 train_metric : 0.88889 test_metric : 0.77116\n",
      "\n",
      " loss : 0.06507 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06507 test_loss : 0.19841 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05731 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05731 test_loss : 0.19205 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.07138 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07138 test_loss : 0.18764 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.14422 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14422 test_loss : 0.19981 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.10904 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10904 test_loss : 0.18584 train_metric : 0.88889 test_metric : 0.77900\n",
      "\n",
      " loss : 0.13316 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13316 test_loss : 0.19627 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.20877 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20877 test_loss : 0.19808 train_metric : 0.74074 test_metric : 0.74922\n",
      "\n",
      " loss : 0.04943 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04943 test_loss : 0.18974 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.13138 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13138 test_loss : 0.20796 train_metric : 0.81481 test_metric : 0.74138\n",
      "\n",
      " loss : 0.03969 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03969 test_loss : 0.19019 train_metric : 0.96296 test_metric : 0.76803\n",
      "\n",
      " loss : 0.03824 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03824 test_loss : 0.19070 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.07280 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.07280 test_loss : 0.19235 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.13366 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13366 test_loss : 0.19542 train_metric : 0.81481 test_metric : 0.76019\n",
      "\n",
      " loss : 0.11196 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11196 test_loss : 0.18799 train_metric : 0.85185 test_metric : 0.77900\n",
      "\n",
      " loss : 0.09459 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09459 test_loss : 0.19471 train_metric : 0.85185 test_metric : 0.74922\n",
      "\n",
      " loss : 0.08604 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08604 test_loss : 0.19000 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.05817 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05817 test_loss : 0.20625 train_metric : 0.92593 test_metric : 0.74138\n",
      "\n",
      " loss : 0.07459 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07459 test_loss : 0.18047 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.08516 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08516 test_loss : 0.19669 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.02101 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02101 test_loss : 0.18342 train_metric : 1.00000 test_metric : 0.77586\n",
      "\n",
      " loss : 0.10696 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10696 test_loss : 0.19116 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.09149 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09149 test_loss : 0.19483 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.06924 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06924 test_loss : 0.19038 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.07795 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07795 test_loss : 0.18843 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.03299 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03299 test_loss : 0.18831 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.06384 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06384 test_loss : 0.19667 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.07422 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07422 test_loss : 0.19512 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.14209 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14209 test_loss : 0.20138 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.06420 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06420 test_loss : 0.19494 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.12310 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12310 test_loss : 0.18153 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07342 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07342 test_loss : 0.18997 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.08276 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08276 test_loss : 0.19184 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.04501 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04501 test_loss : 0.19543 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.10862 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10862 test_loss : 0.18471 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.05900 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05900 test_loss : 0.19603 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.13640 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13640 test_loss : 0.19605 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.09693 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09693 test_loss : 0.19332 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.07823 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07823 test_loss : 0.19590 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.07957 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07957 test_loss : 0.19204 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.06733 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06733 test_loss : 0.19432 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.15273 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15273 test_loss : 0.18659 train_metric : 0.81481 test_metric : 0.76332\n",
      "\n",
      " loss : 0.09867 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09867 test_loss : 0.20120 train_metric : 0.85185 test_metric : 0.74138\n",
      "\n",
      " loss : 0.04817 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04817 test_loss : 0.19106 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.13481 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.13481 test_loss : 0.18911 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.11838 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11838 test_loss : 0.19794 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09951 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09951 test_loss : 0.20415 train_metric : 0.85185 test_metric : 0.73668\n",
      "\n",
      " loss : 0.06531 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06531 test_loss : 0.19432 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.12668 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.12668 test_loss : 0.19295 train_metric : 0.74074 test_metric : 0.76646\n",
      "\n",
      " loss : 0.02556 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02556 test_loss : 0.18953 train_metric : 1.00000 test_metric : 0.76019\n",
      "\n",
      " loss : 0.07533 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07533 test_loss : 0.19687 train_metric : 0.88889 test_metric : 0.74765\n",
      "\n",
      " loss : 0.07715 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07715 test_loss : 0.19423 train_metric : 0.92593 test_metric : 0.75235\n",
      "\n",
      " loss : 0.06012 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06012 test_loss : 0.19318 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.04666 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04666 test_loss : 0.18015 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.13090 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13090 test_loss : 0.19553 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.06657 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06657 test_loss : 0.19662 train_metric : 0.88889 test_metric : 0.74765\n",
      "\n",
      " loss : 0.10985 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10985 test_loss : 0.18817 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.11199 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11199 test_loss : 0.19483 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.06483 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06483 test_loss : 0.19486 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.12376 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12376 test_loss : 0.18970 train_metric : 0.81481 test_metric : 0.75862\n",
      "\n",
      " loss : 0.12474 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12474 test_loss : 0.19298 train_metric : 0.85185 test_metric : 0.74295\n",
      "\n",
      " loss : 0.05260 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05260 test_loss : 0.19326 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.06336 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06336 test_loss : 0.19875 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.11944 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11944 test_loss : 0.19522 train_metric : 0.85185 test_metric : 0.74451\n",
      "\n",
      " loss : 0.03363 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03363 test_loss : 0.20966 train_metric : 0.96296 test_metric : 0.72100\n",
      "\n",
      " loss : 0.08292 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08292 test_loss : 0.18330 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.16705 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16705 test_loss : 0.19125 train_metric : 0.74074 test_metric : 0.76019\n",
      "\n",
      " loss : 0.12544 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12544 test_loss : 0.21242 train_metric : 0.85185 test_metric : 0.73824\n",
      "\n",
      " loss : 0.12560 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12560 test_loss : 0.19100 train_metric : 0.85185 test_metric : 0.77116\n",
      "\n",
      " loss : 0.05288 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05288 test_loss : 0.18200 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.11553 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11553 test_loss : 0.20100 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.09649 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09649 test_loss : 0.18977 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.00929 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00929 test_loss : 0.19126 train_metric : 1.00000 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05347 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05347 test_loss : 0.19313 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.04762 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04762 test_loss : 0.18622 train_metric : 0.96296 test_metric : 0.77743\n",
      "\n",
      " loss : 0.17057 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.17057 test_loss : 0.19456 train_metric : 0.74074 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10834 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10834 test_loss : 0.18726 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_nqe = fc_nqe_train.train(1000, seq_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss : 0.05628 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05628 test_loss : 0.18387 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.05166 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05166 test_loss : 0.18724 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.08438 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08438 test_loss : 0.19689 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.18350 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.18350 test_loss : 0.18451 train_metric : 0.81481 test_metric : 0.75862\n",
      "\n",
      " loss : 0.02040 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02040 test_loss : 0.18872 train_metric : 1.00000 test_metric : 0.76176\n",
      "\n",
      " loss : 0.04230 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04230 test_loss : 0.17951 train_metric : 0.96296 test_metric : 0.77743\n",
      "\n",
      " loss : 0.20455 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20455 test_loss : 0.18455 train_metric : 0.77778 test_metric : 0.76332\n",
      "\n",
      " loss : 0.22920 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.22920 test_loss : 0.19237 train_metric : 0.74074 test_metric : 0.76646\n",
      "\n",
      " loss : 0.02057 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02057 test_loss : 0.18506 train_metric : 1.00000 test_metric : 0.77116\n",
      "\n",
      " loss : 0.13073 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13073 test_loss : 0.18171 train_metric : 0.81481 test_metric : 0.76646\n",
      "\n",
      " loss : 0.10869 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10869 test_loss : 0.19103 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.08137 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08137 test_loss : 0.18229 train_metric : 0.88889 test_metric : 0.77900\n",
      "\n",
      " loss : 0.06415 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06415 test_loss : 0.19835 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.11276 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11276 test_loss : 0.19469 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.06528 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06528 test_loss : 0.18691 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08584 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08584 test_loss : 0.19652 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.11602 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11602 test_loss : 0.19560 train_metric : 0.85185 test_metric : 0.74138\n",
      "\n",
      " loss : 0.16555 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16555 test_loss : 0.18165 train_metric : 0.77778 test_metric : 0.76646\n",
      "\n",
      " loss : 0.04640 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04640 test_loss : 0.20249 train_metric : 0.96296 test_metric : 0.73981\n",
      "\n",
      " loss : 0.08002 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08002 test_loss : 0.19627 train_metric : 0.85185 test_metric : 0.78370\n",
      "\n",
      " loss : 0.10359 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10359 test_loss : 0.20786 train_metric : 0.88889 test_metric : 0.74608\n",
      "\n",
      " loss : 0.04857 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04857 test_loss : 0.19201 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.06012 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06012 test_loss : 0.18862 train_metric : 0.96296 test_metric : 0.74765\n",
      "\n",
      " loss : 0.09654 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09654 test_loss : 0.19253 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08998 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08998 test_loss : 0.18850 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.13502 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13502 test_loss : 0.19547 train_metric : 0.81481 test_metric : 0.75705\n",
      "\n",
      " loss : 0.12375 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12375 test_loss : 0.18715 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.04204 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04204 test_loss : 0.18877 train_metric : 0.96296 test_metric : 0.76332\n",
      "\n",
      " loss : 0.02210 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02210 test_loss : 0.19393 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.09642 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09642 test_loss : 0.19244 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.11631 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11631 test_loss : 0.19901 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.15252 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15252 test_loss : 0.19123 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.12186 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12186 test_loss : 0.19996 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.08888 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08888 test_loss : 0.19527 train_metric : 0.88889 test_metric : 0.74451\n",
      "\n",
      " loss : 0.05855 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05855 test_loss : 0.19736 train_metric : 0.96296 test_metric : 0.75078\n",
      "\n",
      " loss : 0.08980 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08980 test_loss : 0.19530 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.04079 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04079 test_loss : 0.19363 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.04748 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04748 test_loss : 0.19637 train_metric : 0.96296 test_metric : 0.76176\n",
      "\n",
      " loss : 0.13143 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13143 test_loss : 0.19737 train_metric : 0.85185 test_metric : 0.75078\n",
      "\n",
      " loss : 0.16415 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16415 test_loss : 0.19836 train_metric : 0.77778 test_metric : 0.75549\n",
      "\n",
      " loss : 0.02055 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02055 test_loss : 0.19998 train_metric : 1.00000 test_metric : 0.75392\n",
      "\n",
      " loss : 0.10682 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10682 test_loss : 0.19811 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.06839 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.06839 test_loss : 0.18686 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.10340 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10340 test_loss : 0.19664 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.09467 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09467 test_loss : 0.19555 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.07787 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07787 test_loss : 0.19276 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.04917 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04917 test_loss : 0.19221 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.02100 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02100 test_loss : 0.19139 train_metric : 1.00000 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05369 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05369 test_loss : 0.18727 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09169 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09169 test_loss : 0.19404 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.10185 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10185 test_loss : 0.20017 train_metric : 0.85185 test_metric : 0.74608\n",
      "\n",
      " loss : 0.09289 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09289 test_loss : 0.19622 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.13472 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13472 test_loss : 0.19243 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.10295 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10295 test_loss : 0.19680 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.07037 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07037 test_loss : 0.19322 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.03887 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03887 test_loss : 0.18623 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.04543 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04543 test_loss : 0.20215 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.12178 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12178 test_loss : 0.19617 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.05886 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05886 test_loss : 0.19036 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08139 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08139 test_loss : 0.18574 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.12160 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12160 test_loss : 0.19289 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.09851 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09851 test_loss : 0.19971 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.10966 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10966 test_loss : 0.19022 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.02876 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02876 test_loss : 0.19774 train_metric : 1.00000 test_metric : 0.74922\n",
      "\n",
      " loss : 0.04016 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04016 test_loss : 0.18125 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.15832 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15832 test_loss : 0.19426 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.10845 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10845 test_loss : 0.18838 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.09788 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.09788 test_loss : 0.18570 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05194 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05194 test_loss : 0.19178 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.07172 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07172 test_loss : 0.18703 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.02710 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02710 test_loss : 0.18325 train_metric : 1.00000 test_metric : 0.76176\n",
      "\n",
      " loss : 0.08379 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08379 test_loss : 0.19657 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.10845 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10845 test_loss : 0.19232 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.02291 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02291 test_loss : 0.19590 train_metric : 1.00000 test_metric : 0.76019\n",
      "\n",
      " loss : 0.07005 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07005 test_loss : 0.19304 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.07019 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07019 test_loss : 0.19537 train_metric : 0.92593 test_metric : 0.75235\n",
      "\n",
      " loss : 0.08363 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08363 test_loss : 0.19105 train_metric : 0.88889 test_metric : 0.77116\n",
      "\n",
      " loss : 0.15948 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15948 test_loss : 0.19218 train_metric : 0.81481 test_metric : 0.75392\n",
      "\n",
      " loss : 0.07384 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07384 test_loss : 0.20258 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.11454 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11454 test_loss : 0.18297 train_metric : 0.88889 test_metric : 0.78213\n",
      "\n",
      " loss : 0.12998 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12998 test_loss : 0.20526 train_metric : 0.85185 test_metric : 0.73824\n",
      "\n",
      " loss : 0.08129 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08129 test_loss : 0.19678 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.08685 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08685 test_loss : 0.19559 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.11650 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11650 test_loss : 0.18381 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.14773 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14773 test_loss : 0.19600 train_metric : 0.77778 test_metric : 0.75549\n",
      "\n",
      " loss : 0.13407 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13407 test_loss : 0.18554 train_metric : 0.81481 test_metric : 0.77586\n",
      "\n",
      " loss : 0.04433 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04433 test_loss : 0.19249 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.07643 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07643 test_loss : 0.18288 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.07869 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07869 test_loss : 0.19668 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.07934 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07934 test_loss : 0.18389 train_metric : 0.88889 test_metric : 0.77429\n",
      "\n",
      " loss : 0.19982 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.19982 test_loss : 0.19085 train_metric : 0.74074 test_metric : 0.76019\n",
      "\n",
      " loss : 0.12954 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12954 test_loss : 0.19012 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.03014 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03014 test_loss : 0.19083 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.04334 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.04334 test_loss : 0.18815 train_metric : 0.88889 test_metric : 0.77900\n",
      "\n",
      " loss : 0.06881 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06881 test_loss : 0.19495 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.04766 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04766 test_loss : 0.18762 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.03443 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03443 test_loss : 0.18805 train_metric : 0.96296 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05369 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05369 test_loss : 0.19140 train_metric : 0.88889 test_metric : 0.77429\n",
      "\n",
      " loss : 0.04503 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04503 test_loss : 0.18872 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.01212 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01212 test_loss : 0.19171 train_metric : 1.00000 test_metric : 0.76489\n",
      "\n",
      " loss : 0.10607 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10607 test_loss : 0.19673 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.01646 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01646 test_loss : 0.19211 train_metric : 1.00000 test_metric : 0.75862\n",
      "\n",
      " loss : 0.17705 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17705 test_loss : 0.19900 train_metric : 0.81481 test_metric : 0.75078\n",
      "\n",
      " loss : 0.09518 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09518 test_loss : 0.19559 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.07469 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07469 test_loss : 0.19479 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08654 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08654 test_loss : 0.18309 train_metric : 0.92593 test_metric : 0.77116\n",
      "\n",
      " loss : 0.11948 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11948 test_loss : 0.18513 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.13064 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13064 test_loss : 0.19400 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.12307 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12307 test_loss : 0.18779 train_metric : 0.85185 test_metric : 0.74608\n",
      "\n",
      " loss : 0.02315 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02315 test_loss : 0.19011 train_metric : 1.00000 test_metric : 0.76646\n",
      "\n",
      " loss : 0.08478 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08478 test_loss : 0.17917 train_metric : 0.92593 test_metric : 0.78997\n",
      "\n",
      " loss : 0.02619 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02619 test_loss : 0.19657 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.11676 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11676 test_loss : 0.20031 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.05065 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05065 test_loss : 0.19821 train_metric : 0.96296 test_metric : 0.74295\n",
      "\n",
      " loss : 0.07177 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07177 test_loss : 0.18470 train_metric : 0.92593 test_metric : 0.79154\n",
      "\n",
      " loss : 0.13913 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13913 test_loss : 0.18636 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.14871 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14871 test_loss : 0.18648 train_metric : 0.81481 test_metric : 0.76646\n",
      "\n",
      " loss : 0.17010 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17010 test_loss : 0.20139 train_metric : 0.81481 test_metric : 0.74451\n",
      "\n",
      " loss : 0.09271 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09271 test_loss : 0.19126 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.07421 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07421 test_loss : 0.19174 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.04745 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04745 test_loss : 0.18938 train_metric : 0.96296 test_metric : 0.76803\n",
      "\n",
      " loss : 0.06576 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06576 test_loss : 0.19711 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.05596 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05596 test_loss : 0.19280 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.09346 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09346 test_loss : 0.18567 train_metric : 0.88889 test_metric : 0.77586\n",
      "\n",
      " loss : 0.11754 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11754 test_loss : 0.18719 train_metric : 0.85185 test_metric : 0.77429\n",
      "\n",
      " loss : 0.05080 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05080 test_loss : 0.19705 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.06624 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06624 test_loss : 0.18068 train_metric : 0.92593 test_metric : 0.78213\n",
      "\n",
      " loss : 0.08921 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08921 test_loss : 0.19193 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.04853 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04853 test_loss : 0.18531 train_metric : 0.96296 test_metric : 0.76959\n",
      "\n",
      " loss : 0.01101 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01101 test_loss : 0.20624 train_metric : 1.00000 test_metric : 0.72727\n",
      "\n",
      " loss : 0.08873 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08873 test_loss : 0.19821 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.22142 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.22142 test_loss : 0.19466 train_metric : 0.74074 test_metric : 0.75549\n",
      "\n",
      " loss : 0.10273 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10273 test_loss : 0.18860 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.04882 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04882 test_loss : 0.19645 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.10611 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10611 test_loss : 0.19925 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10367 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10367 test_loss : 0.20070 train_metric : 0.85185 test_metric : 0.73981\n",
      "\n",
      " loss : 0.06938 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06938 test_loss : 0.19391 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.04562 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04562 test_loss : 0.18693 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.02695 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02695 test_loss : 0.19091 train_metric : 1.00000 test_metric : 0.77586\n",
      "\n",
      " loss : 0.03411 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03411 test_loss : 0.18534 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.12427 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12427 test_loss : 0.18045 train_metric : 0.88889 test_metric : 0.77586\n",
      "\n",
      " loss : 0.10901 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10901 test_loss : 0.19252 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.13920 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13920 test_loss : 0.19772 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.04890 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04890 test_loss : 0.19853 train_metric : 0.92593 test_metric : 0.74295\n",
      "\n",
      " loss : 0.07228 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07228 test_loss : 0.18749 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.11382 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11382 test_loss : 0.18932 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.09591 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09591 test_loss : 0.20012 train_metric : 0.85185 test_metric : 0.75078\n",
      "\n",
      " loss : 0.04425 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04425 test_loss : 0.18487 train_metric : 0.92593 test_metric : 0.77743\n",
      "\n",
      " loss : 0.10682 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10682 test_loss : 0.19084 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.06510 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06510 test_loss : 0.19907 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.08266 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08266 test_loss : 0.19417 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.06352 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06352 test_loss : 0.19368 train_metric : 0.96296 test_metric : 0.75235\n",
      "\n",
      " loss : 0.11338 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11338 test_loss : 0.20137 train_metric : 0.81481 test_metric : 0.76959\n",
      "\n",
      " loss : 0.16631 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16631 test_loss : 0.18692 train_metric : 0.77778 test_metric : 0.77743\n",
      "\n",
      " loss : 0.10632 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10632 test_loss : 0.20154 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.03381 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03381 test_loss : 0.18721 train_metric : 1.00000 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05115 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05115 test_loss : 0.19212 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.09493 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09493 test_loss : 0.18601 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.05532 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05532 test_loss : 0.19415 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.07941 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07941 test_loss : 0.18491 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.10254 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10254 test_loss : 0.18856 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.02837 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02837 test_loss : 0.19582 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.10114 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10114 test_loss : 0.19591 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.06391 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06391 test_loss : 0.18939 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.13330 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13330 test_loss : 0.19531 train_metric : 0.81481 test_metric : 0.76332\n",
      "\n",
      " loss : 0.07803 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07803 test_loss : 0.19384 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.09369 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09369 test_loss : 0.18958 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.08708 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08708 test_loss : 0.19214 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.14889 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14889 test_loss : 0.20173 train_metric : 0.77778 test_metric : 0.75078\n",
      "\n",
      " loss : 0.05083 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05083 test_loss : 0.18519 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.04654 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04654 test_loss : 0.20696 train_metric : 0.96296 test_metric : 0.75392\n",
      "\n",
      " loss : 0.04411 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04411 test_loss : 0.19452 train_metric : 0.96296 test_metric : 0.76489\n",
      "\n",
      " loss : 0.12999 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12999 test_loss : 0.18929 train_metric : 0.81481 test_metric : 0.75235\n",
      "\n",
      " loss : 0.06012 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06012 test_loss : 0.18921 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.04327 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.04327 test_loss : 0.18347 train_metric : 0.88889 test_metric : 0.77116\n",
      "\n",
      " loss : 0.05607 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05607 test_loss : 0.19765 train_metric : 0.96296 test_metric : 0.75078\n",
      "\n",
      " loss : 0.08352 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08352 test_loss : 0.19551 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.07144 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07144 test_loss : 0.19441 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.08040 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08040 test_loss : 0.19253 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.09011 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09011 test_loss : 0.20080 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.12295 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.12295 test_loss : 0.20051 train_metric : 0.77778 test_metric : 0.74765\n",
      "\n",
      " loss : 0.05838 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05838 test_loss : 0.17561 train_metric : 0.92593 test_metric : 0.78213\n",
      "\n",
      " loss : 0.08536 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08536 test_loss : 0.19925 train_metric : 0.92593 test_metric : 0.75235\n",
      "\n",
      " loss : 0.18806 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18806 test_loss : 0.19865 train_metric : 0.77778 test_metric : 0.74765\n",
      "\n",
      " loss : 0.18410 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.18410 test_loss : 0.19637 train_metric : 0.81481 test_metric : 0.75392\n",
      "\n",
      " loss : 0.05476 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05476 test_loss : 0.21156 train_metric : 0.92593 test_metric : 0.73354\n",
      "\n",
      " loss : 0.10330 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10330 test_loss : 0.19191 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.07713 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07713 test_loss : 0.19063 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.13762 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.13762 test_loss : 0.19542 train_metric : 0.74074 test_metric : 0.74765\n",
      "\n",
      " loss : 0.04193 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04193 test_loss : 0.18049 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.05837 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05837 test_loss : 0.19631 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.07106 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07106 test_loss : 0.19255 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.07304 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07304 test_loss : 0.19929 train_metric : 0.92593 test_metric : 0.74138\n",
      "\n",
      " loss : 0.04265 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04265 test_loss : 0.18720 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.04508 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04508 test_loss : 0.18636 train_metric : 0.96296 test_metric : 0.76959\n",
      "\n",
      " loss : 0.08651 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08651 test_loss : 0.18177 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10067 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10067 test_loss : 0.19130 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.11756 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11756 test_loss : 0.18886 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.03379 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03379 test_loss : 0.19138 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05905 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05905 test_loss : 0.19213 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.04956 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04956 test_loss : 0.19744 train_metric : 0.96296 test_metric : 0.75862\n",
      "\n",
      " loss : 0.06236 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06236 test_loss : 0.19029 train_metric : 0.96296 test_metric : 0.74922\n",
      "\n",
      " loss : 0.04677 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04677 test_loss : 0.19447 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.07773 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07773 test_loss : 0.18891 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.07650 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07650 test_loss : 0.19656 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.05613 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05613 test_loss : 0.19645 train_metric : 0.96296 test_metric : 0.75392\n",
      "\n",
      " loss : 0.09260 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09260 test_loss : 0.18848 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.06896 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06896 test_loss : 0.19202 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.08090 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08090 test_loss : 0.19804 train_metric : 0.92593 test_metric : 0.73668\n",
      "\n",
      " loss : 0.05696 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05696 test_loss : 0.19343 train_metric : 0.92593 test_metric : 0.74608\n",
      "\n",
      " loss : 0.06355 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06355 test_loss : 0.19474 train_metric : 0.92593 test_metric : 0.75235\n",
      "\n",
      " loss : 0.08557 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08557 test_loss : 0.20572 train_metric : 0.85185 test_metric : 0.73824\n",
      "\n",
      " loss : 0.10453 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10453 test_loss : 0.19704 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.09002 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09002 test_loss : 0.19692 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.06497 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06497 test_loss : 0.20343 train_metric : 0.92593 test_metric : 0.74451\n",
      "\n",
      " loss : 0.05214 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05214 test_loss : 0.19571 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.06361 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06361 test_loss : 0.20107 train_metric : 0.88889 test_metric : 0.74295\n",
      "\n",
      " loss : 0.16506 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16506 test_loss : 0.20272 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.11048 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11048 test_loss : 0.18946 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.16626 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16626 test_loss : 0.19217 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.05856 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05856 test_loss : 0.19750 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.06545 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06545 test_loss : 0.19151 train_metric : 0.92593 test_metric : 0.76332\n",
      "\n",
      " loss : 0.11817 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11817 test_loss : 0.19095 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.15519 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15519 test_loss : 0.19250 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.13535 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13535 test_loss : 0.19294 train_metric : 0.85185 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10339 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10339 test_loss : 0.19473 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.13360 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13360 test_loss : 0.19263 train_metric : 0.81481 test_metric : 0.75862\n",
      "\n",
      " loss : 0.08204 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08204 test_loss : 0.19424 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.01624 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01624 test_loss : 0.19720 train_metric : 1.00000 test_metric : 0.75392\n",
      "\n",
      " loss : 0.02585 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02585 test_loss : 0.20269 train_metric : 0.96296 test_metric : 0.73511\n",
      "\n",
      " loss : 0.11167 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11167 test_loss : 0.19423 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.15898 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15898 test_loss : 0.20174 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.07414 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07414 test_loss : 0.20477 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.19653 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.19653 test_loss : 0.18765 train_metric : 0.74074 test_metric : 0.76019\n",
      "\n",
      " loss : 0.07917 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07917 test_loss : 0.19076 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.04463 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04463 test_loss : 0.18470 train_metric : 0.96296 test_metric : 0.77900\n",
      "\n",
      " loss : 0.12488 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12488 test_loss : 0.18954 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.02270 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02270 test_loss : 0.18685 train_metric : 1.00000 test_metric : 0.77116\n",
      "\n",
      " loss : 0.09033 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09033 test_loss : 0.18927 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.16303 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16303 test_loss : 0.19202 train_metric : 0.74074 test_metric : 0.76489\n",
      "\n",
      " loss : 0.13135 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13135 test_loss : 0.20001 train_metric : 0.81481 test_metric : 0.73981\n",
      "\n",
      " loss : 0.06839 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06839 test_loss : 0.18973 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.09523 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09523 test_loss : 0.18651 train_metric : 0.92593 test_metric : 0.77429\n",
      "\n",
      " loss : 0.08803 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08803 test_loss : 0.19813 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.08768 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08768 test_loss : 0.19479 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.10292 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10292 test_loss : 0.18294 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.19357 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19357 test_loss : 0.19796 train_metric : 0.77778 test_metric : 0.74451\n",
      "\n",
      " loss : 0.03514 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03514 test_loss : 0.20180 train_metric : 1.00000 test_metric : 0.75235\n",
      "\n",
      " loss : 0.08573 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08573 test_loss : 0.20160 train_metric : 0.88889 test_metric : 0.74451\n",
      "\n",
      " loss : 0.08795 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08795 test_loss : 0.20348 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.14247 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14247 test_loss : 0.20335 train_metric : 0.85185 test_metric : 0.74451\n",
      "\n",
      " loss : 0.10335 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10335 test_loss : 0.20148 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.07518 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07518 test_loss : 0.19672 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.10113 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10113 test_loss : 0.19730 train_metric : 0.88889 test_metric : 0.74608\n",
      "\n",
      " loss : 0.01081 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01081 test_loss : 0.18128 train_metric : 1.00000 test_metric : 0.77273\n",
      "\n",
      " loss : 0.07307 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07307 test_loss : 0.19551 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08955 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08955 test_loss : 0.20138 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.06672 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06672 test_loss : 0.19063 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.04758 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04758 test_loss : 0.19500 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.07198 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07198 test_loss : 0.20345 train_metric : 0.92593 test_metric : 0.73824\n",
      "\n",
      " loss : 0.07194 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07194 test_loss : 0.19831 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.07981 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07981 test_loss : 0.19664 train_metric : 0.92593 test_metric : 0.74451\n",
      "\n",
      " loss : 0.10875 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10875 test_loss : 0.19139 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.09141 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09141 test_loss : 0.18824 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.10924 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10924 test_loss : 0.20068 train_metric : 0.88889 test_metric : 0.74451\n",
      "\n",
      " loss : 0.06124 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06124 test_loss : 0.18856 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05500 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05500 test_loss : 0.19193 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.06393 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06393 test_loss : 0.18983 train_metric : 0.92593 test_metric : 0.75862\n",
      "\n",
      " loss : 0.07905 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07905 test_loss : 0.19058 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.10284 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10284 test_loss : 0.19642 train_metric : 0.85185 test_metric : 0.75705\n",
      "\n",
      " loss : 0.08742 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08742 test_loss : 0.20002 train_metric : 0.92593 test_metric : 0.74138\n",
      "\n",
      " loss : 0.03187 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03187 test_loss : 0.19757 train_metric : 0.96296 test_metric : 0.76176\n",
      "\n",
      " loss : 0.03524 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03524 test_loss : 0.18657 train_metric : 0.96296 test_metric : 0.77900\n",
      "\n",
      " loss : 0.09945 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09945 test_loss : 0.18784 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.14880 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14880 test_loss : 0.18962 train_metric : 0.81481 test_metric : 0.75862\n",
      "\n",
      " loss : 0.11745 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11745 test_loss : 0.18691 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.04663 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04663 test_loss : 0.18313 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.07609 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07609 test_loss : 0.18678 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.01344 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01344 test_loss : 0.18996 train_metric : 0.96296 test_metric : 0.75392\n",
      "\n",
      " loss : 0.01355 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01355 test_loss : 0.18762 train_metric : 1.00000 test_metric : 0.77116\n",
      "\n",
      " loss : 0.11676 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11676 test_loss : 0.19204 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.10547 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10547 test_loss : 0.19651 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.15163 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15163 test_loss : 0.19912 train_metric : 0.81481 test_metric : 0.74765\n",
      "\n",
      " loss : 0.07150 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07150 test_loss : 0.18769 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.14229 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14229 test_loss : 0.19195 train_metric : 0.81481 test_metric : 0.76176\n",
      "\n",
      " loss : 0.11947 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11947 test_loss : 0.19782 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.08173 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08173 test_loss : 0.19939 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.09302 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09302 test_loss : 0.19200 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09046 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09046 test_loss : 0.19572 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.09234 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09234 test_loss : 0.19330 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.09331 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09331 test_loss : 0.19254 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.04146 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04146 test_loss : 0.19916 train_metric : 0.96296 test_metric : 0.74765\n",
      "\n",
      " loss : 0.07547 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07547 test_loss : 0.19499 train_metric : 0.88889 test_metric : 0.76803\n",
      "\n",
      " loss : 0.06604 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06604 test_loss : 0.19590 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.06932 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06932 test_loss : 0.19371 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.03851 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03851 test_loss : 0.18919 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.13991 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13991 test_loss : 0.18715 train_metric : 0.81481 test_metric : 0.77586\n",
      "\n",
      " loss : 0.04372 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04372 test_loss : 0.20127 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.06799 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06799 test_loss : 0.19205 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.05174 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05174 test_loss : 0.19641 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.09420 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09420 test_loss : 0.19410 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.16184 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16184 test_loss : 0.19247 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.04859 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04859 test_loss : 0.20333 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.16396 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16396 test_loss : 0.18401 train_metric : 0.74074 test_metric : 0.76646\n",
      "\n",
      " loss : 0.11337 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11337 test_loss : 0.18819 train_metric : 0.81481 test_metric : 0.74451\n",
      "\n",
      " loss : 0.13863 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13863 test_loss : 0.20343 train_metric : 0.81481 test_metric : 0.73511\n",
      "\n",
      " loss : 0.14112 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14112 test_loss : 0.19106 train_metric : 0.81481 test_metric : 0.76646\n",
      "\n",
      " loss : 0.04444 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04444 test_loss : 0.20282 train_metric : 0.96296 test_metric : 0.76332\n",
      "\n",
      " loss : 0.05153 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05153 test_loss : 0.18920 train_metric : 0.96296 test_metric : 0.76803\n",
      "\n",
      " loss : 0.00543 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00543 test_loss : 0.18871 train_metric : 1.00000 test_metric : 0.76176\n",
      "\n",
      " loss : 0.11161 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11161 test_loss : 0.19817 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.10518 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10518 test_loss : 0.17257 train_metric : 0.85185 test_metric : 0.77116\n",
      "\n",
      " loss : 0.10331 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10331 test_loss : 0.19086 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.12645 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12645 test_loss : 0.19107 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.01737 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01737 test_loss : 0.19824 train_metric : 1.00000 test_metric : 0.76019\n",
      "\n",
      " loss : 0.06211 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06211 test_loss : 0.19290 train_metric : 0.92593 test_metric : 0.78213\n",
      "\n",
      " loss : 0.12308 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12308 test_loss : 0.19580 train_metric : 0.88889 test_metric : 0.75235\n",
      "\n",
      " loss : 0.10720 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10720 test_loss : 0.19717 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.12375 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12375 test_loss : 0.19178 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.17299 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17299 test_loss : 0.18724 train_metric : 0.81481 test_metric : 0.76019\n",
      "\n",
      " loss : 0.09712 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09712 test_loss : 0.19564 train_metric : 0.85185 test_metric : 0.76019\n",
      "\n",
      " loss : 0.06291 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06291 test_loss : 0.20077 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.19039 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19039 test_loss : 0.19341 train_metric : 0.77778 test_metric : 0.77116\n",
      "\n",
      " loss : 0.14493 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14493 test_loss : 0.18982 train_metric : 0.81481 test_metric : 0.75705\n",
      "\n",
      " loss : 0.10020 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10020 test_loss : 0.19305 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05467 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05467 test_loss : 0.18317 train_metric : 0.96296 test_metric : 0.78997\n",
      "\n",
      " loss : 0.11916 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11916 test_loss : 0.17994 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.14282 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14282 test_loss : 0.18811 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.06796 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06796 test_loss : 0.19082 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.08056 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08056 test_loss : 0.19958 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07950 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07950 test_loss : 0.19153 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.15279 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15279 test_loss : 0.19877 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.08695 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08695 test_loss : 0.18407 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.05464 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05464 test_loss : 0.19319 train_metric : 0.96296 test_metric : 0.75078\n",
      "\n",
      " loss : 0.14835 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.14835 test_loss : 0.19486 train_metric : 0.74074 test_metric : 0.75078\n",
      "\n",
      " loss : 0.14197 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14197 test_loss : 0.19395 train_metric : 0.81481 test_metric : 0.75392\n",
      "\n",
      " loss : 0.10340 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10340 test_loss : 0.18506 train_metric : 0.81481 test_metric : 0.77429\n",
      "\n",
      " loss : 0.04750 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04750 test_loss : 0.18868 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.17059 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17059 test_loss : 0.18512 train_metric : 0.77778 test_metric : 0.78370\n",
      "\n",
      " loss : 0.06420 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06420 test_loss : 0.18031 train_metric : 0.96296 test_metric : 0.77429\n",
      "\n",
      " loss : 0.07979 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07979 test_loss : 0.18572 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10967 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10967 test_loss : 0.20492 train_metric : 0.85185 test_metric : 0.74608\n",
      "\n",
      " loss : 0.03071 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03071 test_loss : 0.19403 train_metric : 0.96296 test_metric : 0.76332\n",
      "\n",
      " loss : 0.02846 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02846 test_loss : 0.19784 train_metric : 0.96296 test_metric : 0.74765\n",
      "\n",
      " loss : 0.04904 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04904 test_loss : 0.19575 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.07613 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07613 test_loss : 0.18436 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.10738 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10738 test_loss : 0.19436 train_metric : 0.85185 test_metric : 0.75235\n",
      "\n",
      " loss : 0.05930 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05930 test_loss : 0.19328 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.05687 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05687 test_loss : 0.19792 train_metric : 0.88889 test_metric : 0.74922\n",
      "\n",
      " loss : 0.20440 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20440 test_loss : 0.19804 train_metric : 0.77778 test_metric : 0.75862\n",
      "\n",
      " loss : 0.06912 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06912 test_loss : 0.19096 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.05230 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05230 test_loss : 0.18414 train_metric : 0.96296 test_metric : 0.77900\n",
      "\n",
      " loss : 0.05491 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05491 test_loss : 0.18683 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.11471 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11471 test_loss : 0.19868 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.20588 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20588 test_loss : 0.19780 train_metric : 0.77778 test_metric : 0.76959\n",
      "\n",
      " loss : 0.07827 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07827 test_loss : 0.19350 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.05416 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05416 test_loss : 0.21038 train_metric : 0.92593 test_metric : 0.74922\n",
      "\n",
      " loss : 0.03414 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03414 test_loss : 0.18652 train_metric : 0.96296 test_metric : 0.77429\n",
      "\n",
      " loss : 0.09087 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09087 test_loss : 0.19308 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.02437 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02437 test_loss : 0.19897 train_metric : 0.96296 test_metric : 0.75392\n",
      "\n",
      " loss : 0.18625 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18625 test_loss : 0.19007 train_metric : 0.74074 test_metric : 0.75235\n",
      "\n",
      " loss : 0.02534 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02534 test_loss : 0.20341 train_metric : 1.00000 test_metric : 0.75235\n",
      "\n",
      " loss : 0.05372 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05372 test_loss : 0.19590 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.11671 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11671 test_loss : 0.19515 train_metric : 0.85185 test_metric : 0.74451\n",
      "\n",
      " loss : 0.07898 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07898 test_loss : 0.19082 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.22270 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.22270 test_loss : 0.19325 train_metric : 0.70370 test_metric : 0.76646\n",
      "\n",
      " loss : 0.07126 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07126 test_loss : 0.18524 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.01076 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01076 test_loss : 0.20039 train_metric : 1.00000 test_metric : 0.75392\n",
      "\n",
      " loss : 0.11536 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11536 test_loss : 0.19766 train_metric : 0.81481 test_metric : 0.75235\n",
      "\n",
      " loss : 0.02737 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02737 test_loss : 0.20227 train_metric : 1.00000 test_metric : 0.74295\n",
      "\n",
      " loss : 0.08881 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08881 test_loss : 0.19007 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.06297 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06297 test_loss : 0.20272 train_metric : 0.92593 test_metric : 0.74451\n",
      "\n",
      " loss : 0.02644 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02644 test_loss : 0.20636 train_metric : 1.00000 test_metric : 0.74608\n",
      "\n",
      " loss : 0.07180 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07180 test_loss : 0.19393 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.11807 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11807 test_loss : 0.20249 train_metric : 0.85185 test_metric : 0.74922\n",
      "\n",
      " loss : 0.12508 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12508 test_loss : 0.17901 train_metric : 0.85185 test_metric : 0.78056\n",
      "\n",
      " loss : 0.05250 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05250 test_loss : 0.19794 train_metric : 0.88889 test_metric : 0.74138\n",
      "\n",
      " loss : 0.12901 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12901 test_loss : 0.19054 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.13047 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13047 test_loss : 0.19472 train_metric : 0.81481 test_metric : 0.74295\n",
      "\n",
      " loss : 0.06299 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06299 test_loss : 0.20224 train_metric : 0.92593 test_metric : 0.75235\n",
      "\n",
      " loss : 0.08173 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08173 test_loss : 0.20261 train_metric : 0.88889 test_metric : 0.74451\n",
      "\n",
      " loss : 0.05739 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05739 test_loss : 0.19302 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.03798 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03798 test_loss : 0.19070 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.14016 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.14016 test_loss : 0.19816 train_metric : 0.88889 test_metric : 0.74451\n",
      "\n",
      " loss : 0.12311 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12311 test_loss : 0.18901 train_metric : 0.88889 test_metric : 0.75862\n",
      "\n",
      " loss : 0.06996 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06996 test_loss : 0.20525 train_metric : 0.88889 test_metric : 0.73668\n",
      "\n",
      " loss : 0.01785 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01785 test_loss : 0.20405 train_metric : 0.96296 test_metric : 0.75078\n",
      "\n",
      " loss : 0.04590 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04590 test_loss : 0.20515 train_metric : 0.96296 test_metric : 0.73668\n",
      "\n",
      " loss : 0.06878 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06878 test_loss : 0.19847 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.12453 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12453 test_loss : 0.20577 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.16623 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16623 test_loss : 0.19989 train_metric : 0.81481 test_metric : 0.74451\n",
      "\n",
      " loss : 0.12341 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12341 test_loss : 0.19406 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.09823 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09823 test_loss : 0.19407 train_metric : 0.88889 test_metric : 0.75705\n",
      "\n",
      " loss : 0.05847 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05847 test_loss : 0.19104 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.07775 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07775 test_loss : 0.19295 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.09165 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09165 test_loss : 0.19626 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.03597 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03597 test_loss : 0.18480 train_metric : 0.96296 test_metric : 0.77586\n",
      "\n",
      " loss : 0.11188 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11188 test_loss : 0.19389 train_metric : 0.85185 test_metric : 0.75862\n",
      "\n",
      " loss : 0.03432 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03432 test_loss : 0.19527 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.13607 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13607 test_loss : 0.20736 train_metric : 0.81481 test_metric : 0.74138\n",
      "\n",
      " loss : 0.04067 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04067 test_loss : 0.20001 train_metric : 0.92593 test_metric : 0.73354\n",
      "\n",
      " loss : 0.14122 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14122 test_loss : 0.21039 train_metric : 0.81481 test_metric : 0.73354\n",
      "\n",
      " loss : 0.14943 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14943 test_loss : 0.19361 train_metric : 0.81481 test_metric : 0.75235\n",
      "\n",
      " loss : 0.07459 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07459 test_loss : 0.19582 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.09547 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09547 test_loss : 0.19739 train_metric : 0.88889 test_metric : 0.76646\n",
      "\n",
      " loss : 0.14540 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14540 test_loss : 0.18837 train_metric : 0.85185 test_metric : 0.76803\n",
      "\n",
      " loss : 0.15137 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15137 test_loss : 0.19312 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.06083 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06083 test_loss : 0.20287 train_metric : 0.92593 test_metric : 0.74608\n",
      "\n",
      " loss : 0.08903 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08903 test_loss : 0.20287 train_metric : 0.85185 test_metric : 0.74451\n",
      "\n",
      " loss : 0.13204 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13204 test_loss : 0.19744 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.08399 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08399 test_loss : 0.19162 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.04130 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04130 test_loss : 0.20775 train_metric : 0.96296 test_metric : 0.75392\n",
      "\n",
      " loss : 0.07948 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07948 test_loss : 0.19445 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.11165 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11165 test_loss : 0.19540 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.01376 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01376 test_loss : 0.19812 train_metric : 1.00000 test_metric : 0.75392\n",
      "\n",
      " loss : 0.10445 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10445 test_loss : 0.19049 train_metric : 0.88889 test_metric : 0.78370\n",
      "\n",
      " loss : 0.04876 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04876 test_loss : 0.19719 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.07249 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07249 test_loss : 0.19115 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.06850 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06850 test_loss : 0.20498 train_metric : 0.92593 test_metric : 0.73511\n",
      "\n",
      " loss : 0.14153 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14153 test_loss : 0.18773 train_metric : 0.85185 test_metric : 0.76646\n",
      "\n",
      " loss : 0.11557 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11557 test_loss : 0.18536 train_metric : 0.88889 test_metric : 0.76176\n",
      "\n",
      " loss : 0.03362 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03362 test_loss : 0.19325 train_metric : 0.96296 test_metric : 0.75392\n",
      "\n",
      " loss : 0.07225 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07225 test_loss : 0.20150 train_metric : 0.92593 test_metric : 0.76176\n",
      "\n",
      " loss : 0.04131 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04131 test_loss : 0.19404 train_metric : 0.92593 test_metric : 0.75705\n",
      "\n",
      " loss : 0.03521 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03521 test_loss : 0.19733 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.09777 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09777 test_loss : 0.20023 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.04419 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04419 test_loss : 0.20752 train_metric : 0.92593 test_metric : 0.73354\n",
      "\n",
      " loss : 0.15875 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15875 test_loss : 0.19881 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.09199 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09199 test_loss : 0.19743 train_metric : 0.85185 test_metric : 0.75549\n",
      "\n",
      " loss : 0.08431 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08431 test_loss : 0.18646 train_metric : 0.88889 test_metric : 0.76332\n",
      "\n",
      " loss : 0.02007 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02007 test_loss : 0.19571 train_metric : 1.00000 test_metric : 0.75549\n",
      "\n",
      " loss : 0.12326 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12326 test_loss : 0.18464 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.02371 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02371 test_loss : 0.19867 train_metric : 0.96296 test_metric : 0.74451\n",
      "\n",
      " loss : 0.12880 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12880 test_loss : 0.18991 train_metric : 0.85185 test_metric : 0.76959\n",
      "\n",
      " loss : 0.14296 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14296 test_loss : 0.19963 train_metric : 0.81481 test_metric : 0.75549\n",
      "\n",
      " loss : 0.05938 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05938 test_loss : 0.18659 train_metric : 0.96296 test_metric : 0.76803\n",
      "\n",
      " loss : 0.03256 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03256 test_loss : 0.18885 train_metric : 0.96296 test_metric : 0.76019\n",
      "\n",
      " loss : 0.06272 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06272 test_loss : 0.19086 train_metric : 0.92593 test_metric : 0.76803\n",
      "\n",
      " loss : 0.13629 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.13629 test_loss : 0.20157 train_metric : 0.88889 test_metric : 0.74295\n",
      "\n",
      " loss : 0.06711 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06711 test_loss : 0.19819 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.15402 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15402 test_loss : 0.19490 train_metric : 0.85185 test_metric : 0.75078\n",
      "\n",
      " loss : 0.02193 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02193 test_loss : 0.19959 train_metric : 1.00000 test_metric : 0.75235\n",
      "\n",
      " loss : 0.06398 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06398 test_loss : 0.18444 train_metric : 0.92593 test_metric : 0.77273\n",
      "\n",
      " loss : 0.11144 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11144 test_loss : 0.19011 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.03097 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03097 test_loss : 0.18324 train_metric : 0.96296 test_metric : 0.77116\n",
      "\n",
      " loss : 0.05661 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05661 test_loss : 0.19519 train_metric : 0.92593 test_metric : 0.75392\n",
      "\n",
      " loss : 0.14140 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14140 test_loss : 0.21306 train_metric : 0.81481 test_metric : 0.74451\n",
      "\n",
      " loss : 0.02189 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02189 test_loss : 0.18978 train_metric : 1.00000 test_metric : 0.76489\n",
      "\n",
      " loss : 0.04286 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04286 test_loss : 0.20307 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.06411 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06411 test_loss : 0.19660 train_metric : 0.88889 test_metric : 0.75078\n",
      "\n",
      " loss : 0.11974 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11974 test_loss : 0.17683 train_metric : 0.88889 test_metric : 0.78527\n",
      "\n",
      " loss : 0.08597 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08597 test_loss : 0.19044 train_metric : 0.85185 test_metric : 0.77586\n",
      "\n",
      " loss : 0.04249 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04249 test_loss : 0.19370 train_metric : 0.96296 test_metric : 0.76646\n",
      "\n",
      " loss : 0.12459 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12459 test_loss : 0.19200 train_metric : 0.88889 test_metric : 0.78213\n",
      "\n",
      " loss : 0.03880 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.03880 test_loss : 0.20574 train_metric : 0.88889 test_metric : 0.74608\n",
      "\n",
      " loss : 0.06800 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06800 test_loss : 0.20146 train_metric : 0.88889 test_metric : 0.74765\n",
      "\n",
      " loss : 0.10234 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.10234 test_loss : 0.18867 train_metric : 0.92593 test_metric : 0.76959\n",
      "\n",
      " loss : 0.06501 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06501 test_loss : 0.19725 train_metric : 0.92593 test_metric : 0.75549\n",
      "\n",
      " loss : 0.15953 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15953 test_loss : 0.19774 train_metric : 0.81481 test_metric : 0.74138\n",
      "\n",
      " loss : 0.16022 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.16022 test_loss : 0.19662 train_metric : 0.85185 test_metric : 0.75392\n",
      "\n",
      " loss : 0.04734 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04734 test_loss : 0.19181 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.07567 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07567 test_loss : 0.19846 train_metric : 0.92593 test_metric : 0.76489\n",
      "\n",
      " loss : 0.02410 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02410 test_loss : 0.19718 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n",
      " loss : 0.13743 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13743 test_loss : 0.19752 train_metric : 0.81481 test_metric : 0.75705\n",
      "\n",
      " loss : 0.06872 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06872 test_loss : 0.19176 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.06369 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06369 test_loss : 0.20141 train_metric : 0.92593 test_metric : 0.74765\n",
      "\n",
      " loss : 0.03718 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03718 test_loss : 0.19224 train_metric : 1.00000 test_metric : 0.76019\n",
      "\n",
      " loss : 0.08512 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08512 test_loss : 0.19978 train_metric : 0.85185 test_metric : 0.75078\n",
      "\n",
      " loss : 0.09801 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09801 test_loss : 0.19645 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.04626 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04626 test_loss : 0.20176 train_metric : 0.92593 test_metric : 0.74295\n",
      "\n",
      " loss : 0.13432 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13432 test_loss : 0.20365 train_metric : 0.85185 test_metric : 0.74765\n",
      "\n",
      " loss : 0.10656 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10656 test_loss : 0.19921 train_metric : 0.85185 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07114 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07114 test_loss : 0.19434 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.05330 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05330 test_loss : 0.19083 train_metric : 0.96296 test_metric : 0.75078\n",
      "\n",
      " loss : 0.07334 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07334 test_loss : 0.19299 train_metric : 0.88889 test_metric : 0.75549\n",
      "\n",
      " loss : 0.05605 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05605 test_loss : 0.19848 train_metric : 0.92593 test_metric : 0.74608\n",
      "\n",
      " loss : 0.08331 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08331 test_loss : 0.18692 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.08305 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08305 test_loss : 0.18716 train_metric : 0.88889 test_metric : 0.76959\n",
      "\n",
      " loss : 0.05938 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05938 test_loss : 0.19362 train_metric : 0.92593 test_metric : 0.76646\n",
      "\n",
      " loss : 0.07757 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07757 test_loss : 0.18657 train_metric : 0.88889 test_metric : 0.77273\n",
      "\n",
      " loss : 0.11563 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11563 test_loss : 0.19323 train_metric : 0.85185 test_metric : 0.77429\n",
      "\n",
      " loss : 0.08888 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08888 test_loss : 0.19960 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.11612 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11612 test_loss : 0.19355 train_metric : 0.81481 test_metric : 0.76489\n",
      "\n",
      " loss : 0.07353 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07353 test_loss : 0.20209 train_metric : 0.92593 test_metric : 0.75078\n",
      "\n",
      " loss : 0.15434 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15434 test_loss : 0.21193 train_metric : 0.85185 test_metric : 0.73511\n",
      "\n",
      " loss : 0.14752 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14752 test_loss : 0.19074 train_metric : 0.81481 test_metric : 0.76646\n",
      "\n",
      " loss : 0.14167 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14167 test_loss : 0.20561 train_metric : 0.85185 test_metric : 0.73824\n",
      "\n",
      " loss : 0.18247 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18247 test_loss : 0.20562 train_metric : 0.77778 test_metric : 0.75549\n",
      "\n",
      " loss : 0.07754 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07754 test_loss : 0.20408 train_metric : 0.88889 test_metric : 0.76019\n",
      "\n",
      " loss : 0.08678 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08678 test_loss : 0.19013 train_metric : 0.88889 test_metric : 0.76489\n",
      "\n",
      " loss : 0.01465 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01465 test_loss : 0.19053 train_metric : 0.96296 test_metric : 0.75705\n",
      "\n",
      " loss : 0.03779 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03779 test_loss : 0.19031 train_metric : 0.92593 test_metric : 0.76019\n",
      "\n",
      " loss : 0.08707 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08707 test_loss : 0.20172 train_metric : 0.85185 test_metric : 0.74608\n",
      "\n",
      " loss : 0.01028 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01028 test_loss : 0.19033 train_metric : 1.00000 test_metric : 0.76646\n",
      "\n",
      " loss : 0.13024 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13024 test_loss : 0.19560 train_metric : 0.85185 test_metric : 0.76332\n",
      "\n",
      " loss : 0.02647 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02647 test_loss : 0.18828 train_metric : 1.00000 test_metric : 0.76803\n",
      "\n",
      " loss : 0.02309 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02309 test_loss : 0.19639 train_metric : 1.00000 test_metric : 0.75705\n",
      "\n",
      " loss : 0.16314 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16314 test_loss : 0.20854 train_metric : 0.81481 test_metric : 0.75078\n",
      "\n",
      " loss : 0.07928 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07928 test_loss : 0.18819 train_metric : 0.88889 test_metric : 0.75392\n",
      "\n",
      " loss : 0.04859 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04859 test_loss : 0.19382 train_metric : 0.96296 test_metric : 0.75549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_nqe_after_500 = fc_nqe_train.train(500, seq_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_nqe.state_dict(), \"./models/pca_FC_NQE_loss187.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제로 같은 label을 갖는 feature에 대해서는 Embedding한 state간의 내적이 1에 가깝고, 그렇지 않으면 0으로 되는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[-1.2158e+00,  2.6049e+00,  3.2846e-01,  6.1858e-01],\n",
      "         [-1.4919e+00,  7.5409e-01, -9.8366e-02, -3.3946e-01]],\n",
      "\n",
      "        [[ 1.8011e+00,  7.8165e-01, -2.7626e-01, -7.9209e-01],\n",
      "         [-2.8622e+00, -8.9282e-01,  9.9488e-02,  4.8230e-02]],\n",
      "\n",
      "        [[-1.3783e+00, -5.2450e-01, -2.6319e-01, -4.1469e-01],\n",
      "         [-2.4822e+00, -9.5507e-01, -5.0605e-01, -2.8460e-03]],\n",
      "\n",
      "        [[ 5.7335e-01,  9.6609e-02, -3.2476e-01, -5.8291e-01],\n",
      "         [ 2.1940e-01, -8.3477e-02, -2.9614e-03, -8.8602e-01]],\n",
      "\n",
      "        [[-2.2716e+00, -1.1708e+00, -1.1284e+00,  4.3273e-01],\n",
      "         [-1.7903e+00,  4.0601e+00, -2.1713e-01,  3.1490e+00]],\n",
      "\n",
      "        [[-1.2252e+00, -1.2273e+00,  9.5935e-01, -1.1580e-01],\n",
      "         [ 3.1160e+00, -1.5854e+00,  6.1983e-02, -1.7014e-01]],\n",
      "\n",
      "        [[ 1.7007e+00, -7.2836e-01,  1.0045e+00,  8.3188e-02],\n",
      "         [-1.3481e+00, -1.7277e+00,  9.1373e-01,  8.5572e-01]],\n",
      "\n",
      "        [[ 1.9020e+00,  1.9909e+00,  6.9364e-01, -5.0573e-01],\n",
      "         [ 2.1197e+00,  1.2863e+00,  7.7727e-01, -6.4500e-01]],\n",
      "\n",
      "        [[-2.3939e-01,  1.0460e+00, -1.7626e+00,  1.5204e+00],\n",
      "         [-2.3818e+00, -9.7831e-01, -5.5679e-01, -1.1835e-01]],\n",
      "\n",
      "        [[-3.9868e+00, -1.1703e+00, -1.9591e-01, -4.8265e-01],\n",
      "         [ 1.1753e+00, -1.9614e-01, -8.5918e-01, -7.1746e-01]],\n",
      "\n",
      "        [[-1.3622e+00, -6.0499e-01, -1.7152e+00, -4.2112e-01],\n",
      "         [ 1.8676e-01, -4.9772e-01,  1.3269e+00,  5.5767e-01]],\n",
      "\n",
      "        [[-1.0839e-01,  3.1013e+00,  4.1344e-01,  1.1434e+00],\n",
      "         [ 4.6306e+00, -1.2083e-01,  1.6509e+00,  7.0292e-01]],\n",
      "\n",
      "        [[ 1.1394e+00,  1.6310e+00,  4.5754e-01, -9.8298e-01],\n",
      "         [ 5.5863e+00, -2.0282e+00, -2.4525e-01,  1.5170e+00]],\n",
      "\n",
      "        [[-7.3692e-01,  2.5381e-02, -2.3808e+00, -7.2943e-01],\n",
      "         [ 1.9558e+00, -2.7386e-01, -1.0843e+00, -3.8817e-01]],\n",
      "\n",
      "        [[ 5.2487e-01, -1.6246e+00,  7.7978e-01,  7.3130e-01],\n",
      "         [ 2.4295e+00,  1.1817e+00,  6.7183e-01, -7.0823e-01]],\n",
      "\n",
      "        [[ 1.9139e+00,  1.3553e+00,  2.5020e+00, -2.7006e-01],\n",
      "         [ 2.8828e+00, -2.2508e+00, -1.4430e+00,  1.2275e-01]],\n",
      "\n",
      "        [[ 8.5126e-01,  1.6286e+00,  2.1627e-01, -1.2166e+00],\n",
      "         [-3.9603e+00,  1.6159e+00, -7.4889e-02,  8.6767e-01]],\n",
      "\n",
      "        [[ 1.7463e-01, -1.0561e-01,  1.3339e+00, -4.4716e-01],\n",
      "         [ 1.9662e+00, -1.9387e+00, -7.5761e-01,  6.9571e-01]],\n",
      "\n",
      "        [[-5.8345e-01, -2.3337e+00, -3.6973e-01,  4.8900e-01],\n",
      "         [-1.1541e+00,  3.0681e+00,  1.2182e+00,  4.9270e-01]],\n",
      "\n",
      "        [[-1.9615e+00,  1.2555e+00, -4.0817e-01, -2.2799e-01],\n",
      "         [-6.7892e-01,  3.5280e+00, -2.5383e+00,  2.0604e+00]],\n",
      "\n",
      "        [[-1.4919e+00,  7.5409e-01, -9.8366e-02, -3.3946e-01],\n",
      "         [ 2.7684e+00, -2.2019e+00, -1.7320e+00,  1.0716e+00]],\n",
      "\n",
      "        [[-2.7692e+00,  5.7390e-01, -4.9892e-02, -3.7337e-01],\n",
      "         [ 1.7761e+00,  1.6499e-01,  6.6872e-01, -1.0086e+00]],\n",
      "\n",
      "        [[-1.1173e+00,  7.1718e-01,  1.8987e+00, -2.1384e-01],\n",
      "         [ 9.5488e-02, -2.2942e+00, -6.3160e-01,  6.2440e-01]],\n",
      "\n",
      "        [[-1.0712e+00,  2.4414e+00,  2.0887e+00,  1.2846e+00],\n",
      "         [-5.4828e-01,  2.8353e+00, -5.5141e-01, -1.6915e+00]],\n",
      "\n",
      "        [[ 8.1991e-01, -1.0876e+00, -6.7312e-01,  4.7218e-01],\n",
      "         [-1.7387e+00,  6.1512e-01,  9.2856e-01,  1.0805e+00]],\n",
      "\n",
      "        [[-4.7310e+00, -1.1833e+00,  6.8503e-01, -5.8542e-02],\n",
      "         [-8.4606e-01,  1.4528e+00, -4.9805e-01, -4.9821e-01]],\n",
      "\n",
      "        [[-1.4919e+00,  7.5409e-01, -9.8366e-02, -3.3946e-01],\n",
      "         [ 3.3379e+00, -1.5257e+00, -2.5054e+00, -3.5328e-01]],\n",
      "\n",
      "        [[-2.6627e+00, -2.6205e+00,  7.3303e-02,  7.0344e-01],\n",
      "         [-1.2424e+00,  1.2835e-01, -1.3516e+00, -3.1533e-01]],\n",
      "\n",
      "        [[ 3.0594e+00, -1.5068e+00, -6.3206e-01,  9.5999e-01],\n",
      "         [ 3.5632e+00, -1.5142e+00, -8.9502e-01,  3.6901e-01]],\n",
      "\n",
      "        [[ 1.6216e-02, -1.8873e-01, -7.1188e-01, -9.1959e-02],\n",
      "         [-8.0067e-01,  2.3663e+00, -1.5031e-01, -8.9830e-01]],\n",
      "\n",
      "        [[ 2.5826e-01,  9.3554e-01,  3.8525e-01,  1.8639e-01],\n",
      "         [-7.5751e-01, -3.1636e-02, -3.1477e-01, -6.3626e-01]],\n",
      "\n",
      "        [[-2.9321e+00, -9.1425e-01,  1.5047e+00,  2.4694e-01],\n",
      "         [ 7.6444e-01, -5.0202e-02, -3.0146e-01, -3.8571e-01]]]), tensor([[ 1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1.,  1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [ 1., -1.],\n",
      "        [ 1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [ 1., -1.],\n",
      "        [-1., -1.],\n",
      "        [ 1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1.,  1.],\n",
      "        [ 1.,  1.],\n",
      "        [-1.,  1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1.,  1.],\n",
      "        [-1., -1.],\n",
      "        [-1.,  1.],\n",
      "        [-1., -1.],\n",
      "        [-1.,  1.],\n",
      "        [-1., -1.],\n",
      "        [-1.,  1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.]])]\n"
     ]
    }
   ],
   "source": [
    "for e in train_loader:\n",
    "    print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.4700, -0.5930,  0.0424,  0.4030]) tensor(-1.)\n",
      "tensor([ 2.7916, -0.4528, -1.0187, -0.6341]) tensor(-1.)\n",
      "tensor([ 1.1479, -2.6952,  0.1751,  0.9549]) tensor(-1.)\n",
      "tensor([-1.1129,  1.7565, -1.9460,  0.1122]) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for e in train_loader:\n",
    "    f1, l1 = e[0][0][0], e[1][0][0]\n",
    "    f2, l2 = e[0][0][1], e[1][0][1]\n",
    "    f3, l3 = e[0][1][1], e[1][1][1]\n",
    "    f4, l4 = e[0][2][1], e[1][2][1]\n",
    "    \n",
    "    print(f1, l1)\n",
    "    print(f2, l2)\n",
    "    print(f3, l3)\n",
    "    print(f4, l4)\n",
    "    break\n",
    "# print(torch.stack([f1, f2]))\n",
    "f_data = torch.stack([torch.stack([f1, f2]), torch.stack([f2, f3]), torch.stack([f3, f1]), torch.stack([f3, f4]), torch.stack([f2, f4])])\n",
    "l_data = torch.stack([torch.stack([l1, l2]), torch.stack([l2, l3]), torch.stack([l3, l1]), torch.stack([l3, l4]), torch.stack([l2, l4])])\n",
    "\n",
    "# print(f_data, f_data.shape)\n",
    "# print(f_data.permute(1, 0, 2), f_data.permute(1,0,2).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.4700, -0.5930,  0.0424,  0.4030],\n",
      "         [ 2.7916, -0.4528, -1.0187, -0.6341]],\n",
      "\n",
      "        [[ 2.7916, -0.4528, -1.0187, -0.6341],\n",
      "         [ 1.1479, -2.6952,  0.1751,  0.9549]],\n",
      "\n",
      "        [[ 1.1479, -2.6952,  0.1751,  0.9549],\n",
      "         [ 4.4700, -0.5930,  0.0424,  0.4030]],\n",
      "\n",
      "        [[ 1.1479, -2.6952,  0.1751,  0.9549],\n",
      "         [-1.1129,  1.7565, -1.9460,  0.1122]],\n",
      "\n",
      "        [[ 2.7916, -0.4528, -1.0187, -0.6341],\n",
      "         [-1.1129,  1.7565, -1.9460,  0.1122]]])\n",
      "tensor([[-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1.,  1.],\n",
      "        [-1.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9924, 1.0000, 0.9924, 0.0569, 0.0569], dtype=torch.float64,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f_data)\n",
    "print(l_data)\n",
    "trained_nqe(f_data.permute(1, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KAN NQE도?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "kan_nqe = NQE(n_feature=4, mode='KAN')\n",
    "kan_nqe_train = NQE_Train(kan_nqe, criterion, train_loader, test_loader, [accuarcy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss : 0.73604 metric0 : 0.18519\n",
      "\n",
      " train_loss : 0.73604 test_loss : 0.58877 train_metric : 0.18519 test_metric : 0.34326\n",
      "\n",
      " loss : 0.60606 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.60606 test_loss : 0.58245 train_metric : 0.29630 test_metric : 0.34169\n",
      "\n",
      " loss : 0.64014 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.64014 test_loss : 0.58127 train_metric : 0.29630 test_metric : 0.34483\n",
      "\n",
      " loss : 0.67932 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.67932 test_loss : 0.58545 train_metric : 0.25926 test_metric : 0.34169\n",
      "\n",
      " loss : 0.58306 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.58306 test_loss : 0.59054 train_metric : 0.33333 test_metric : 0.34326\n",
      "\n",
      " loss : 0.70631 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.70631 test_loss : 0.59048 train_metric : 0.22222 test_metric : 0.34169\n",
      "\n",
      " loss : 0.68561 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.68561 test_loss : 0.59146 train_metric : 0.22222 test_metric : 0.34326\n",
      "\n",
      " loss : 0.52930 metric0 : 0.40741\n",
      "\n",
      " train_loss : 0.52930 test_loss : 0.59612 train_metric : 0.40741 test_metric : 0.34013\n",
      "\n",
      " loss : 0.64713 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.64713 test_loss : 0.59174 train_metric : 0.25926 test_metric : 0.34169\n",
      "\n",
      " loss : 0.58756 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.58756 test_loss : 0.58281 train_metric : 0.33333 test_metric : 0.34326\n",
      "\n",
      " loss : 0.67548 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.67548 test_loss : 0.58481 train_metric : 0.25926 test_metric : 0.34169\n",
      "\n",
      " loss : 0.58279 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.58279 test_loss : 0.59184 train_metric : 0.37037 test_metric : 0.34169\n",
      "\n",
      " loss : 0.48774 metric0 : 0.44444\n",
      "\n",
      " train_loss : 0.48774 test_loss : 0.58580 train_metric : 0.44444 test_metric : 0.34483\n",
      "\n",
      " loss : 0.64988 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.64988 test_loss : 0.58519 train_metric : 0.25926 test_metric : 0.34169\n",
      "\n",
      " loss : 0.40398 metric0 : 0.55556\n",
      "\n",
      " train_loss : 0.40398 test_loss : 0.59161 train_metric : 0.55556 test_metric : 0.34639\n",
      "\n",
      " loss : 0.62189 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.62189 test_loss : 0.59481 train_metric : 0.29630 test_metric : 0.34013\n",
      "\n",
      " loss : 0.63777 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.63777 test_loss : 0.58774 train_metric : 0.29630 test_metric : 0.34326\n",
      "\n",
      " loss : 0.54919 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.54919 test_loss : 0.58753 train_metric : 0.37037 test_metric : 0.34169\n",
      "\n",
      " loss : 0.68213 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.68213 test_loss : 0.59468 train_metric : 0.22222 test_metric : 0.34169\n",
      "\n",
      " loss : 0.51285 metric0 : 0.40741\n",
      "\n",
      " train_loss : 0.51285 test_loss : 0.58247 train_metric : 0.40741 test_metric : 0.34169\n",
      "\n",
      " loss : 0.55048 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.55048 test_loss : 0.58738 train_metric : 0.37037 test_metric : 0.34169\n",
      "\n",
      " loss : 0.58374 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.58374 test_loss : 0.58937 train_metric : 0.29630 test_metric : 0.34169\n",
      "\n",
      " loss : 0.61532 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.61532 test_loss : 0.58115 train_metric : 0.33333 test_metric : 0.34483\n",
      "\n",
      " loss : 0.54911 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.54911 test_loss : 0.58488 train_metric : 0.37037 test_metric : 0.33856\n",
      "\n",
      " loss : 0.54729 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.54729 test_loss : 0.58573 train_metric : 0.37037 test_metric : 0.34326\n",
      "\n",
      " loss : 0.65956 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.65956 test_loss : 0.58055 train_metric : 0.25926 test_metric : 0.34639\n",
      "\n",
      " loss : 0.67555 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.67555 test_loss : 0.58938 train_metric : 0.22222 test_metric : 0.34169\n",
      "\n",
      " loss : 0.70123 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.70123 test_loss : 0.59115 train_metric : 0.22222 test_metric : 0.34326\n",
      "\n",
      " loss : 0.58549 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.58549 test_loss : 0.58191 train_metric : 0.37037 test_metric : 0.34013\n",
      "\n",
      " loss : 0.62279 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.62279 test_loss : 0.58660 train_metric : 0.29630 test_metric : 0.34483\n",
      "\n",
      " loss : 0.51608 metric0 : 0.40741\n",
      "\n",
      " train_loss : 0.51608 test_loss : 0.58527 train_metric : 0.40741 test_metric : 0.34013\n",
      "\n",
      " loss : 0.72940 metric0 : 0.18519\n",
      "\n",
      " train_loss : 0.72940 test_loss : 0.58604 train_metric : 0.18519 test_metric : 0.34326\n",
      "\n",
      " loss : 0.53909 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.53909 test_loss : 0.58942 train_metric : 0.37037 test_metric : 0.34326\n",
      "\n",
      " loss : 0.64611 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.64611 test_loss : 0.58250 train_metric : 0.29630 test_metric : 0.34169\n",
      "\n",
      " loss : 0.68724 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.68724 test_loss : 0.58758 train_metric : 0.22222 test_metric : 0.34169\n",
      "\n",
      " loss : 0.60962 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.60962 test_loss : 0.58741 train_metric : 0.33333 test_metric : 0.34169\n",
      "\n",
      " loss : 0.63666 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.63666 test_loss : 0.58673 train_metric : 0.29630 test_metric : 0.34169\n",
      "\n",
      " loss : 0.63270 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.63270 test_loss : 0.58249 train_metric : 0.25926 test_metric : 0.34483\n",
      "\n",
      " loss : 0.74259 metric0 : 0.18519\n",
      "\n",
      " train_loss : 0.74259 test_loss : 0.58312 train_metric : 0.18519 test_metric : 0.34013\n",
      "\n",
      " loss : 0.70341 metric0 : 0.18519\n",
      "\n",
      " train_loss : 0.70341 test_loss : 0.58854 train_metric : 0.18519 test_metric : 0.34013\n",
      "\n",
      " loss : 0.60300 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.60300 test_loss : 0.58031 train_metric : 0.33333 test_metric : 0.34483\n",
      "\n",
      " loss : 0.57291 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.57291 test_loss : 0.59061 train_metric : 0.33333 test_metric : 0.34013\n",
      "\n",
      " loss : 0.62981 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.62981 test_loss : 0.58332 train_metric : 0.29630 test_metric : 0.33542\n",
      "\n",
      " loss : 0.52477 metric0 : 0.40741\n",
      "\n",
      " train_loss : 0.52477 test_loss : 0.58983 train_metric : 0.40741 test_metric : 0.34013\n",
      "\n",
      " loss : 0.75880 metric0 : 0.14815\n",
      "\n",
      " train_loss : 0.75880 test_loss : 0.59238 train_metric : 0.14815 test_metric : 0.34483\n",
      "\n",
      " loss : 0.69054 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.69054 test_loss : 0.58820 train_metric : 0.25926 test_metric : 0.34013\n",
      "\n",
      " loss : 0.78558 metric0 : 0.14815\n",
      "\n",
      " train_loss : 0.78558 test_loss : 0.57859 train_metric : 0.14815 test_metric : 0.34639\n",
      "\n",
      " loss : 0.52478 metric0 : 0.40741\n",
      "\n",
      " train_loss : 0.52478 test_loss : 0.58002 train_metric : 0.40741 test_metric : 0.34326\n",
      "\n",
      " loss : 0.52296 metric0 : 0.40741\n",
      "\n",
      " train_loss : 0.52296 test_loss : 0.58568 train_metric : 0.40741 test_metric : 0.34326\n",
      "\n",
      " loss : 0.70383 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.70383 test_loss : 0.58526 train_metric : 0.25926 test_metric : 0.34169\n",
      "\n",
      " loss : 0.52524 metric0 : 0.40741\n",
      "\n",
      " train_loss : 0.52524 test_loss : 0.58649 train_metric : 0.40741 test_metric : 0.34013\n",
      "\n",
      " loss : 0.68237 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.68237 test_loss : 0.58414 train_metric : 0.25926 test_metric : 0.34013\n",
      "\n",
      " loss : 0.64432 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.64432 test_loss : 0.58797 train_metric : 0.29630 test_metric : 0.34326\n",
      "\n",
      " loss : 0.61458 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.61458 test_loss : 0.58388 train_metric : 0.33333 test_metric : 0.34169\n",
      "\n",
      " loss : 0.50906 metric0 : 0.44444\n",
      "\n",
      " train_loss : 0.50906 test_loss : 0.58790 train_metric : 0.44444 test_metric : 0.34326\n",
      "\n",
      " loss : 0.65091 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.65091 test_loss : 0.58593 train_metric : 0.25926 test_metric : 0.34639\n",
      "\n",
      " loss : 0.67903 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.67903 test_loss : 0.58797 train_metric : 0.22222 test_metric : 0.34326\n",
      "\n",
      " loss : 0.64989 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.64989 test_loss : 0.59334 train_metric : 0.25926 test_metric : 0.33699\n",
      "\n",
      " loss : 0.64115 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.64115 test_loss : 0.58500 train_metric : 0.29630 test_metric : 0.34326\n",
      "\n",
      " loss : 0.68929 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.68929 test_loss : 0.58580 train_metric : 0.22222 test_metric : 0.34169\n",
      "\n",
      " loss : 0.63965 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.63965 test_loss : 0.58804 train_metric : 0.29630 test_metric : 0.34483\n",
      "\n",
      " loss : 0.58426 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.58426 test_loss : 0.58614 train_metric : 0.33333 test_metric : 0.34169\n",
      "\n",
      " loss : 0.66325 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.66325 test_loss : 0.58822 train_metric : 0.25926 test_metric : 0.34326\n",
      "\n",
      " loss : 0.62135 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.62135 test_loss : 0.58261 train_metric : 0.29630 test_metric : 0.34326\n",
      "\n",
      " loss : 0.57948 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.57948 test_loss : 0.58191 train_metric : 0.33333 test_metric : 0.34483\n",
      "\n",
      " loss : 0.74394 metric0 : 0.14815\n",
      "\n",
      " train_loss : 0.74394 test_loss : 0.58579 train_metric : 0.14815 test_metric : 0.34639\n",
      "\n",
      " loss : 0.66329 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.66329 test_loss : 0.58278 train_metric : 0.22222 test_metric : 0.34013\n",
      "\n",
      " loss : 0.71020 metric0 : 0.18519\n",
      "\n",
      " train_loss : 0.71020 test_loss : 0.58749 train_metric : 0.18519 test_metric : 0.34483\n",
      "\n",
      " loss : 0.56481 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.56481 test_loss : 0.58140 train_metric : 0.37037 test_metric : 0.34326\n",
      "\n",
      " loss : 0.69552 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.69552 test_loss : 0.58431 train_metric : 0.22222 test_metric : 0.34639\n",
      "\n",
      " loss : 0.58787 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.58787 test_loss : 0.57971 train_metric : 0.33333 test_metric : 0.34326\n",
      "\n",
      " loss : 0.58514 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.58514 test_loss : 0.58809 train_metric : 0.37037 test_metric : 0.34326\n",
      "\n",
      " loss : 0.57347 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.57347 test_loss : 0.59126 train_metric : 0.37037 test_metric : 0.34169\n",
      "\n",
      " loss : 0.59641 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.59641 test_loss : 0.58819 train_metric : 0.37037 test_metric : 0.34326\n",
      "\n",
      " loss : 0.64478 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.64478 test_loss : 0.59666 train_metric : 0.29630 test_metric : 0.34169\n",
      "\n",
      " loss : 0.59084 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.59084 test_loss : 0.58038 train_metric : 0.33333 test_metric : 0.34326\n",
      "\n",
      " loss : 0.62609 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.62609 test_loss : 0.58326 train_metric : 0.33333 test_metric : 0.34483\n",
      "\n",
      " loss : 0.57168 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.57168 test_loss : 0.58287 train_metric : 0.37037 test_metric : 0.34169\n",
      "\n",
      " loss : 0.65718 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.65718 test_loss : 0.59021 train_metric : 0.25926 test_metric : 0.34013\n",
      "\n",
      " loss : 0.73094 metric0 : 0.18519\n",
      "\n",
      " train_loss : 0.73094 test_loss : 0.58214 train_metric : 0.18519 test_metric : 0.34326\n",
      "\n",
      " loss : 0.62693 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.62693 test_loss : 0.58353 train_metric : 0.29630 test_metric : 0.34483\n",
      "\n",
      " loss : 0.70376 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.70376 test_loss : 0.58844 train_metric : 0.22222 test_metric : 0.34169\n",
      "\n",
      " loss : 0.50492 metric0 : 0.40741\n",
      "\n",
      " train_loss : 0.50492 test_loss : 0.58493 train_metric : 0.40741 test_metric : 0.34326\n",
      "\n",
      " loss : 0.62772 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.62772 test_loss : 0.58135 train_metric : 0.29630 test_metric : 0.34483\n",
      "\n",
      " loss : 0.66744 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.66744 test_loss : 0.58058 train_metric : 0.25926 test_metric : 0.34326\n",
      "\n",
      " loss : 0.67434 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.67434 test_loss : 0.58875 train_metric : 0.22222 test_metric : 0.34169\n",
      "\n",
      " loss : 0.68691 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.68691 test_loss : 0.58552 train_metric : 0.22222 test_metric : 0.34169\n",
      "\n",
      " loss : 0.52636 metric0 : 0.40741\n",
      "\n",
      " train_loss : 0.52636 test_loss : 0.58598 train_metric : 0.40741 test_metric : 0.34483\n",
      "\n",
      " loss : 0.59100 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.59100 test_loss : 0.58975 train_metric : 0.29630 test_metric : 0.34326\n",
      "\n",
      " loss : 0.74367 metric0 : 0.18519\n",
      "\n",
      " train_loss : 0.74367 test_loss : 0.58510 train_metric : 0.18519 test_metric : 0.34483\n",
      "\n",
      " loss : 0.63737 metric0 : 0.25926\n",
      "\n",
      " train_loss : 0.63737 test_loss : 0.58996 train_metric : 0.25926 test_metric : 0.34483\n",
      "\n",
      " loss : 0.69612 metric0 : 0.22222\n",
      "\n",
      " train_loss : 0.69612 test_loss : 0.58550 train_metric : 0.22222 test_metric : 0.33856\n",
      "\n",
      " loss : 0.58875 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.58875 test_loss : 0.58807 train_metric : 0.29630 test_metric : 0.34326\n",
      "\n",
      " loss : 0.52937 metric0 : 0.44444\n",
      "\n",
      " train_loss : 0.52937 test_loss : 0.58078 train_metric : 0.44444 test_metric : 0.34169\n",
      "\n",
      " loss : 0.65896 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.65896 test_loss : 0.58803 train_metric : 0.29630 test_metric : 0.34013\n",
      "\n",
      " loss : 0.56538 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.56538 test_loss : 0.58579 train_metric : 0.37037 test_metric : 0.34326\n",
      "\n",
      " loss : 0.59805 metric0 : 0.29630\n",
      "\n",
      " train_loss : 0.59805 test_loss : 0.58574 train_metric : 0.29630 test_metric : 0.34326\n",
      "\n",
      " loss : 0.57524 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.57524 test_loss : 0.57988 train_metric : 0.37037 test_metric : 0.34326\n",
      "\n",
      " loss : 0.59372 metric0 : 0.37037\n",
      "\n",
      " train_loss : 0.59372 test_loss : 0.58792 train_metric : 0.37037 test_metric : 0.34326\n",
      "\n",
      " loss : 0.57182 metric0 : 0.33333\n",
      "\n",
      " train_loss : 0.57182 test_loss : 0.58499 train_metric : 0.33333 test_metric : 0.34326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_kanqe = kan_nqe_train.train(100, seq_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.4700, -0.5930,  0.0424,  0.4030],\n",
      "         [ 2.7916, -0.4528, -1.0187, -0.6341]],\n",
      "\n",
      "        [[ 2.7916, -0.4528, -1.0187, -0.6341],\n",
      "         [ 1.1479, -2.6952,  0.1751,  0.9549]],\n",
      "\n",
      "        [[ 1.1479, -2.6952,  0.1751,  0.9549],\n",
      "         [ 4.4700, -0.5930,  0.0424,  0.4030]],\n",
      "\n",
      "        [[ 1.1479, -2.6952,  0.1751,  0.9549],\n",
      "         [-1.1129,  1.7565, -1.9460,  0.1122]],\n",
      "\n",
      "        [[ 2.7916, -0.4528, -1.0187, -0.6341],\n",
      "         [-1.1129,  1.7565, -1.9460,  0.1122]]])\n",
      "tensor([[-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1., -1.],\n",
      "        [-1.,  1.],\n",
      "        [-1.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0201, 0.1455, 0.1010, 0.1053, 0.0003], dtype=torch.float64,\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f_data)\n",
    "print(l_data)\n",
    "trained_kanqe(f_data.permute(1, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fucntions_1029 import data_seq, train_seq\n",
    "from RNNQE_class import NQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnqe = NQE(n_feature=4, mode='RNN', rnn_sequence=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
