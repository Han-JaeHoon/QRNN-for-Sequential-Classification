{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3yUJB9sbKg0m"
      },
      "outputs": [],
      "source": [
        "# Quantum\n",
        "import pennylane as qml\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# Numpy, Pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Layer\n",
        "from kan import KAN\n",
        "from RNN_block import RNN_block\n",
        "# Data processing\n",
        "from fucntions import data_seq, train_seq\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Quantum User-Def Classes\n",
        "from utils import my_utils\n",
        "from NQE_class import NQE\n",
        "from NQE_train_class import NQE_Train\n",
        "from RNN_class import RNNModel, RNN_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_qu = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data uploading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "locations = ['Adelaide', 'Albany', 'Albury', 'AliceSprings', 'BadgerysCreek', 'Ballarat', 'Bendigo', 'Brisbane', 'Cairns', 'Canberra', 'Cobar', 'CoffsHarbour', 'Dartmoor', 'Darwin', 'GoldCoast', 'Hobart', 'Katherine', 'Launceston', 'Melbourne', 'MelbourneAirport', 'Mildura', 'Moree', 'MountGambier', 'MountGinini', 'Newcastle', 'Nhil', 'NorahHead', 'NorfolkIsland', 'Nuriootpa', 'PearceRAAF', 'Penrith', 'Perth', 'PerthAirport', 'Portland', 'Richmond', 'Sale', 'SalmonGums', 'Sydney', 'SydneyAirport', 'Townsville', 'Tuggeranong', 'Uluru', 'WaggaWagga', 'Walpole', 'Watsonia', 'Williamtown', 'Witchcliffe', 'Wollongong', 'Woomera']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_data = 3000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_dict = dict()\n",
        "label_data_dict = dict()\n",
        "for e in locations:\n",
        "    # print(e)\n",
        "    train_df = pd.read_csv(\"./data/train_data_\" + e + \".csv\")\n",
        "    label_df = pd.read_csv(\"./data/label_data_\" + e + \".csv\")\n",
        "    train_data_dict[e] = torch.tensor(train_df[[\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"Humidity3pm\",\"Pressure3pm\"]].to_numpy()[:num_data]).to(torch.float)\n",
        "    label_data_dict[e] = torch.tensor(label_df['RainTomorrow'].to_numpy()[:num_data]).to(torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adelaide 100\n",
            "Albany 20\n",
            "Albury 29\n",
            "AliceSprings 7\n",
            "BadgerysCreek 81\n",
            "Ballarat 12\n",
            "Bendigo 5\n",
            "Brisbane 27\n",
            "Cairns 52\n",
            "Canberra 16\n",
            "Cobar 21\n",
            "CoffsHarbour 56\n",
            "Dartmoor 66\n",
            "Darwin 0\n",
            "GoldCoast 60\n",
            "Hobart 5\n",
            "Katherine 19\n",
            "Launceston 8\n",
            "Melbourne 758\n",
            "MelbourneAirport 0\n",
            "Mildura 2\n",
            "Moree 155\n",
            "MountGambier 6\n",
            "MountGinini 133\n",
            "Newcastle 84\n",
            "Nhil 9\n",
            "NorahHead 75\n",
            "NorfolkIsland 45\n",
            "Nuriootpa 6\n",
            "PearceRAAF 246\n",
            "Penrith 74\n",
            "Perth 0\n",
            "PerthAirport 0\n",
            "Portland 13\n",
            "Richmond 58\n",
            "Sale 9\n",
            "SalmonGums 46\n",
            "Sydney 7\n",
            "SydneyAirport 4\n",
            "Townsville 6\n",
            "Tuggeranong 41\n",
            "Uluru 57\n",
            "WaggaWagga 33\n",
            "Walpole 187\n",
            "Watsonia 10\n",
            "Williamtown 456\n",
            "Witchcliffe 57\n",
            "Wollongong 48\n",
            "Woomera 18\n"
          ]
        }
      ],
      "source": [
        "for e in label_data_dict:\n",
        "    print(e, list(label_data_dict[e]).count(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3000, 5])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_dict['Darwin'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24360\\2769686528.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
            "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_24360\\2769686528.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "x_train = train_data_dict['Darwin']\n",
        "y_train = label_data_dict['Darwin']\n",
        "\n",
        "non_zero = (y_train != 0).nonzero()\n",
        "print(len(non_zero))\n",
        "\n",
        "x_train = torch.squeeze(train_data_dict['Darwin'][non_zero])\n",
        "y_train = torch.squeeze(label_data_dict['Darwin'][non_zero])\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_train , y_train, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Tensor로 변환\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([600, 5, 5])\n",
            "torch.Size([600, 5])\n"
          ]
        }
      ],
      "source": [
        "total_feature_data = torch.concat([X_train_tensor, X_test_tensor], dim = 0).reshape((-1, 5, 5))\n",
        "total_label_data = torch.concat([y_train_tensor, y_test_tensor], dim = 0).reshape((-1, 5))\n",
        "\n",
        "# total_feature_data.reshape((600, 5, 5))\n",
        "# total_label_data.reshape((600, 5))\n",
        "\n",
        "\n",
        "print(total_feature_data.shape)\n",
        "print(total_label_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "seq_data = data_seq(total_feature_data, total_label_data)\n",
        "train_loader, test_loader = seq_data.split_data(test_ratio=0.2, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "32\n",
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "for e in train_loader:\n",
        "    print(len(e))\n",
        "    print(len(e[0]))\n",
        "    print(len(e[0][0]))\n",
        "    print(len(e[0][0][0]))\n",
        "    # print(len(e[0][0][0][0])) # Err\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NQE Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fc_nqe = NQE(n_qu, 'FC')\n",
        "fc_nqe.load_state_dict(torch.load(\"./models/nqe_fc_loss220.pth\"))\n",
        "\n",
        "kan_nqe = NQE(n_qu, 'KAN')\n",
        "kan_nqe.load_state_dict(torch.load(\"./models/nqe_kan_loss284.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model, NQE model, criterion, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from RNN_class import RNN_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KN1XjNzMKg0q"
      },
      "outputs": [],
      "source": [
        "no_nqe_RNN = RNN_layer(5, 1, 5)\n",
        "fc_nqe_RNN = RNN_layer(5, 1, 5, nQE_model = fc_nqe)\n",
        "kan_nqe_RNN = RNN_layer(5,1, 5, nQE_model = kan_nqe)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer1 = optim.Adam(no_nqe_RNN.parameters(), lr = 0.002)\n",
        "optimizer2 = optim.Adam(fc_nqe_RNN.parameters(), lr = 0.002)\n",
        "optimizer3 = optim.Adam(kan_nqe_RNN.parameters(), lr = 0.002)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "O4BMa4xyKg0q"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "shape '[32, 45]' is invalid for input of size 1152",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m train_corpus \u001b[38;5;241m=\u001b[39m train_seq(no_nqe_RNN, train_loader, test_loader)\n\u001b[1;32m----> 3\u001b[0m train_loss_list, test_loss_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_corpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\ALL\\아주대학교\\비교과\\2024-여름\\Quantum Break\\QRNN-for-Sequential-Classification\\fucntions.py:80\u001b[0m, in \u001b[0;36mtrain_seq.train\u001b[1;34m(self, epochs, optimizer, criterion, metrics, seq_first)\u001b[0m\n\u001b[0;32m     77\u001b[0m     label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     79\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 80\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m## Forward 사용\u001b[39;00m\n\u001b[0;32m     81\u001b[0m pred_list\u001b[38;5;241m.\u001b[39mappend(pred)\n\u001b[0;32m     82\u001b[0m label_list\u001b[38;5;241m.\u001b[39mappend(label)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\ALL\\아주대학교\\비교과\\2024-여름\\Quantum Break\\QRNN-for-Sequential-Classification\\RNN_class.py:98\u001b[0m, in \u001b[0;36mRNN_layer.forward\u001b[1;34m(self, inputs, return_hidden_list, chk)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnQE_layer(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_layer(hidden,\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mansatz_params_1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mansatz_params_2),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    100\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m hidden\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kan\\KAN.py:311\u001b[0m, in \u001b[0;36mKAN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts\u001b[38;5;241m.\u001b[39mappend(x)  \u001b[38;5;66;03m# acts shape: (batch, width[l])\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m--> 311\u001b[0m     x_numerical, preacts, postacts_numerical, postspline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fun\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m         x_symbolic, postacts_symbolic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_fun[l](x)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kan\\KANLayer.py:170\u001b[0m, in \u001b[0;36mKANLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    168\u001b[0m batch \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# x: shape (batch, in_dim) => shape (size, batch) (size = out_dim * in_dim)\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mij,k->ikj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    171\u001b[0m preacts \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mreshape(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n\u001b[0;32m    172\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun(x)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (batch, size)\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: shape '[32, 45]' is invalid for input of size 1152"
          ]
        }
      ],
      "source": [
        "train_corpus = train_seq(no_nqe_RNN, train_loader, test_loader)\n",
        "\n",
        "train_loss_list, test_loss_list = train_corpus.train(500, optimizer1, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_loss_list' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[78], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_loss_list\u001b[49m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0.04\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_loss_list, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_loss_list' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_loss_list, label = 'train loss')\n",
        "plt.ylim(0,0.04)\n",
        "plt.plot(test_loss_list, label = 'test loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iteration')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye6cxRVyjUbO",
        "outputId": "eac3637e-c9c7-4baf-fe49-5b90328ebc5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(22270.1816, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "def decoding(input,max_value):\n",
        "  max = 1754.882\n",
        "  min = 85.192\n",
        "  return (max-min)/max_value*input+min\n",
        "\n",
        "for feature,label in test_loader:\n",
        "    pred = decoding(model(feature),1)\n",
        "    true = decoding(label,1)\n",
        "    print(nn.MSELoss()(true,pred))\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "예시 : pd.DataFrame{’tain_loss’:train_loss,…..}\n",
        "\n",
        "저장할때 index = False 해야함\n",
        "\n",
        "data.to_csv(’경로명’,index=False)\n",
        "\n",
        "폴더명 :  result_data\n",
        "\n",
        "파일명 : <model_name>_<method_name>_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "mUI_JKHZKg0s"
      },
      "outputs": [],
      "source": [
        "pred_list, train_label_list, test_pred_list, test_label_list = get_data(model=model, train_loader=test_loader, test_loader=test_loader)\n",
        "\n",
        "data_df = pd.DataFrame({'train_loss': train_loss_list, 'test_loss':test_loss_list,'train_predict':pred_list,'train_label':train_label_list,'validation_pred':test_pred_list,'validation_label':test_label_list})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       0                                                  1\n",
            "0             train_loss  [0.7028571963310242, 0.26157712936401367, 0.05...\n",
            "1         test_loss_list  [0.4050746560096741, 0.09366366267204285, 0.01...\n",
            "2          train_predict  [0.5189198, 0.63135177, 0.5798306, 0.6479473, ...\n",
            "3       train_label_list  [0.6068493, 0.6901615, 0.7628788, 0.8246914, 0...\n",
            "4   validation_pred_list  [0.5189198, 0.63135177, 0.5798306, 0.6479473, ...\n",
            "5  validation_label_list  [0.6068493, 0.6901615, 0.7628788, 0.8246914, 0...\n"
          ]
        }
      ],
      "source": [
        "print(data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_df.to_csv('./result_data_ysj/qRNN_NQEKAN_mse22270._data.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "penny_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
