{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' !git clone https://github.com/Han-JaeHoon/QRNN-for-Sequential-Classification.git\n",
        "!pip install pykan\n",
        "!pip install pennylane\n",
        "%cd QRNN-for-Sequential-Classification '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3yUJB9sbKg0m"
      },
      "outputs": [],
      "source": [
        "# Quantum\n",
        "import pennylane as qml\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# Numpy, Pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Layer\n",
        "from kan import KAN\n",
        "from RNN_block import RNN_block\n",
        "# Data processing\n",
        "from fucntions import data_seq, train_seq\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_qu = 5\n",
        "dev = qml.device('default.qubit', wires = n_qu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DiqQHp2AKg0n"
      },
      "outputs": [],
      "source": [
        "def embedding(params, n_qu):\n",
        "    '''\n",
        "    embedding layer\n",
        "    '''\n",
        "    n = n_qu\n",
        "    for i in range(n):\n",
        "        qml.Hadamard(i)\n",
        "        qml.RZ(2.0 * params[ : , i], i)\n",
        "     \n",
        "    for i in range(n - 1):\n",
        "        qml.IsingZZ(2.0 * params[ : , n + i] , [i, i + 1])\n",
        "\n",
        "@qml.qnode(dev, interface = \"torch\")\n",
        "def fidelity(vec1, vec2, n_qu):\n",
        "    '''\n",
        "        Args:\n",
        "            vec1 : list, (2n - 1)개의 element로 이루어진 vector\n",
        "            vec2 : list, (2n - 1)개의 element로 이루어진 vector\n",
        "    '''\n",
        "    embedding(vec1, n_qu) # Phi(x1) circuit 적용\n",
        "    qml.adjoint(embedding)(vec2, n_qu) # Phi^t(x2) 적용\n",
        "    return qml.probs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NQE Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NQE(nn.Module):\n",
        "    def __init__(self, n_feature, mode : str):\n",
        "        '''\n",
        "            Args:\n",
        "                type(str) : 'FC' or 'KAN'\n",
        "                n_feature(int) : # of feature\n",
        "        '''\n",
        "        super(NQE, self).__init__()\n",
        "\n",
        "        self.mode = mode\n",
        "\n",
        "        if mode == 'FC':\n",
        "            self.n_qu = n_feature\n",
        "            self.li1 = nn.Linear(n_feature, n_feature * n_feature)\n",
        "            self.li2 = nn.Linear(n_feature * n_feature, n_feature * n_feature)\n",
        "            self.li3 = nn.Linear(n_feature * n_feature, 2 * n_feature - 1)\n",
        "            self.quantum_layer = fidelity\n",
        "        \n",
        "        if mode == 'KAN':\n",
        "            self.n_qu = n_feature\n",
        "            self.linear1 = KAN([self.n_qu, self.n_qu * 2 + 1, self.n_qu * 2 - 1], grid = 1)\n",
        "            self.quantum_layer = fidelity\n",
        "\n",
        "    def forward_input_FC(self, inputs):\n",
        "        inputs = self.li1(inputs)\n",
        "        inputs = F.relu(inputs)\n",
        "        inputs = self.li2(inputs)\n",
        "        inputs = F.relu(inputs)\n",
        "        inputs = self.li3(inputs)\n",
        "        result = 2 * torch.pi * F.relu(inputs)\n",
        "        ## Quantum Layer 추가 필요\n",
        "        return result # Quantum Layer의 output을 리턴\n",
        "\n",
        "    def forward_FC(self,inputs):\n",
        "        input1 = inputs[0]\n",
        "        input2 = inputs[1]\n",
        "        input1 = self.forward_input_FC(input1)\n",
        "        input2 = self.forward_input_FC(input2)\n",
        "        output = self.quantum_layer(input1, input2, self.n_qu)[ : , 0]\n",
        "        return output\n",
        "\n",
        "    def forward_KAN(self, inputs):\n",
        "        input1 = inputs[0]\n",
        "        input2 = inputs[1]\n",
        "        input1 = self.linear1(input1)\n",
        "        input2 = self.linear1(input2)\n",
        "        output = self.quantum_layer(input1, input2, self.n_qu)[ : , 0]\n",
        "        return output\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.mode == 'FC':\n",
        "            return self.forward_FC(inputs)\n",
        "        if self.mode == 'KAN':\n",
        "            return self.forward_KAN(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data uploading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "locations = ['Adelaide', 'Albany', 'Albury', 'AliceSprings', 'BadgerysCreek', 'Ballarat', 'Bendigo', 'Brisbane', 'Cairns', 'Canberra', 'Cobar', 'CoffsHarbour', 'Dartmoor', 'Darwin', 'GoldCoast', 'Hobart', 'Katherine', 'Launceston', 'Melbourne', 'MelbourneAirport', 'Mildura', 'Moree', 'MountGambier', 'MountGinini', 'Newcastle', 'Nhil', 'NorahHead', 'NorfolkIsland', 'Nuriootpa', 'PearceRAAF', 'Penrith', 'Perth', 'PerthAirport', 'Portland', 'Richmond', 'Sale', 'SalmonGums', 'Sydney', 'SydneyAirport', 'Townsville', 'Tuggeranong', 'Uluru', 'WaggaWagga', 'Walpole', 'Watsonia', 'Williamtown', 'Witchcliffe', 'Wollongong', 'Woomera']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "nqe_train = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adelaide\n",
            "Albany\n",
            "Albury\n",
            "AliceSprings\n",
            "BadgerysCreek\n",
            "Ballarat\n",
            "Bendigo\n",
            "Brisbane\n",
            "Cairns\n",
            "Canberra\n",
            "Cobar\n",
            "CoffsHarbour\n",
            "Dartmoor\n",
            "Darwin\n",
            "GoldCoast\n",
            "Hobart\n",
            "Katherine\n",
            "Launceston\n",
            "Melbourne\n",
            "MelbourneAirport\n",
            "Mildura\n",
            "Moree\n",
            "MountGambier\n",
            "MountGinini\n",
            "Newcastle\n",
            "Nhil\n",
            "NorahHead\n",
            "NorfolkIsland\n",
            "Nuriootpa\n",
            "PearceRAAF\n",
            "Penrith\n",
            "Perth\n",
            "PerthAirport\n",
            "Portland\n",
            "Richmond\n",
            "Sale\n",
            "SalmonGums\n",
            "Sydney\n",
            "SydneyAirport\n",
            "Townsville\n",
            "Tuggeranong\n",
            "Uluru\n",
            "WaggaWagga\n",
            "Walpole\n",
            "Watsonia\n",
            "Williamtown\n",
            "Witchcliffe\n",
            "Wollongong\n",
            "Woomera\n"
          ]
        }
      ],
      "source": [
        "train_data_dict = dict()\n",
        "label_data_dict = dict()\n",
        "for e in locations:\n",
        "    print(e)\n",
        "    train_df = pd.read_csv(\"./data/train_data_\" + e + \".csv\")\n",
        "    label_df = pd.read_csv(\"./data/label_data_\" + e + \".csv\")\n",
        "    train_data_dict[e] = torch.tensor(train_df[[\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"Humidity3pm\",\"Pressure3pm\"]].to_numpy()[:nqe_train]).to(torch.float)\n",
        "    label_data_dict[e] = torch.tensor(label_df['RainTomorrow'].to_numpy()[:nqe_train]).to(torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "nqe_x_train = train_data_dict[locations[0]]\n",
        "nqe_y_train = label_data_dict[locations[0]]\n",
        "\n",
        "\n",
        "non_zero = (nqe_y_train != 0).nonzero()\n",
        "\n",
        "nqe_x_train = torch.squeeze(train_data_dict[locations[0]][non_zero])\n",
        "nqe_y_train = torch.squeeze(label_data_dict[locations[0]][non_zero])\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(nqe_x_train , nqe_y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Tensor로 변환\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "nqe_train_list = []\n",
        "nqe_train_label_list = []\n",
        "nqe_test_list = []\n",
        "nqe_test_label_list = []\n",
        "\n",
        "for i in range(len(X_train_tensor)):\n",
        "    nqe_train_data = torch.stack([X_train_tensor, torch.concat([X_train_tensor[(i + 1) : ], X_train_tensor[ : (i + 1)]])])\n",
        "    nqe_train_list.append(nqe_train_data)\n",
        "    nqe_label_data = torch.stack([y_train_tensor,torch.concat([y_train_tensor[(i + 1) :],y_train_tensor[: (i + 1)]])])\n",
        "    nqe_train_label_list.append(nqe_label_data)\n",
        "  \n",
        "for i in range(len(X_test_tensor)):\n",
        "    nqe_test_data = torch.stack([X_test_tensor, torch.concat([X_test_tensor[(i + 1) : ], X_test_tensor[ : (i + 1)]])])\n",
        "    nqe_test_list.append(nqe_test_data)\n",
        "    nqe_label_data = torch.stack([y_test_tensor,torch.concat([y_test_tensor[(i + 1) :],y_test_tensor[: (i + 1)]])])\n",
        "    nqe_test_label_list.append(nqe_label_data)\n",
        "\n",
        "nqe_train_data = torch.concat(nqe_train_list, dim = 1)\n",
        "nqe_train_label = torch.concat(nqe_train_label_list, dim = 1)\n",
        "nqe_test_data = torch.concat(nqe_test_list, dim = 1)\n",
        "nqe_test_label = torch.concat(nqe_test_label_list, dim = 1)\n",
        "\n",
        "\n",
        "print(nqe_train_data.shape)\n",
        "print(nqe_train_label.shape)\n",
        "print(nqe_test_data.shape)\n",
        "print(nqe_test_label.shape)\n",
        "\n",
        "\n",
        "nqe_train_data = nqe_train_data.permute(1,0,2)\n",
        "nqe_test_data = nqe_test_data.permute(1,0,2)\n",
        "nqe_train_label = nqe_train_label.permute(1,0)\n",
        "nqe_test_label = nqe_test_label.permute(1,0)\n",
        "\n",
        "print(nqe_train_data.shape)\n",
        "print(nqe_train_label.shape)\n",
        "print(nqe_test_data.shape)\n",
        "print(nqe_test_label.shape)\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "train_dataset = TensorDataset(nqe_train_data, nqe_train_label)\n",
        "test_dataset = TensorDataset(nqe_test_data, nqe_test_label)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NQE Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NQE_Train:\n",
        "    def __init__(self, nqe, criterion, train_loader,test_loader,matrics = []):\n",
        "        '''\n",
        "            Args:\n",
        "                nqe (NQE) : nqe object want to train\n",
        "                criterion (function) : loss function\n",
        "                data_pretrain (data_seq) : want to make train_seq\n",
        "                optimizer (torch.optimizer)\n",
        "        '''\n",
        "        self.nqe = nqe\n",
        "        self.loss = criterion\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.optim = optim.Adam(self.nqe.parameters(), lr = 0.005)\n",
        "        self.matrics = matrics\n",
        "    def train(self, epoch):\n",
        "        nqe_seq = train_seq(self.nqe, self.train_loader, self.test_loader)\n",
        "        nqe_seq.train(epoch, self.optim, self.loss, self.matrics, seq_first=True)\n",
        "        return self.nqe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "def criterion(pred, label):\n",
        "    '''\n",
        "        pred : inner product of two states\n",
        "        label : label data\n",
        "    '''\n",
        "    # print(pred.shape)\n",
        "    # print(label.shape)\n",
        "    loss = torch.sum(((pred) - 0.5 * (label[:, 0] * label[:, 1] + 1)) ** 2 )/len(pred)\n",
        "    return loss\n",
        "\n",
        "def accuarcy(pred, label):\n",
        "    '''\n",
        "        pred : inner product of two states\n",
        "        label : label data\n",
        "    '''\n",
        "    acc = torch.sum((torch.round(pred) ==torch.round(0.5 * (label[:, 0] * label[:, 1] + 1))))/len(pred)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_qu = 5 # number of features\n",
        "nqe1 = NQE(n_qu, 'FC')\n",
        "nqe_train1 = NQE_Train(nqe1, criterion, train_loader,test_loader,[accuarcy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 1 loss :0.586495041847229 loss_test = 0.5870387554168701\n",
            "epoch : 2 loss :0.5866676568984985 loss_test = 0.587451696395874\n",
            "epoch : 3 loss :0.5865719318389893 loss_test = 0.5876114368438721\n",
            "epoch : 4 loss :0.5866602063179016 loss_test = 0.5874125957489014\n",
            "epoch : 5 loss :0.5867141485214233 loss_test = 0.5875712633132935\n",
            "epoch : 6 loss :0.5867512822151184 loss_test = 0.5869946479797363\n",
            "epoch : 7 loss :0.5865515470504761 loss_test = 0.5872092247009277\n",
            "epoch : 8 loss :0.5866084694862366 loss_test = 0.5874603986740112\n",
            "epoch : 9 loss :0.5867410898208618 loss_test = 0.5874874591827393\n",
            "epoch : 10 loss :0.5866948962211609 loss_test = 0.5873752236366272\n"
          ]
        }
      ],
      "source": [
        "trained_nqe = nqe_train1.train(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "penny_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
