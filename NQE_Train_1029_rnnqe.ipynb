{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum\n",
    "import pennylane as qml\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Numpy, Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Layer\n",
    "from kan import KAN\n",
    "from RNN_block import RNN_block\n",
    "# Data processing\n",
    "# from fucntions_1028 import data_seq, train_seq\n",
    "from fucntions import data_seq, train_seq\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Quantum User-Def Classes\n",
    "from utils import my_utils\n",
    "from RNNQE_class import NQE\n",
    "from NQE_train_class import NQE_Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3168\n",
      "dataset length : 3163\n",
      "test_size : 608\n",
      "train_size : 2555\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 경로\n",
    "feature_path = './data/pca/pca_train_data_Perth.csv'\n",
    "label_path = './data/pca/pca_label_data_Perth.csv'\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "new_size = (len(pd.read_csv(feature_path).values) // batch_size) * batch_size\n",
    "print(new_size)\n",
    "\n",
    "# CSV 파일을 읽어 Tensor로 변환\n",
    "feature_data = torch.tensor(pd.read_csv(feature_path).values[:], dtype=torch.float32)\n",
    "label_data = torch.tensor(pd.read_csv(label_path).values[:], dtype=torch.float32)\n",
    "\n",
    "# data_seq 객체 생성\n",
    "data = data_seq(feature_data, label_data)\n",
    "train_loader, test_loader = data.split_data(test_ratio = 0.2, batch_size=batch_size, seq_first = False, for_nqe = True, n_sequence=5, seed = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for i, (t, l) in enumerate(train_loader):\n",
    "    print(i, l.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(pred, label):\n",
    "    '''\n",
    "        pred : inner product of two states\n",
    "        label : label data\n",
    "    '''\n",
    "    # print('pred : ', pred.shape)\n",
    "    # print('label :', label.shape)\n",
    "    # print('lbl[:, 0][-1] :', label[:, 0][-1])\n",
    "    # print('2nd term :', (label[:, 0] * label[:, 1] + 1).shape)\n",
    "    # loss = torch.sum((pred - label[:]) ** 2) / len(pred)\n",
    "    loss = torch.sum(((pred) - 0.5 * (label[:, 0] * label[:, 1] + 1)) ** 2 ) / len(pred)\n",
    "    return loss\n",
    "\n",
    "def accuarcy(pred, label):\n",
    "    '''\n",
    "        pred : inner product of two states\n",
    "        label : label data\n",
    "    '''\n",
    "    acc = torch.sum((torch.round(pred) == torch.round(0.5 * (label[:, 0] * label[:, 1] + 1)))) / len(pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnqe = NQE(n_feature=4, mode='RNN', rnn_sequence=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([27, 2, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "for tr, lbl in train_loader:\n",
    "    print(tr.shape)\n",
    "    # print(rnnqe(tr).shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnqe_train = NQE_Train(rnnqe, criterion, train_loader, test_loader, [accuarcy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch : 1 =====\n",
      " loss : 0.10141 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.10141 test_loss : 0.16877 train_metric : 0.92593 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 2 =====\n",
      " loss : 0.12347 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12347 test_loss : 0.14820 train_metric : 0.85185 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 3 =====\n",
      " loss : 0.21783 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.21783 test_loss : 0.16685 train_metric : 0.74074 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 4 =====\n",
      " loss : 0.12038 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12038 test_loss : 0.15142 train_metric : 0.88889 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 5 =====\n",
      " loss : 0.07806 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07806 test_loss : 0.16205 train_metric : 0.88889 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 6 =====\n",
      " loss : 0.10302 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10302 test_loss : 0.16047 train_metric : 0.88889 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 7 =====\n",
      " loss : 0.14343 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14343 test_loss : 0.17082 train_metric : 0.81481 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 8 =====\n",
      " loss : 0.08106 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08106 test_loss : 0.15614 train_metric : 0.88889 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 9 =====\n",
      " loss : 0.12451 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12451 test_loss : 0.16569 train_metric : 0.85185 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 10 =====\n",
      " loss : 0.14078 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14078 test_loss : 0.15507 train_metric : 0.81481 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 11 =====\n",
      " loss : 0.08897 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08897 test_loss : 0.17554 train_metric : 0.88889 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 12 =====\n",
      " loss : 0.12746 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12746 test_loss : 0.16543 train_metric : 0.85185 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 13 =====\n",
      " loss : 0.11595 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11595 test_loss : 0.15396 train_metric : 0.81481 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 14 =====\n",
      " loss : 0.12051 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12051 test_loss : 0.16560 train_metric : 0.81481 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 15 =====\n",
      " loss : 0.05985 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05985 test_loss : 0.16835 train_metric : 0.96296 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 16 =====\n",
      " loss : 0.15919 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15919 test_loss : 0.16811 train_metric : 0.81481 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 17 =====\n",
      " loss : 0.10589 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10589 test_loss : 0.17440 train_metric : 0.88889 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 18 =====\n",
      " loss : 0.13996 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13996 test_loss : 0.16783 train_metric : 0.81481 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 19 =====\n",
      " loss : 0.14226 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.14226 test_loss : 0.16266 train_metric : 0.74074 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 20 =====\n",
      " loss : 0.16473 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16473 test_loss : 0.17445 train_metric : 0.81481 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 21 =====\n",
      " loss : 0.12703 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12703 test_loss : 0.17192 train_metric : 0.85185 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 22 =====\n",
      " loss : 0.11436 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11436 test_loss : 0.17498 train_metric : 0.81481 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 23 =====\n",
      " loss : 0.08889 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08889 test_loss : 0.17947 train_metric : 0.85185 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 24 =====\n",
      " loss : 0.12477 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12477 test_loss : 0.17040 train_metric : 0.81481 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 25 =====\n",
      " loss : 0.07326 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07326 test_loss : 0.18018 train_metric : 0.88889 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 26 =====\n",
      " loss : 0.05681 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05681 test_loss : 0.18577 train_metric : 0.92593 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 27 =====\n",
      " loss : 0.09361 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09361 test_loss : 0.18267 train_metric : 0.88889 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 28 =====\n",
      " loss : 0.01448 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01448 test_loss : 0.18242 train_metric : 1.00000 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 29 =====\n",
      " loss : 0.13037 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13037 test_loss : 0.18116 train_metric : 0.81481 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 30 =====\n",
      " loss : 0.10717 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10717 test_loss : 0.18556 train_metric : 0.88889 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 31 =====\n",
      " loss : 0.03061 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03061 test_loss : 0.19561 train_metric : 0.92593 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 32 =====\n",
      " loss : 0.12943 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12943 test_loss : 0.18084 train_metric : 0.85185 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 33 =====\n",
      " loss : 0.10342 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10342 test_loss : 0.18366 train_metric : 0.85185 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 34 =====\n",
      " loss : 0.05649 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05649 test_loss : 0.17480 train_metric : 0.92593 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 35 =====\n",
      " loss : 0.05356 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05356 test_loss : 0.18721 train_metric : 0.92593 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 36 =====\n",
      " loss : 0.04859 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04859 test_loss : 0.17711 train_metric : 0.92593 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 37 =====\n",
      " loss : 0.12311 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12311 test_loss : 0.18476 train_metric : 0.85185 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 38 =====\n",
      " loss : 0.13839 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.13839 test_loss : 0.19533 train_metric : 0.77778 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 39 =====\n",
      " loss : 0.05865 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05865 test_loss : 0.18778 train_metric : 0.92593 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 40 =====\n",
      " loss : 0.08698 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08698 test_loss : 0.18421 train_metric : 0.88889 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 41 =====\n",
      " loss : 0.06082 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06082 test_loss : 0.18917 train_metric : 0.88889 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 42 =====\n",
      " loss : 0.04875 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04875 test_loss : 0.18634 train_metric : 0.92593 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 43 =====\n",
      " loss : 0.07448 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07448 test_loss : 0.19124 train_metric : 0.92593 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 44 =====\n",
      " loss : 0.07486 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07486 test_loss : 0.18334 train_metric : 0.85185 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 45 =====\n",
      " loss : 0.05739 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05739 test_loss : 0.18990 train_metric : 0.92593 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 46 =====\n",
      " loss : 0.09288 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09288 test_loss : 0.18675 train_metric : 0.88889 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 47 =====\n",
      " loss : 0.06631 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06631 test_loss : 0.19190 train_metric : 0.92593 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 48 =====\n",
      " loss : 0.10799 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10799 test_loss : 0.18221 train_metric : 0.85185 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 49 =====\n",
      " loss : 0.09901 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09901 test_loss : 0.18319 train_metric : 0.88889 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 50 =====\n",
      " loss : 0.06363 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06363 test_loss : 0.17551 train_metric : 0.92593 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 51 =====\n",
      " loss : 0.07759 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07759 test_loss : 0.18572 train_metric : 0.85185 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 52 =====\n",
      " loss : 0.11914 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11914 test_loss : 0.18162 train_metric : 0.85185 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 53 =====\n",
      " loss : 0.15626 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15626 test_loss : 0.19603 train_metric : 0.81481 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 54 =====\n",
      " loss : 0.08573 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08573 test_loss : 0.17917 train_metric : 0.92593 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 55 =====\n",
      " loss : 0.01570 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01570 test_loss : 0.18571 train_metric : 1.00000 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 56 =====\n",
      " loss : 0.14422 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14422 test_loss : 0.18313 train_metric : 0.81481 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 57 =====\n",
      " loss : 0.06383 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06383 test_loss : 0.16863 train_metric : 0.92593 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 58 =====\n",
      " loss : 0.03417 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03417 test_loss : 0.18564 train_metric : 1.00000 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 59 =====\n",
      " loss : 0.06672 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06672 test_loss : 0.17831 train_metric : 0.88889 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 60 =====\n",
      " loss : 0.13727 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13727 test_loss : 0.18135 train_metric : 0.81481 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 61 =====\n",
      " loss : 0.02682 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02682 test_loss : 0.17984 train_metric : 0.96296 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 62 =====\n",
      " loss : 0.05793 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05793 test_loss : 0.18763 train_metric : 0.88889 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 63 =====\n",
      " loss : 0.01237 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01237 test_loss : 0.19938 train_metric : 1.00000 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 64 =====\n",
      " loss : 0.06817 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06817 test_loss : 0.18391 train_metric : 0.88889 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 65 =====\n",
      " loss : 0.01310 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01310 test_loss : 0.17785 train_metric : 1.00000 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 66 =====\n",
      " loss : 0.04145 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04145 test_loss : 0.19232 train_metric : 0.92593 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 67 =====\n",
      " loss : 0.01010 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01010 test_loss : 0.18653 train_metric : 1.00000 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 68 =====\n",
      " loss : 0.03143 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03143 test_loss : 0.19767 train_metric : 0.96296 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 69 =====\n",
      " loss : 0.05355 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05355 test_loss : 0.20221 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 70 =====\n",
      " loss : 0.02347 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02347 test_loss : 0.18303 train_metric : 0.96296 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 71 =====\n",
      " loss : 0.01493 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01493 test_loss : 0.17737 train_metric : 1.00000 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 72 =====\n",
      " loss : 0.16710 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16710 test_loss : 0.19555 train_metric : 0.81481 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 73 =====\n",
      " loss : 0.10760 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10760 test_loss : 0.19999 train_metric : 0.81481 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 74 =====\n",
      " loss : 0.04942 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04942 test_loss : 0.18650 train_metric : 0.96296 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 75 =====\n",
      " loss : 0.09526 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09526 test_loss : 0.18378 train_metric : 0.88889 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 76 =====\n",
      " loss : 0.04472 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04472 test_loss : 0.19270 train_metric : 0.96296 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 77 =====\n",
      " loss : 0.10291 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10291 test_loss : 0.18146 train_metric : 0.88889 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 78 =====\n",
      " loss : 0.04995 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04995 test_loss : 0.19860 train_metric : 0.96296 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 79 =====\n",
      " loss : 0.03976 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03976 test_loss : 0.20433 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 80 =====\n",
      " loss : 0.07000 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07000 test_loss : 0.19173 train_metric : 0.92593 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 81 =====\n",
      " loss : 0.03646 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03646 test_loss : 0.20005 train_metric : 0.96296 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 82 =====\n",
      " loss : 0.02623 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.02623 test_loss : 0.19171 train_metric : 0.92593 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 83 =====\n",
      " loss : 0.09284 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09284 test_loss : 0.18822 train_metric : 0.88889 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 84 =====\n",
      " loss : 0.01730 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01730 test_loss : 0.19471 train_metric : 1.00000 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 85 =====\n",
      " loss : 0.00764 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00764 test_loss : 0.18478 train_metric : 1.00000 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 86 =====\n",
      " loss : 0.01192 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01192 test_loss : 0.18648 train_metric : 1.00000 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 87 =====\n",
      " loss : 0.06207 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06207 test_loss : 0.19503 train_metric : 0.92593 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 88 =====\n",
      " loss : 0.06286 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06286 test_loss : 0.18999 train_metric : 0.92593 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 89 =====\n",
      " loss : 0.07548 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07548 test_loss : 0.19846 train_metric : 0.92593 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 90 =====\n",
      " loss : 0.09101 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09101 test_loss : 0.19169 train_metric : 0.88889 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 91 =====\n",
      " loss : 0.12812 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12812 test_loss : 0.20050 train_metric : 0.85185 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 92 =====\n",
      " loss : 0.03469 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03469 test_loss : 0.20008 train_metric : 0.96296 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 93 =====\n",
      " loss : 0.11206 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11206 test_loss : 0.18985 train_metric : 0.88889 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 94 =====\n",
      " loss : 0.06414 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06414 test_loss : 0.20076 train_metric : 0.92593 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 95 =====\n",
      " loss : 0.03327 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03327 test_loss : 0.19746 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 96 =====\n",
      " loss : 0.09433 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09433 test_loss : 0.19526 train_metric : 0.88889 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 97 =====\n",
      " loss : 0.06909 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06909 test_loss : 0.18870 train_metric : 0.88889 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 98 =====\n",
      " loss : 0.03378 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03378 test_loss : 0.19177 train_metric : 0.96296 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 99 =====\n",
      " loss : 0.05378 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05378 test_loss : 0.18454 train_metric : 0.92593 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 100 =====\n",
      " loss : 0.00976 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00976 test_loss : 0.19998 train_metric : 1.00000 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 101 =====\n",
      " loss : 0.03253 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03253 test_loss : 0.18415 train_metric : 0.96296 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 102 =====\n",
      " loss : 0.08573 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08573 test_loss : 0.20170 train_metric : 0.88889 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 103 =====\n",
      " loss : 0.04953 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04953 test_loss : 0.19319 train_metric : 0.96296 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 104 =====\n",
      " loss : 0.00604 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00604 test_loss : 0.19924 train_metric : 1.00000 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 105 =====\n",
      " loss : 0.02323 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02323 test_loss : 0.20413 train_metric : 0.96296 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 106 =====\n",
      " loss : 0.04920 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04920 test_loss : 0.20327 train_metric : 0.96296 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 107 =====\n",
      " loss : 0.11398 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11398 test_loss : 0.21110 train_metric : 0.88889 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 108 =====\n",
      " loss : 0.04525 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04525 test_loss : 0.18552 train_metric : 0.92593 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 109 =====\n",
      " loss : 0.04499 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04499 test_loss : 0.20963 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 110 =====\n",
      " loss : 0.04106 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04106 test_loss : 0.20306 train_metric : 0.92593 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 111 =====\n",
      " loss : 0.02817 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02817 test_loss : 0.19404 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 112 =====\n",
      " loss : 0.07878 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07878 test_loss : 0.18805 train_metric : 0.88889 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 113 =====\n",
      " loss : 0.00757 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00757 test_loss : 0.21189 train_metric : 1.00000 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 114 =====\n",
      " loss : 0.05433 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05433 test_loss : 0.20180 train_metric : 0.96296 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 115 =====\n",
      " loss : 0.00541 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00541 test_loss : 0.20411 train_metric : 1.00000 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 116 =====\n",
      " loss : 0.02961 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02961 test_loss : 0.21404 train_metric : 0.96296 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 117 =====\n",
      " loss : 0.05870 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05870 test_loss : 0.20493 train_metric : 0.92593 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 118 =====\n",
      " loss : 0.00432 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00432 test_loss : 0.20418 train_metric : 1.00000 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 119 =====\n",
      " loss : 0.01292 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01292 test_loss : 0.19738 train_metric : 0.96296 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 120 =====\n",
      " loss : 0.04102 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04102 test_loss : 0.20080 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 121 =====\n",
      " loss : 0.00192 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00192 test_loss : 0.21082 train_metric : 1.00000 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 122 =====\n",
      " loss : 0.03404 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03404 test_loss : 0.19721 train_metric : 0.96296 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 123 =====\n",
      " loss : 0.06044 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06044 test_loss : 0.19901 train_metric : 0.92593 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 124 =====\n",
      " loss : 0.00671 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00671 test_loss : 0.20194 train_metric : 1.00000 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 125 =====\n",
      " loss : 0.03741 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03741 test_loss : 0.20106 train_metric : 0.96296 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 126 =====\n",
      " loss : 0.00620 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00620 test_loss : 0.19388 train_metric : 1.00000 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 127 =====\n",
      " loss : 0.04478 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04478 test_loss : 0.21144 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 128 =====\n",
      " loss : 0.04732 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04732 test_loss : 0.20139 train_metric : 0.96296 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 129 =====\n",
      " loss : 0.06656 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06656 test_loss : 0.19865 train_metric : 0.92593 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 130 =====\n",
      " loss : 0.00300 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00300 test_loss : 0.20506 train_metric : 1.00000 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 131 =====\n",
      " loss : 0.02665 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02665 test_loss : 0.20953 train_metric : 0.96296 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 132 =====\n",
      " loss : 0.04704 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04704 test_loss : 0.20877 train_metric : 0.96296 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 133 =====\n",
      " loss : 0.07444 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07444 test_loss : 0.21420 train_metric : 0.92593 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 134 =====\n",
      " loss : 0.06896 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06896 test_loss : 0.20993 train_metric : 0.92593 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 135 =====\n",
      " loss : 0.08454 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08454 test_loss : 0.20183 train_metric : 0.88889 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 136 =====\n",
      " loss : 0.11886 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11886 test_loss : 0.20389 train_metric : 0.85185 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 137 =====\n",
      " loss : 0.11332 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11332 test_loss : 0.19974 train_metric : 0.81481 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 138 =====\n",
      " loss : 0.07280 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07280 test_loss : 0.20437 train_metric : 0.92593 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 139 =====\n",
      " loss : 0.06261 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06261 test_loss : 0.20533 train_metric : 0.92593 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 140 =====\n",
      " loss : 0.04833 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.04833 test_loss : 0.21382 train_metric : 0.88889 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 141 =====\n",
      " loss : 0.05065 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05065 test_loss : 0.20873 train_metric : 0.92593 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 142 =====\n",
      " loss : 0.03853 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03853 test_loss : 0.22111 train_metric : 0.96296 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 143 =====\n",
      " loss : 0.05418 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05418 test_loss : 0.21801 train_metric : 0.92593 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 144 =====\n",
      " loss : 0.05927 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05927 test_loss : 0.19730 train_metric : 0.92593 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 145 =====\n",
      " loss : 0.05115 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05115 test_loss : 0.21341 train_metric : 0.96296 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 146 =====\n",
      " loss : 0.03041 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03041 test_loss : 0.21413 train_metric : 0.96296 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 147 =====\n",
      " loss : 0.08683 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08683 test_loss : 0.20440 train_metric : 0.92593 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 148 =====\n",
      " loss : 0.11174 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11174 test_loss : 0.20690 train_metric : 0.85185 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 149 =====\n",
      " loss : 0.03806 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03806 test_loss : 0.20910 train_metric : 0.96296 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 150 =====\n",
      " loss : 0.00229 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00229 test_loss : 0.21186 train_metric : 1.00000 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 151 =====\n",
      " loss : 0.00989 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00989 test_loss : 0.19973 train_metric : 1.00000 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 152 =====\n",
      " loss : 0.14012 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14012 test_loss : 0.23222 train_metric : 0.81481 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 153 =====\n",
      " loss : 0.05600 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05600 test_loss : 0.21550 train_metric : 0.96296 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 154 =====\n",
      " loss : 0.06727 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06727 test_loss : 0.20794 train_metric : 0.92593 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 155 =====\n",
      " loss : 0.09875 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09875 test_loss : 0.21048 train_metric : 0.85185 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 156 =====\n",
      " loss : 0.01544 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01544 test_loss : 0.21885 train_metric : 1.00000 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 157 =====\n",
      " loss : 0.04662 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04662 test_loss : 0.19770 train_metric : 0.96296 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 158 =====\n",
      " loss : 0.03774 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03774 test_loss : 0.21752 train_metric : 0.96296 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 159 =====\n",
      " loss : 0.01768 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01768 test_loss : 0.20751 train_metric : 1.00000 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 160 =====\n",
      " loss : 0.00247 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00247 test_loss : 0.21954 train_metric : 1.00000 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 161 =====\n",
      " loss : 0.04031 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04031 test_loss : 0.21083 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 162 =====\n",
      " loss : 0.06315 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06315 test_loss : 0.21854 train_metric : 0.92593 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 163 =====\n",
      " loss : 0.04325 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04325 test_loss : 0.21918 train_metric : 0.96296 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 164 =====\n",
      " loss : 0.00828 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00828 test_loss : 0.21202 train_metric : 1.00000 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 165 =====\n",
      " loss : 0.06079 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06079 test_loss : 0.21555 train_metric : 0.92593 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 166 =====\n",
      " loss : 0.06177 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06177 test_loss : 0.21125 train_metric : 0.92593 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 167 =====\n",
      " loss : 0.01886 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01886 test_loss : 0.21596 train_metric : 0.96296 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 168 =====\n",
      " loss : 0.04408 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04408 test_loss : 0.20166 train_metric : 0.96296 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 169 =====\n",
      " loss : 0.07569 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07569 test_loss : 0.21191 train_metric : 0.88889 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 170 =====\n",
      " loss : 0.02617 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02617 test_loss : 0.20803 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 171 =====\n",
      " loss : 0.04870 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04870 test_loss : 0.21960 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 172 =====\n",
      " loss : 0.06894 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06894 test_loss : 0.20970 train_metric : 0.92593 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 173 =====\n",
      " loss : 0.12134 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12134 test_loss : 0.21568 train_metric : 0.85185 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 174 =====\n",
      " loss : 0.02688 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02688 test_loss : 0.22429 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 175 =====\n",
      " loss : 0.13596 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13596 test_loss : 0.22766 train_metric : 0.85185 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 176 =====\n",
      " loss : 0.08736 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08736 test_loss : 0.22108 train_metric : 0.88889 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 177 =====\n",
      " loss : 0.03913 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03913 test_loss : 0.21259 train_metric : 0.96296 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 178 =====\n",
      " loss : 0.00195 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00195 test_loss : 0.20765 train_metric : 1.00000 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 179 =====\n",
      " loss : 0.00669 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00669 test_loss : 0.22013 train_metric : 1.00000 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 180 =====\n",
      " loss : 0.05023 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05023 test_loss : 0.22420 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 181 =====\n",
      " loss : 0.04342 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04342 test_loss : 0.22078 train_metric : 0.96296 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 182 =====\n",
      " loss : 0.03580 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03580 test_loss : 0.21631 train_metric : 0.96296 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 183 =====\n",
      " loss : 0.01784 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01784 test_loss : 0.22102 train_metric : 0.96296 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 184 =====\n",
      " loss : 0.04585 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04585 test_loss : 0.20506 train_metric : 0.96296 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 185 =====\n",
      " loss : 0.01412 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01412 test_loss : 0.22491 train_metric : 1.00000 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 186 =====\n",
      " loss : 0.08629 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08629 test_loss : 0.21885 train_metric : 0.88889 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 187 =====\n",
      " loss : 0.00465 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00465 test_loss : 0.21079 train_metric : 1.00000 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 188 =====\n",
      " loss : 0.04505 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04505 test_loss : 0.21263 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 189 =====\n",
      " loss : 0.06161 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06161 test_loss : 0.21537 train_metric : 0.92593 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 190 =====\n",
      " loss : 0.02968 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02968 test_loss : 0.22724 train_metric : 0.96296 test_metric : 0.71875\n",
      "\n",
      "=====Epoch : 191 =====\n",
      " loss : 0.02295 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02295 test_loss : 0.23599 train_metric : 0.96296 test_metric : 0.70230\n",
      "\n",
      "=====Epoch : 192 =====\n",
      " loss : 0.01640 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01640 test_loss : 0.23195 train_metric : 0.96296 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 193 =====\n",
      " loss : 0.01487 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01487 test_loss : 0.21552 train_metric : 0.96296 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 194 =====\n",
      " loss : 0.15306 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15306 test_loss : 0.22804 train_metric : 0.85185 test_metric : 0.71875\n",
      "\n",
      "=====Epoch : 195 =====\n",
      " loss : 0.04121 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04121 test_loss : 0.22799 train_metric : 0.96296 test_metric : 0.71875\n",
      "\n",
      "=====Epoch : 196 =====\n",
      " loss : 0.01217 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01217 test_loss : 0.22056 train_metric : 1.00000 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 197 =====\n",
      " loss : 0.06323 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06323 test_loss : 0.22110 train_metric : 0.92593 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 198 =====\n",
      " loss : 0.00862 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00862 test_loss : 0.22072 train_metric : 1.00000 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 199 =====\n",
      " loss : 0.05835 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05835 test_loss : 0.22210 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 200 =====\n",
      " loss : 0.00126 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00126 test_loss : 0.23835 train_metric : 1.00000 test_metric : 0.72039\n",
      "\n",
      "=====Epoch : 201 =====\n",
      " loss : 0.00137 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00137 test_loss : 0.21439 train_metric : 1.00000 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 202 =====\n",
      " loss : 0.01213 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01213 test_loss : 0.23627 train_metric : 1.00000 test_metric : 0.71546\n",
      "\n",
      "=====Epoch : 203 =====\n",
      " loss : 0.04861 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04861 test_loss : 0.22252 train_metric : 0.92593 test_metric : 0.71053\n",
      "\n",
      "=====Epoch : 204 =====\n",
      " loss : 0.18186 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18186 test_loss : 0.23368 train_metric : 0.77778 test_metric : 0.70230\n",
      "\n",
      "=====Epoch : 205 =====\n",
      " loss : 0.00665 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00665 test_loss : 0.23999 train_metric : 1.00000 test_metric : 0.70888\n",
      "\n",
      "=====Epoch : 206 =====\n",
      " loss : 0.03909 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03909 test_loss : 0.23736 train_metric : 0.96296 test_metric : 0.70559\n",
      "\n",
      "=====Epoch : 207 =====\n",
      " loss : 0.07558 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07558 test_loss : 0.22900 train_metric : 0.92593 test_metric : 0.72039\n",
      "\n",
      "=====Epoch : 208 =====\n",
      " loss : 0.09716 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09716 test_loss : 0.22445 train_metric : 0.85185 test_metric : 0.71546\n",
      "\n",
      "=====Epoch : 209 =====\n",
      " loss : 0.00978 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00978 test_loss : 0.22902 train_metric : 1.00000 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 210 =====\n",
      " loss : 0.01314 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01314 test_loss : 0.23940 train_metric : 1.00000 test_metric : 0.69737\n",
      "\n",
      "=====Epoch : 211 =====\n",
      " loss : 0.08347 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08347 test_loss : 0.24418 train_metric : 0.92593 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 212 =====\n",
      " loss : 0.14981 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14981 test_loss : 0.22448 train_metric : 0.85185 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 213 =====\n",
      " loss : 0.10363 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10363 test_loss : 0.24063 train_metric : 0.88889 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 214 =====\n",
      " loss : 0.03614 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03614 test_loss : 0.22372 train_metric : 0.96296 test_metric : 0.72039\n",
      "\n",
      "=====Epoch : 215 =====\n",
      " loss : 0.01503 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01503 test_loss : 0.21128 train_metric : 0.96296 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 216 =====\n",
      " loss : 0.03968 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03968 test_loss : 0.22967 train_metric : 0.92593 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 217 =====\n",
      " loss : 0.00215 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00215 test_loss : 0.21073 train_metric : 1.00000 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 218 =====\n",
      " loss : 0.05389 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05389 test_loss : 0.22434 train_metric : 0.92593 test_metric : 0.71382\n",
      "\n",
      "=====Epoch : 219 =====\n",
      " loss : 0.12484 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12484 test_loss : 0.22333 train_metric : 0.85185 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 220 =====\n",
      " loss : 0.03728 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03728 test_loss : 0.21568 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 221 =====\n",
      " loss : 0.06807 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06807 test_loss : 0.21761 train_metric : 0.88889 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 222 =====\n",
      " loss : 0.00297 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00297 test_loss : 0.22936 train_metric : 1.00000 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 223 =====\n",
      " loss : 0.04039 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04039 test_loss : 0.23049 train_metric : 0.96296 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 224 =====\n",
      " loss : 0.03690 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03690 test_loss : 0.22836 train_metric : 0.96296 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 225 =====\n",
      " loss : 0.05375 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05375 test_loss : 0.22638 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 226 =====\n",
      " loss : 0.07799 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07799 test_loss : 0.23471 train_metric : 0.92593 test_metric : 0.71382\n",
      "\n",
      "=====Epoch : 227 =====\n",
      " loss : 0.05305 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05305 test_loss : 0.22911 train_metric : 0.96296 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 228 =====\n",
      " loss : 0.02496 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02496 test_loss : 0.23132 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 229 =====\n",
      " loss : 0.00949 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00949 test_loss : 0.21790 train_metric : 1.00000 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 230 =====\n",
      " loss : 0.06251 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06251 test_loss : 0.22272 train_metric : 0.92593 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 231 =====\n",
      " loss : 0.02354 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02354 test_loss : 0.23216 train_metric : 0.96296 test_metric : 0.71382\n",
      "\n",
      "=====Epoch : 232 =====\n",
      " loss : 0.07632 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07632 test_loss : 0.22861 train_metric : 0.85185 test_metric : 0.72039\n",
      "\n",
      "=====Epoch : 233 =====\n",
      " loss : 0.03706 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03706 test_loss : 0.23063 train_metric : 0.96296 test_metric : 0.71875\n",
      "\n",
      "=====Epoch : 234 =====\n",
      " loss : 0.03902 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03902 test_loss : 0.21938 train_metric : 0.96296 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 235 =====\n",
      " loss : 0.04526 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04526 test_loss : 0.22152 train_metric : 0.96296 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 236 =====\n",
      " loss : 0.04290 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04290 test_loss : 0.22063 train_metric : 0.96296 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 237 =====\n",
      " loss : 0.04691 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04691 test_loss : 0.22948 train_metric : 0.92593 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 238 =====\n",
      " loss : 0.03613 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03613 test_loss : 0.22196 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 239 =====\n",
      " loss : 0.00096 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00096 test_loss : 0.23391 train_metric : 1.00000 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 240 =====\n",
      " loss : 0.04448 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04448 test_loss : 0.21720 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 241 =====\n",
      " loss : 0.09891 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09891 test_loss : 0.22140 train_metric : 0.88889 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 242 =====\n",
      " loss : 0.00375 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00375 test_loss : 0.23402 train_metric : 1.00000 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 243 =====\n",
      " loss : 0.03675 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03675 test_loss : 0.23317 train_metric : 0.96296 test_metric : 0.71217\n",
      "\n",
      "=====Epoch : 244 =====\n",
      " loss : 0.06855 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06855 test_loss : 0.22830 train_metric : 0.92593 test_metric : 0.71875\n",
      "\n",
      "=====Epoch : 245 =====\n",
      " loss : 0.02130 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02130 test_loss : 0.22125 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 246 =====\n",
      " loss : 0.00459 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00459 test_loss : 0.20987 train_metric : 1.00000 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 247 =====\n",
      " loss : 0.00066 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00066 test_loss : 0.23147 train_metric : 1.00000 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 248 =====\n",
      " loss : 0.11241 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11241 test_loss : 0.23180 train_metric : 0.88889 test_metric : 0.71217\n",
      "\n",
      "=====Epoch : 249 =====\n",
      " loss : 0.03812 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03812 test_loss : 0.22818 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 250 =====\n",
      " loss : 0.01406 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01406 test_loss : 0.20907 train_metric : 1.00000 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 251 =====\n",
      " loss : 0.07623 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07623 test_loss : 0.24259 train_metric : 0.92593 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 252 =====\n",
      " loss : 0.02379 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02379 test_loss : 0.21847 train_metric : 0.96296 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 253 =====\n",
      " loss : 0.11329 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11329 test_loss : 0.22886 train_metric : 0.88889 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 254 =====\n",
      " loss : 0.01246 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01246 test_loss : 0.22586 train_metric : 1.00000 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 255 =====\n",
      " loss : 0.03663 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03663 test_loss : 0.23529 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 256 =====\n",
      " loss : 0.13418 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13418 test_loss : 0.21935 train_metric : 0.85185 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 257 =====\n",
      " loss : 0.02294 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02294 test_loss : 0.23415 train_metric : 0.96296 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 258 =====\n",
      " loss : 0.04080 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04080 test_loss : 0.22459 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 259 =====\n",
      " loss : 0.00128 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00128 test_loss : 0.21658 train_metric : 1.00000 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 260 =====\n",
      " loss : 0.03616 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03616 test_loss : 0.22570 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 261 =====\n",
      " loss : 0.05204 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05204 test_loss : 0.22426 train_metric : 0.92593 test_metric : 0.70724\n",
      "\n",
      "=====Epoch : 262 =====\n",
      " loss : 0.02634 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02634 test_loss : 0.23185 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 263 =====\n",
      " loss : 0.01082 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01082 test_loss : 0.22573 train_metric : 1.00000 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 264 =====\n",
      " loss : 0.02726 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02726 test_loss : 0.22986 train_metric : 0.96296 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 265 =====\n",
      " loss : 0.00581 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00581 test_loss : 0.22314 train_metric : 1.00000 test_metric : 0.71546\n",
      "\n",
      "=====Epoch : 266 =====\n",
      " loss : 0.10913 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10913 test_loss : 0.23152 train_metric : 0.88889 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 267 =====\n",
      " loss : 0.08425 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08425 test_loss : 0.22985 train_metric : 0.92593 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 268 =====\n",
      " loss : 0.01528 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01528 test_loss : 0.24076 train_metric : 0.96296 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 269 =====\n",
      " loss : 0.04528 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04528 test_loss : 0.22551 train_metric : 0.96296 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 270 =====\n",
      " loss : 0.01419 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01419 test_loss : 0.23201 train_metric : 0.96296 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 271 =====\n",
      " loss : 0.13207 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13207 test_loss : 0.20373 train_metric : 0.85185 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 272 =====\n",
      " loss : 0.01518 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01518 test_loss : 0.22255 train_metric : 1.00000 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 273 =====\n",
      " loss : 0.00522 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00522 test_loss : 0.21014 train_metric : 1.00000 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 274 =====\n",
      " loss : 0.01626 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01626 test_loss : 0.22931 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 275 =====\n",
      " loss : 0.00100 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00100 test_loss : 0.23381 train_metric : 1.00000 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 276 =====\n",
      " loss : 0.08538 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08538 test_loss : 0.23018 train_metric : 0.88889 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 277 =====\n",
      " loss : 0.03490 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03490 test_loss : 0.22502 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 278 =====\n",
      " loss : 0.04474 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04474 test_loss : 0.21498 train_metric : 0.92593 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 279 =====\n",
      " loss : 0.02358 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02358 test_loss : 0.21323 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 280 =====\n",
      " loss : 0.10411 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10411 test_loss : 0.21922 train_metric : 0.88889 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 281 =====\n",
      " loss : 0.02786 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.02786 test_loss : 0.21488 train_metric : 0.92593 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 282 =====\n",
      " loss : 0.03506 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03506 test_loss : 0.22401 train_metric : 0.96296 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 283 =====\n",
      " loss : 0.02267 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02267 test_loss : 0.22261 train_metric : 0.96296 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 284 =====\n",
      " loss : 0.03653 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03653 test_loss : 0.23267 train_metric : 0.96296 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 285 =====\n",
      " loss : 0.04388 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04388 test_loss : 0.23431 train_metric : 0.96296 test_metric : 0.71053\n",
      "\n",
      "=====Epoch : 286 =====\n",
      " loss : 0.04871 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04871 test_loss : 0.23544 train_metric : 0.96296 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 287 =====\n",
      " loss : 0.10018 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10018 test_loss : 0.21973 train_metric : 0.88889 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 288 =====\n",
      " loss : 0.04469 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04469 test_loss : 0.22993 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 289 =====\n",
      " loss : 0.01962 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01962 test_loss : 0.23434 train_metric : 1.00000 test_metric : 0.72039\n",
      "\n",
      "=====Epoch : 290 =====\n",
      " loss : 0.00775 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00775 test_loss : 0.23349 train_metric : 1.00000 test_metric : 0.72039\n",
      "\n",
      "=====Epoch : 291 =====\n",
      " loss : 0.01493 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01493 test_loss : 0.22234 train_metric : 0.96296 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 292 =====\n",
      " loss : 0.08277 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08277 test_loss : 0.23019 train_metric : 0.92593 test_metric : 0.71546\n",
      "\n",
      "=====Epoch : 293 =====\n",
      " loss : 0.00642 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00642 test_loss : 0.22218 train_metric : 1.00000 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 294 =====\n",
      " loss : 0.05442 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05442 test_loss : 0.23489 train_metric : 0.92593 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 295 =====\n",
      " loss : 0.03136 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03136 test_loss : 0.22321 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 296 =====\n",
      " loss : 0.06052 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06052 test_loss : 0.22791 train_metric : 0.92593 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 297 =====\n",
      " loss : 0.07753 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07753 test_loss : 0.22775 train_metric : 0.92593 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 298 =====\n",
      " loss : 0.00783 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00783 test_loss : 0.22772 train_metric : 1.00000 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 299 =====\n",
      " loss : 0.02114 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02114 test_loss : 0.22748 train_metric : 0.96296 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 300 =====\n",
      " loss : 0.05059 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05059 test_loss : 0.22391 train_metric : 0.96296 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 301 =====\n",
      " loss : 0.03931 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03931 test_loss : 0.22022 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 302 =====\n",
      " loss : 0.02684 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02684 test_loss : 0.23589 train_metric : 0.96296 test_metric : 0.70559\n",
      "\n",
      "=====Epoch : 303 =====\n",
      " loss : 0.04899 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04899 test_loss : 0.22719 train_metric : 0.96296 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 304 =====\n",
      " loss : 0.03879 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03879 test_loss : 0.21651 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 305 =====\n",
      " loss : 0.04414 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04414 test_loss : 0.23722 train_metric : 0.96296 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 306 =====\n",
      " loss : 0.05161 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05161 test_loss : 0.22785 train_metric : 0.92593 test_metric : 0.70888\n",
      "\n",
      "=====Epoch : 307 =====\n",
      " loss : 0.00700 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00700 test_loss : 0.22601 train_metric : 1.00000 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 308 =====\n",
      " loss : 0.05544 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05544 test_loss : 0.25338 train_metric : 0.92593 test_metric : 0.70559\n",
      "\n",
      "=====Epoch : 309 =====\n",
      " loss : 0.07824 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07824 test_loss : 0.22972 train_metric : 0.88889 test_metric : 0.71875\n",
      "\n",
      "=====Epoch : 310 =====\n",
      " loss : 0.02601 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02601 test_loss : 0.22867 train_metric : 0.96296 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 311 =====\n",
      " loss : 0.02302 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02302 test_loss : 0.22239 train_metric : 0.96296 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 312 =====\n",
      " loss : 0.03218 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03218 test_loss : 0.22883 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 313 =====\n",
      " loss : 0.04208 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04208 test_loss : 0.21834 train_metric : 0.96296 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 314 =====\n",
      " loss : 0.03873 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03873 test_loss : 0.22594 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 315 =====\n",
      " loss : 0.01485 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01485 test_loss : 0.22005 train_metric : 0.96296 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 316 =====\n",
      " loss : 0.01168 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01168 test_loss : 0.22404 train_metric : 1.00000 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 317 =====\n",
      " loss : 0.07073 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07073 test_loss : 0.22599 train_metric : 0.92593 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 318 =====\n",
      " loss : 0.03773 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03773 test_loss : 0.22545 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 319 =====\n",
      " loss : 0.06968 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06968 test_loss : 0.22781 train_metric : 0.92593 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 320 =====\n",
      " loss : 0.05133 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05133 test_loss : 0.20641 train_metric : 0.92593 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 321 =====\n",
      " loss : 0.00308 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00308 test_loss : 0.20816 train_metric : 1.00000 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 322 =====\n",
      " loss : 0.00081 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00081 test_loss : 0.21990 train_metric : 1.00000 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 323 =====\n",
      " loss : 0.04050 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04050 test_loss : 0.22205 train_metric : 0.96296 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 324 =====\n",
      " loss : 0.07114 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07114 test_loss : 0.23241 train_metric : 0.92593 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 325 =====\n",
      " loss : 0.00684 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00684 test_loss : 0.21345 train_metric : 1.00000 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 326 =====\n",
      " loss : 0.09789 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09789 test_loss : 0.22390 train_metric : 0.88889 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 327 =====\n",
      " loss : 0.03614 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03614 test_loss : 0.21340 train_metric : 0.96296 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 328 =====\n",
      " loss : 0.03886 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03886 test_loss : 0.22121 train_metric : 0.96296 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 329 =====\n",
      " loss : 0.00587 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00587 test_loss : 0.20987 train_metric : 1.00000 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 330 =====\n",
      " loss : 0.04159 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04159 test_loss : 0.22960 train_metric : 0.96296 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 331 =====\n",
      " loss : 0.11560 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11560 test_loss : 0.19771 train_metric : 0.88889 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 332 =====\n",
      " loss : 0.10653 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10653 test_loss : 0.22705 train_metric : 0.88889 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 333 =====\n",
      " loss : 0.04648 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.04648 test_loss : 0.21925 train_metric : 0.88889 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 334 =====\n",
      " loss : 0.04091 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04091 test_loss : 0.21076 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 335 =====\n",
      " loss : 0.01080 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01080 test_loss : 0.21680 train_metric : 1.00000 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 336 =====\n",
      " loss : 0.00610 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00610 test_loss : 0.22282 train_metric : 1.00000 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 337 =====\n",
      " loss : 0.07287 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07287 test_loss : 0.21705 train_metric : 0.92593 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 338 =====\n",
      " loss : 0.01134 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01134 test_loss : 0.21256 train_metric : 0.96296 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 339 =====\n",
      " loss : 0.02121 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02121 test_loss : 0.23670 train_metric : 0.96296 test_metric : 0.71875\n",
      "\n",
      "=====Epoch : 340 =====\n",
      " loss : 0.04164 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04164 test_loss : 0.23892 train_metric : 0.96296 test_metric : 0.71382\n",
      "\n",
      "=====Epoch : 341 =====\n",
      " loss : 0.07655 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07655 test_loss : 0.20064 train_metric : 0.92593 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 342 =====\n",
      " loss : 0.05251 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05251 test_loss : 0.20991 train_metric : 0.92593 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 343 =====\n",
      " loss : 0.04283 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04283 test_loss : 0.21265 train_metric : 0.96296 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 344 =====\n",
      " loss : 0.07377 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07377 test_loss : 0.21387 train_metric : 0.92593 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 345 =====\n",
      " loss : 0.03494 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03494 test_loss : 0.20880 train_metric : 0.96296 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 346 =====\n",
      " loss : 0.01670 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01670 test_loss : 0.21696 train_metric : 0.96296 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 347 =====\n",
      " loss : 0.00491 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00491 test_loss : 0.21161 train_metric : 1.00000 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 348 =====\n",
      " loss : 0.04274 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04274 test_loss : 0.21414 train_metric : 0.92593 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 349 =====\n",
      " loss : 0.05605 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05605 test_loss : 0.20901 train_metric : 0.92593 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 350 =====\n",
      " loss : 0.07253 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07253 test_loss : 0.21787 train_metric : 0.92593 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 351 =====\n",
      " loss : 0.03711 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03711 test_loss : 0.19856 train_metric : 0.92593 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 352 =====\n",
      " loss : 0.02945 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02945 test_loss : 0.21187 train_metric : 0.96296 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 353 =====\n",
      " loss : 0.00791 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00791 test_loss : 0.21756 train_metric : 1.00000 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 354 =====\n",
      " loss : 0.02489 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02489 test_loss : 0.21830 train_metric : 0.96296 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 355 =====\n",
      " loss : 0.00097 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00097 test_loss : 0.21633 train_metric : 1.00000 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 356 =====\n",
      " loss : 0.03280 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03280 test_loss : 0.22408 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 357 =====\n",
      " loss : 0.04186 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04186 test_loss : 0.21068 train_metric : 0.96296 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 358 =====\n",
      " loss : 0.08056 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08056 test_loss : 0.20755 train_metric : 0.92593 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 359 =====\n",
      " loss : 0.09061 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09061 test_loss : 0.20267 train_metric : 0.88889 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 360 =====\n",
      " loss : 0.07365 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07365 test_loss : 0.22122 train_metric : 0.92593 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 361 =====\n",
      " loss : 0.02303 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02303 test_loss : 0.21231 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 362 =====\n",
      " loss : 0.03949 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03949 test_loss : 0.21178 train_metric : 0.96296 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 363 =====\n",
      " loss : 0.01862 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01862 test_loss : 0.23716 train_metric : 0.96296 test_metric : 0.71546\n",
      "\n",
      "=====Epoch : 364 =====\n",
      " loss : 0.04258 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04258 test_loss : 0.22624 train_metric : 0.96296 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 365 =====\n",
      " loss : 0.03626 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03626 test_loss : 0.21393 train_metric : 0.96296 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 366 =====\n",
      " loss : 0.07356 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07356 test_loss : 0.21911 train_metric : 0.92593 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 367 =====\n",
      " loss : 0.03528 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03528 test_loss : 0.21164 train_metric : 0.96296 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 368 =====\n",
      " loss : 0.00615 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00615 test_loss : 0.21885 train_metric : 1.00000 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 369 =====\n",
      " loss : 0.03891 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03891 test_loss : 0.22536 train_metric : 0.96296 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 370 =====\n",
      " loss : 0.02961 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02961 test_loss : 0.22876 train_metric : 0.96296 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 371 =====\n",
      " loss : 0.00824 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00824 test_loss : 0.19575 train_metric : 1.00000 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 372 =====\n",
      " loss : 0.03827 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03827 test_loss : 0.21664 train_metric : 0.96296 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 373 =====\n",
      " loss : 0.03307 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03307 test_loss : 0.20303 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 374 =====\n",
      " loss : 0.08493 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08493 test_loss : 0.22290 train_metric : 0.88889 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 375 =====\n",
      " loss : 0.02226 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02226 test_loss : 0.20739 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 376 =====\n",
      " loss : 0.00483 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00483 test_loss : 0.21694 train_metric : 1.00000 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 377 =====\n",
      " loss : 0.07264 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07264 test_loss : 0.20667 train_metric : 0.92593 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 378 =====\n",
      " loss : 0.00226 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00226 test_loss : 0.21662 train_metric : 1.00000 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 379 =====\n",
      " loss : 0.00281 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00281 test_loss : 0.21911 train_metric : 1.00000 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 380 =====\n",
      " loss : 0.03739 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03739 test_loss : 0.20833 train_metric : 0.96296 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 381 =====\n",
      " loss : 0.07011 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07011 test_loss : 0.21663 train_metric : 0.88889 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 382 =====\n",
      " loss : 0.02861 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02861 test_loss : 0.21793 train_metric : 0.96296 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 383 =====\n",
      " loss : 0.03721 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03721 test_loss : 0.22118 train_metric : 0.96296 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 384 =====\n",
      " loss : 0.06095 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06095 test_loss : 0.20594 train_metric : 0.92593 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 385 =====\n",
      " loss : 0.05775 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05775 test_loss : 0.21520 train_metric : 0.92593 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 386 =====\n",
      " loss : 0.00245 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00245 test_loss : 0.20869 train_metric : 1.00000 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 387 =====\n",
      " loss : 0.03829 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03829 test_loss : 0.20681 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 388 =====\n",
      " loss : 0.00321 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00321 test_loss : 0.22227 train_metric : 1.00000 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 389 =====\n",
      " loss : 0.02008 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02008 test_loss : 0.22756 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 390 =====\n",
      " loss : 0.00179 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00179 test_loss : 0.22673 train_metric : 1.00000 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 391 =====\n",
      " loss : 0.01111 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01111 test_loss : 0.21985 train_metric : 0.96296 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 392 =====\n",
      " loss : 0.03781 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03781 test_loss : 0.22812 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 393 =====\n",
      " loss : 0.01274 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01274 test_loss : 0.21768 train_metric : 1.00000 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 394 =====\n",
      " loss : 0.05087 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05087 test_loss : 0.21416 train_metric : 0.96296 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 395 =====\n",
      " loss : 0.14995 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14995 test_loss : 0.21006 train_metric : 0.81481 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 396 =====\n",
      " loss : 0.13249 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13249 test_loss : 0.18965 train_metric : 0.81481 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 397 =====\n",
      " loss : 0.00309 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00309 test_loss : 0.20442 train_metric : 1.00000 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 398 =====\n",
      " loss : 0.00555 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00555 test_loss : 0.21320 train_metric : 1.00000 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 399 =====\n",
      " loss : 0.07993 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07993 test_loss : 0.21059 train_metric : 0.88889 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 400 =====\n",
      " loss : 0.09104 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09104 test_loss : 0.21090 train_metric : 0.88889 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 401 =====\n",
      " loss : 0.00216 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00216 test_loss : 0.20747 train_metric : 1.00000 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 402 =====\n",
      " loss : 0.03773 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03773 test_loss : 0.21545 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 403 =====\n",
      " loss : 0.04729 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04729 test_loss : 0.21713 train_metric : 0.96296 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 404 =====\n",
      " loss : 0.02899 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02899 test_loss : 0.22730 train_metric : 0.96296 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 405 =====\n",
      " loss : 0.04244 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04244 test_loss : 0.21857 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 406 =====\n",
      " loss : 0.04418 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04418 test_loss : 0.20777 train_metric : 0.92593 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 407 =====\n",
      " loss : 0.02936 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02936 test_loss : 0.20391 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 408 =====\n",
      " loss : 0.01935 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01935 test_loss : 0.21333 train_metric : 0.96296 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 409 =====\n",
      " loss : 0.07037 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07037 test_loss : 0.20940 train_metric : 0.92593 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 410 =====\n",
      " loss : 0.03723 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03723 test_loss : 0.21397 train_metric : 0.96296 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 411 =====\n",
      " loss : 0.00176 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00176 test_loss : 0.23050 train_metric : 1.00000 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 412 =====\n",
      " loss : 0.05102 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05102 test_loss : 0.20421 train_metric : 0.88889 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 413 =====\n",
      " loss : 0.03939 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03939 test_loss : 0.20990 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 414 =====\n",
      " loss : 0.07182 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07182 test_loss : 0.23435 train_metric : 0.92593 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 415 =====\n",
      " loss : 0.03866 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03866 test_loss : 0.22245 train_metric : 0.96296 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 416 =====\n",
      " loss : 0.00409 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00409 test_loss : 0.22353 train_metric : 1.00000 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 417 =====\n",
      " loss : 0.00070 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00070 test_loss : 0.21813 train_metric : 1.00000 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 418 =====\n",
      " loss : 0.03834 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03834 test_loss : 0.20488 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 419 =====\n",
      " loss : 0.06495 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06495 test_loss : 0.22624 train_metric : 0.92593 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 420 =====\n",
      " loss : 0.07287 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07287 test_loss : 0.21109 train_metric : 0.92593 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 421 =====\n",
      " loss : 0.00489 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00489 test_loss : 0.21437 train_metric : 1.00000 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 422 =====\n",
      " loss : 0.01168 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01168 test_loss : 0.22149 train_metric : 1.00000 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 423 =====\n",
      " loss : 0.01928 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01928 test_loss : 0.21715 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 424 =====\n",
      " loss : 0.11230 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11230 test_loss : 0.20103 train_metric : 0.85185 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 425 =====\n",
      " loss : 0.16213 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16213 test_loss : 0.19672 train_metric : 0.81481 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 426 =====\n",
      " loss : 0.11106 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11106 test_loss : 0.20852 train_metric : 0.81481 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 427 =====\n",
      " loss : 0.19400 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.19400 test_loss : 0.18831 train_metric : 0.74074 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 428 =====\n",
      " loss : 0.04963 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04963 test_loss : 0.22424 train_metric : 0.96296 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 429 =====\n",
      " loss : 0.11788 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11788 test_loss : 0.18961 train_metric : 0.85185 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 430 =====\n",
      " loss : 0.08257 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08257 test_loss : 0.20692 train_metric : 0.88889 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 431 =====\n",
      " loss : 0.02742 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02742 test_loss : 0.20134 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 432 =====\n",
      " loss : 0.00690 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00690 test_loss : 0.21585 train_metric : 1.00000 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 433 =====\n",
      " loss : 0.01230 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01230 test_loss : 0.21212 train_metric : 1.00000 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 434 =====\n",
      " loss : 0.07392 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07392 test_loss : 0.18620 train_metric : 0.92593 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 435 =====\n",
      " loss : 0.09910 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09910 test_loss : 0.19968 train_metric : 0.88889 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 436 =====\n",
      " loss : 0.00996 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00996 test_loss : 0.20156 train_metric : 1.00000 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 437 =====\n",
      " loss : 0.00497 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00497 test_loss : 0.20539 train_metric : 1.00000 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 438 =====\n",
      " loss : 0.03141 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03141 test_loss : 0.20010 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 439 =====\n",
      " loss : 0.05348 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05348 test_loss : 0.21761 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 440 =====\n",
      " loss : 0.08376 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08376 test_loss : 0.21980 train_metric : 0.88889 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 441 =====\n",
      " loss : 0.02982 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02982 test_loss : 0.22432 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 442 =====\n",
      " loss : 0.03748 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03748 test_loss : 0.21897 train_metric : 0.96296 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 443 =====\n",
      " loss : 0.12849 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12849 test_loss : 0.21840 train_metric : 0.81481 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 444 =====\n",
      " loss : 0.04073 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04073 test_loss : 0.20073 train_metric : 0.96296 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 445 =====\n",
      " loss : 0.00671 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00671 test_loss : 0.20506 train_metric : 1.00000 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 446 =====\n",
      " loss : 0.13126 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13126 test_loss : 0.21385 train_metric : 0.85185 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 447 =====\n",
      " loss : 0.03980 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03980 test_loss : 0.21313 train_metric : 0.96296 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 448 =====\n",
      " loss : 0.02429 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02429 test_loss : 0.20786 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 449 =====\n",
      " loss : 0.04640 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04640 test_loss : 0.19969 train_metric : 0.96296 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 450 =====\n",
      " loss : 0.02621 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02621 test_loss : 0.19464 train_metric : 0.96296 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 451 =====\n",
      " loss : 0.02827 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02827 test_loss : 0.21135 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 452 =====\n",
      " loss : 0.05162 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05162 test_loss : 0.20942 train_metric : 0.92593 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 453 =====\n",
      " loss : 0.00643 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00643 test_loss : 0.18921 train_metric : 1.00000 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 454 =====\n",
      " loss : 0.00379 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00379 test_loss : 0.21782 train_metric : 1.00000 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 455 =====\n",
      " loss : 0.05343 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05343 test_loss : 0.20468 train_metric : 0.92593 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 456 =====\n",
      " loss : 0.03671 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.03671 test_loss : 0.20773 train_metric : 0.88889 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 457 =====\n",
      " loss : 0.00420 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00420 test_loss : 0.20740 train_metric : 1.00000 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 458 =====\n",
      " loss : 0.01704 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01704 test_loss : 0.20238 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 459 =====\n",
      " loss : 0.03249 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03249 test_loss : 0.21491 train_metric : 0.96296 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 460 =====\n",
      " loss : 0.02810 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02810 test_loss : 0.20595 train_metric : 1.00000 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 461 =====\n",
      " loss : 0.04704 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04704 test_loss : 0.20125 train_metric : 0.96296 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 462 =====\n",
      " loss : 0.02757 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02757 test_loss : 0.22388 train_metric : 0.96296 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 463 =====\n",
      " loss : 0.06370 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06370 test_loss : 0.21164 train_metric : 0.92593 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 464 =====\n",
      " loss : 0.04418 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04418 test_loss : 0.20784 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 465 =====\n",
      " loss : 0.03875 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03875 test_loss : 0.21210 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 466 =====\n",
      " loss : 0.06776 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06776 test_loss : 0.22551 train_metric : 0.92593 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 467 =====\n",
      " loss : 0.07283 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07283 test_loss : 0.21672 train_metric : 0.92593 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 468 =====\n",
      " loss : 0.06803 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06803 test_loss : 0.22511 train_metric : 0.92593 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 469 =====\n",
      " loss : 0.04265 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04265 test_loss : 0.20885 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 470 =====\n",
      " loss : 0.04057 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04057 test_loss : 0.21865 train_metric : 0.96296 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 471 =====\n",
      " loss : 0.01290 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01290 test_loss : 0.22990 train_metric : 1.00000 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 472 =====\n",
      " loss : 0.00078 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00078 test_loss : 0.21384 train_metric : 1.00000 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 473 =====\n",
      " loss : 0.01313 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01313 test_loss : 0.22655 train_metric : 0.96296 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 474 =====\n",
      " loss : 0.00163 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00163 test_loss : 0.20653 train_metric : 1.00000 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 475 =====\n",
      " loss : 0.04356 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04356 test_loss : 0.21749 train_metric : 0.96296 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 476 =====\n",
      " loss : 0.08357 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08357 test_loss : 0.21006 train_metric : 0.88889 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 477 =====\n",
      " loss : 0.03172 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03172 test_loss : 0.21070 train_metric : 0.96296 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 478 =====\n",
      " loss : 0.13516 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13516 test_loss : 0.23402 train_metric : 0.85185 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 479 =====\n",
      " loss : 0.03674 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03674 test_loss : 0.21474 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 480 =====\n",
      " loss : 0.00498 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00498 test_loss : 0.20131 train_metric : 1.00000 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 481 =====\n",
      " loss : 0.06074 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06074 test_loss : 0.21692 train_metric : 0.92593 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 482 =====\n",
      " loss : 0.01570 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01570 test_loss : 0.22144 train_metric : 0.96296 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 483 =====\n",
      " loss : 0.02688 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02688 test_loss : 0.22202 train_metric : 0.96296 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 484 =====\n",
      " loss : 0.00235 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00235 test_loss : 0.20556 train_metric : 1.00000 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 485 =====\n",
      " loss : 0.04515 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04515 test_loss : 0.21964 train_metric : 0.96296 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 486 =====\n",
      " loss : 0.03788 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03788 test_loss : 0.20160 train_metric : 0.96296 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 487 =====\n",
      " loss : 0.04484 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04484 test_loss : 0.20748 train_metric : 0.92593 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 488 =====\n",
      " loss : 0.01945 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01945 test_loss : 0.21059 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 489 =====\n",
      " loss : 0.02280 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02280 test_loss : 0.20943 train_metric : 0.96296 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 490 =====\n",
      " loss : 0.00849 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00849 test_loss : 0.22281 train_metric : 1.00000 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 491 =====\n",
      " loss : 0.02794 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02794 test_loss : 0.20880 train_metric : 0.96296 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 492 =====\n",
      " loss : 0.08275 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08275 test_loss : 0.20798 train_metric : 0.92593 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 493 =====\n",
      " loss : 0.02293 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02293 test_loss : 0.21438 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 494 =====\n",
      " loss : 0.02390 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02390 test_loss : 0.21650 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 495 =====\n",
      " loss : 0.07014 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07014 test_loss : 0.22180 train_metric : 0.92593 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 496 =====\n",
      " loss : 0.01938 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01938 test_loss : 0.21039 train_metric : 0.96296 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 497 =====\n",
      " loss : 0.04160 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04160 test_loss : 0.21677 train_metric : 0.96296 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 498 =====\n",
      " loss : 0.01364 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01364 test_loss : 0.23335 train_metric : 1.00000 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 499 =====\n",
      " loss : 0.00715 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00715 test_loss : 0.23948 train_metric : 1.00000 test_metric : 0.71546\n",
      "\n",
      "=====Epoch : 500 =====\n",
      " loss : 0.00558 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00558 test_loss : 0.22041 train_metric : 1.00000 test_metric : 0.75000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_rnnqe = rnnqe_train.train(500, seq_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_rnnqe.state_dict(), \"./models/pca_RNNQE_loss220.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
