{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum\n",
    "import pennylane as qml\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Numpy, Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Layer\n",
    "from kan import KAN\n",
    "from RNN_block import RNN_block\n",
    "# Data processing\n",
    "# from fucntions_1028 import data_seq, train_seq\n",
    "from fucntions import data_seq, train_seq\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Quantum User-Def Classes\n",
    "from utils import my_utils\n",
    "from NQE_class import NQE\n",
    "from NQE_train_class import NQE_Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3168\n",
      "dataset length : 3168\n",
      "test_size : 608\n",
      "train_size : 2560\n",
      "dataset length : 3163\n",
      "test_size : 608\n",
      "train_size : 2555\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 경로\n",
    "feature_path = './data/pca/pca_train_data_Perth.csv'\n",
    "label_path = './data/pca/pca_label_data_Perth.csv'\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "new_size = (len(pd.read_csv(feature_path).values) // batch_size) * batch_size\n",
    "print(new_size)\n",
    "\n",
    "# CSV 파일을 읽어 Tensor로 변환\n",
    "feature_data = torch.tensor(pd.read_csv(feature_path).values[:], dtype=torch.float32)\n",
    "label_data = torch.tensor(pd.read_csv(label_path).values[:], dtype=torch.float32)\n",
    "\n",
    "# data_seq 객체 생성\n",
    "data = data_seq(feature_data, label_data)\n",
    "\n",
    "train_loader, test_loader = data.split_data(test_ratio = 0.2, batch_size=batch_size, seq_first = False, for_nqe = True, n_sequence=0, seed = 40)\n",
    "rnn_train_loader, rnn_test_loader = data.split_data(test_ratio = 0.2, batch_size=batch_size, seq_first = False, for_nqe = True, n_sequence=5, seed = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 4])\n",
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for t, l in train_loader:\n",
    "    print(t.shape)\n",
    "    print(l.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 5, 4])\n",
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for t, l in rnn_train_loader:\n",
    "    print(t.shape)\n",
    "    print(l.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(pred, label):\n",
    "    '''\n",
    "        pred : inner product of two states\n",
    "        label : label data\n",
    "    '''\n",
    "    # print('pred : ', pred.shape)\n",
    "    # print('label :', label.shape)\n",
    "    # print('lbl[:, 0][-1] :', label[:, 0][-1])\n",
    "    # print('2nd term :', (label[:, 0] * label[:, 1] + 1).shape)\n",
    "    # loss = torch.sum((pred - label[:]) ** 2) / len(pred)\n",
    "    loss = torch.sum(((pred) - 0.5 * (label[:, 0] * label[:, 1] + 1)) ** 2 ) / len(pred)\n",
    "    return loss\n",
    "\n",
    "def accuarcy(pred, label):\n",
    "    '''\n",
    "        pred : inner product of two states\n",
    "        label : label data\n",
    "    '''\n",
    "    acc = torch.sum((torch.round(pred) == torch.round(0.5 * (label[:, 0] * label[:, 1] + 1)))) / len(pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC NQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch : 1 =====\n",
      " loss : 0.09484 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09484 test_loss : 0.15535 train_metric : 0.84375 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 2 =====\n",
      " loss : 0.11835 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.11835 test_loss : 0.15188 train_metric : 0.81250 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 3 =====\n",
      " loss : 0.10309 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10309 test_loss : 0.15048 train_metric : 0.87500 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 4 =====\n",
      " loss : 0.12521 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12521 test_loss : 0.14334 train_metric : 0.84375 test_metric : 0.80921\n",
      "\n",
      "=====Epoch : 5 =====\n",
      " loss : 0.11084 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11084 test_loss : 0.14950 train_metric : 0.87500 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 6 =====\n",
      " loss : 0.12429 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12429 test_loss : 0.14629 train_metric : 0.81250 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 7 =====\n",
      " loss : 0.17851 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.17851 test_loss : 0.15058 train_metric : 0.78125 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 8 =====\n",
      " loss : 0.25296 metric0 : 0.71875\n",
      "\n",
      " train_loss : 0.25296 test_loss : 0.14760 train_metric : 0.71875 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 9 =====\n",
      " loss : 0.08115 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08115 test_loss : 0.15348 train_metric : 0.90625 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 10 =====\n",
      " loss : 0.14055 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.14055 test_loss : 0.16356 train_metric : 0.75000 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 11 =====\n",
      " loss : 0.11517 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11517 test_loss : 0.14129 train_metric : 0.84375 test_metric : 0.80757\n",
      "\n",
      "=====Epoch : 12 =====\n",
      " loss : 0.10719 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10719 test_loss : 0.14575 train_metric : 0.84375 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 13 =====\n",
      " loss : 0.08815 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08815 test_loss : 0.14970 train_metric : 0.87500 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 14 =====\n",
      " loss : 0.11954 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11954 test_loss : 0.14358 train_metric : 0.84375 test_metric : 0.81086\n",
      "\n",
      "=====Epoch : 15 =====\n",
      " loss : 0.16340 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.16340 test_loss : 0.15189 train_metric : 0.78125 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 16 =====\n",
      " loss : 0.18286 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.18286 test_loss : 0.15530 train_metric : 0.75000 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 17 =====\n",
      " loss : 0.18564 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.18564 test_loss : 0.16078 train_metric : 0.78125 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 18 =====\n",
      " loss : 0.13694 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.13694 test_loss : 0.16287 train_metric : 0.78125 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 19 =====\n",
      " loss : 0.09028 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09028 test_loss : 0.14917 train_metric : 0.90625 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 20 =====\n",
      " loss : 0.12041 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12041 test_loss : 0.15658 train_metric : 0.84375 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 21 =====\n",
      " loss : 0.14790 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.14790 test_loss : 0.14916 train_metric : 0.78125 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 22 =====\n",
      " loss : 0.12028 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12028 test_loss : 0.15107 train_metric : 0.84375 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 23 =====\n",
      " loss : 0.27911 metric0 : 0.62500\n",
      "\n",
      " train_loss : 0.27911 test_loss : 0.14812 train_metric : 0.62500 test_metric : 0.80592\n",
      "\n",
      "=====Epoch : 24 =====\n",
      " loss : 0.10223 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10223 test_loss : 0.15594 train_metric : 0.87500 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 25 =====\n",
      " loss : 0.05228 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.05228 test_loss : 0.15699 train_metric : 0.96875 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 26 =====\n",
      " loss : 0.14612 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14612 test_loss : 0.15625 train_metric : 0.84375 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 27 =====\n",
      " loss : 0.09672 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09672 test_loss : 0.16600 train_metric : 0.90625 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 28 =====\n",
      " loss : 0.16777 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.16777 test_loss : 0.15887 train_metric : 0.78125 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 29 =====\n",
      " loss : 0.06906 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06906 test_loss : 0.15919 train_metric : 0.93750 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 30 =====\n",
      " loss : 0.14142 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14142 test_loss : 0.15431 train_metric : 0.81250 test_metric : 0.80592\n",
      "\n",
      "=====Epoch : 31 =====\n",
      " loss : 0.15127 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.15127 test_loss : 0.16200 train_metric : 0.78125 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 32 =====\n",
      " loss : 0.10836 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10836 test_loss : 0.15447 train_metric : 0.84375 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 33 =====\n",
      " loss : 0.14421 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14421 test_loss : 0.15621 train_metric : 0.81250 test_metric : 0.80757\n",
      "\n",
      "=====Epoch : 34 =====\n",
      " loss : 0.15213 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.15213 test_loss : 0.16038 train_metric : 0.81250 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 35 =====\n",
      " loss : 0.08967 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08967 test_loss : 0.15531 train_metric : 0.90625 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 36 =====\n",
      " loss : 0.09687 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.09687 test_loss : 0.15509 train_metric : 0.81250 test_metric : 0.80757\n",
      "\n",
      "=====Epoch : 37 =====\n",
      " loss : 0.16152 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.16152 test_loss : 0.14922 train_metric : 0.81250 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 38 =====\n",
      " loss : 0.08706 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08706 test_loss : 0.15769 train_metric : 0.90625 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 39 =====\n",
      " loss : 0.18123 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.18123 test_loss : 0.14960 train_metric : 0.75000 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 40 =====\n",
      " loss : 0.09425 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09425 test_loss : 0.15307 train_metric : 0.87500 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 41 =====\n",
      " loss : 0.09785 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09785 test_loss : 0.15713 train_metric : 0.87500 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 42 =====\n",
      " loss : 0.12954 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12954 test_loss : 0.15672 train_metric : 0.81250 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 43 =====\n",
      " loss : 0.10969 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10969 test_loss : 0.15102 train_metric : 0.84375 test_metric : 0.82072\n",
      "\n",
      "=====Epoch : 44 =====\n",
      " loss : 0.14776 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14776 test_loss : 0.15176 train_metric : 0.84375 test_metric : 0.80428\n",
      "\n",
      "=====Epoch : 45 =====\n",
      " loss : 0.16098 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.16098 test_loss : 0.15960 train_metric : 0.81250 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 46 =====\n",
      " loss : 0.16093 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.16093 test_loss : 0.15917 train_metric : 0.78125 test_metric : 0.80592\n",
      "\n",
      "=====Epoch : 47 =====\n",
      " loss : 0.17977 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.17977 test_loss : 0.14507 train_metric : 0.78125 test_metric : 0.81414\n",
      "\n",
      "=====Epoch : 48 =====\n",
      " loss : 0.13171 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.13171 test_loss : 0.15298 train_metric : 0.84375 test_metric : 0.80592\n",
      "\n",
      "=====Epoch : 49 =====\n",
      " loss : 0.13258 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13258 test_loss : 0.15336 train_metric : 0.81250 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 50 =====\n",
      " loss : 0.15396 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.15396 test_loss : 0.15918 train_metric : 0.78125 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 51 =====\n",
      " loss : 0.09782 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09782 test_loss : 0.15647 train_metric : 0.90625 test_metric : 0.80428\n",
      "\n",
      "=====Epoch : 52 =====\n",
      " loss : 0.08632 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08632 test_loss : 0.15545 train_metric : 0.90625 test_metric : 0.80757\n",
      "\n",
      "=====Epoch : 53 =====\n",
      " loss : 0.13031 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.13031 test_loss : 0.15203 train_metric : 0.84375 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 54 =====\n",
      " loss : 0.11067 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11067 test_loss : 0.15663 train_metric : 0.87500 test_metric : 0.80592\n",
      "\n",
      "=====Epoch : 55 =====\n",
      " loss : 0.12860 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.12860 test_loss : 0.15308 train_metric : 0.78125 test_metric : 0.80921\n",
      "\n",
      "=====Epoch : 56 =====\n",
      " loss : 0.13132 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.13132 test_loss : 0.16283 train_metric : 0.84375 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 57 =====\n",
      " loss : 0.13659 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.13659 test_loss : 0.14940 train_metric : 0.84375 test_metric : 0.81414\n",
      "\n",
      "=====Epoch : 58 =====\n",
      " loss : 0.14348 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.14348 test_loss : 0.15600 train_metric : 0.78125 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 59 =====\n",
      " loss : 0.10469 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10469 test_loss : 0.16097 train_metric : 0.84375 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 60 =====\n",
      " loss : 0.16230 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.16230 test_loss : 0.15618 train_metric : 0.78125 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 61 =====\n",
      " loss : 0.18788 metric0 : 0.71875\n",
      "\n",
      " train_loss : 0.18788 test_loss : 0.15828 train_metric : 0.71875 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 62 =====\n",
      " loss : 0.13373 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13373 test_loss : 0.16391 train_metric : 0.81250 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 63 =====\n",
      " loss : 0.05771 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.05771 test_loss : 0.15481 train_metric : 0.90625 test_metric : 0.81414\n",
      "\n",
      "=====Epoch : 64 =====\n",
      " loss : 0.09828 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09828 test_loss : 0.16095 train_metric : 0.87500 test_metric : 0.80757\n",
      "\n",
      "=====Epoch : 65 =====\n",
      " loss : 0.18973 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.18973 test_loss : 0.15692 train_metric : 0.75000 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 66 =====\n",
      " loss : 0.13528 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13528 test_loss : 0.16097 train_metric : 0.81250 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 67 =====\n",
      " loss : 0.11155 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.11155 test_loss : 0.16142 train_metric : 0.90625 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 68 =====\n",
      " loss : 0.12875 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12875 test_loss : 0.16429 train_metric : 0.84375 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 69 =====\n",
      " loss : 0.13495 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13495 test_loss : 0.14945 train_metric : 0.81250 test_metric : 0.82566\n",
      "\n",
      "=====Epoch : 70 =====\n",
      " loss : 0.11246 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.11246 test_loss : 0.15571 train_metric : 0.81250 test_metric : 0.81086\n",
      "\n",
      "=====Epoch : 71 =====\n",
      " loss : 0.08151 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08151 test_loss : 0.16176 train_metric : 0.90625 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 72 =====\n",
      " loss : 0.22551 metric0 : 0.68750\n",
      "\n",
      " train_loss : 0.22551 test_loss : 0.14905 train_metric : 0.68750 test_metric : 0.80757\n",
      "\n",
      "=====Epoch : 73 =====\n",
      " loss : 0.15591 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.15591 test_loss : 0.17450 train_metric : 0.81250 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 74 =====\n",
      " loss : 0.02617 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02617 test_loss : 0.15712 train_metric : 1.00000 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 75 =====\n",
      " loss : 0.13608 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13608 test_loss : 0.15982 train_metric : 0.81250 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 76 =====\n",
      " loss : 0.10842 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10842 test_loss : 0.15537 train_metric : 0.87500 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 77 =====\n",
      " loss : 0.09740 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09740 test_loss : 0.16588 train_metric : 0.84375 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 78 =====\n",
      " loss : 0.09116 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09116 test_loss : 0.16267 train_metric : 0.90625 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 79 =====\n",
      " loss : 0.10375 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.10375 test_loss : 0.16412 train_metric : 0.90625 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 80 =====\n",
      " loss : 0.18164 metric0 : 0.71875\n",
      "\n",
      " train_loss : 0.18164 test_loss : 0.16580 train_metric : 0.71875 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 81 =====\n",
      " loss : 0.08123 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08123 test_loss : 0.16264 train_metric : 0.87500 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 82 =====\n",
      " loss : 0.19009 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.19009 test_loss : 0.15680 train_metric : 0.75000 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 83 =====\n",
      " loss : 0.14593 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14593 test_loss : 0.15454 train_metric : 0.81250 test_metric : 0.80592\n",
      "\n",
      "=====Epoch : 84 =====\n",
      " loss : 0.04785 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04785 test_loss : 0.15612 train_metric : 0.96875 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 85 =====\n",
      " loss : 0.12696 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12696 test_loss : 0.15065 train_metric : 0.84375 test_metric : 0.80428\n",
      "\n",
      "=====Epoch : 86 =====\n",
      " loss : 0.07100 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.07100 test_loss : 0.15708 train_metric : 0.87500 test_metric : 0.80592\n",
      "\n",
      "=====Epoch : 87 =====\n",
      " loss : 0.08974 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.08974 test_loss : 0.15695 train_metric : 0.84375 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 88 =====\n",
      " loss : 0.11728 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11728 test_loss : 0.15609 train_metric : 0.87500 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 89 =====\n",
      " loss : 0.14593 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.14593 test_loss : 0.16609 train_metric : 0.87500 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 90 =====\n",
      " loss : 0.10483 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.10483 test_loss : 0.15817 train_metric : 0.90625 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 91 =====\n",
      " loss : 0.10038 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10038 test_loss : 0.15778 train_metric : 0.87500 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 92 =====\n",
      " loss : 0.12983 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.12983 test_loss : 0.15742 train_metric : 0.75000 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 93 =====\n",
      " loss : 0.19560 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.19560 test_loss : 0.15687 train_metric : 0.81250 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 94 =====\n",
      " loss : 0.22440 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.22440 test_loss : 0.15942 train_metric : 0.75000 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 95 =====\n",
      " loss : 0.13904 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13904 test_loss : 0.16051 train_metric : 0.81250 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 96 =====\n",
      " loss : 0.10859 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10859 test_loss : 0.16432 train_metric : 0.87500 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 97 =====\n",
      " loss : 0.07696 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.07696 test_loss : 0.15910 train_metric : 0.87500 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 98 =====\n",
      " loss : 0.18951 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.18951 test_loss : 0.16016 train_metric : 0.78125 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 99 =====\n",
      " loss : 0.29374 metric0 : 0.59375\n",
      "\n",
      " train_loss : 0.29374 test_loss : 0.16005 train_metric : 0.59375 test_metric : 0.80921\n",
      "\n",
      "=====Epoch : 100 =====\n",
      " loss : 0.11793 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11793 test_loss : 0.15479 train_metric : 0.84375 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 101 =====\n",
      " loss : 0.06658 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06658 test_loss : 0.15986 train_metric : 0.93750 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 102 =====\n",
      " loss : 0.08062 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08062 test_loss : 0.16266 train_metric : 0.90625 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 103 =====\n",
      " loss : 0.08911 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08911 test_loss : 0.15976 train_metric : 0.87500 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 104 =====\n",
      " loss : 0.12457 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12457 test_loss : 0.15640 train_metric : 0.84375 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 105 =====\n",
      " loss : 0.12483 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12483 test_loss : 0.15784 train_metric : 0.81250 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 106 =====\n",
      " loss : 0.09748 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09748 test_loss : 0.15740 train_metric : 0.84375 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 107 =====\n",
      " loss : 0.08645 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08645 test_loss : 0.16077 train_metric : 0.90625 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 108 =====\n",
      " loss : 0.07591 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07591 test_loss : 0.15863 train_metric : 0.90625 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 109 =====\n",
      " loss : 0.11159 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.11159 test_loss : 0.15642 train_metric : 0.81250 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 110 =====\n",
      " loss : 0.03698 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.03698 test_loss : 0.16684 train_metric : 0.96875 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 111 =====\n",
      " loss : 0.14262 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.14262 test_loss : 0.16376 train_metric : 0.78125 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 112 =====\n",
      " loss : 0.13333 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.13333 test_loss : 0.15462 train_metric : 0.87500 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 113 =====\n",
      " loss : 0.15611 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.15611 test_loss : 0.16329 train_metric : 0.81250 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 114 =====\n",
      " loss : 0.11460 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11460 test_loss : 0.14877 train_metric : 0.84375 test_metric : 0.80592\n",
      "\n",
      "=====Epoch : 115 =====\n",
      " loss : 0.08493 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08493 test_loss : 0.15364 train_metric : 0.87500 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 116 =====\n",
      " loss : 0.13362 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.13362 test_loss : 0.15279 train_metric : 0.87500 test_metric : 0.80757\n",
      "\n",
      "=====Epoch : 117 =====\n",
      " loss : 0.11990 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.11990 test_loss : 0.14548 train_metric : 0.81250 test_metric : 0.81414\n",
      "\n",
      "=====Epoch : 118 =====\n",
      " loss : 0.08656 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08656 test_loss : 0.16187 train_metric : 0.90625 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 119 =====\n",
      " loss : 0.19251 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.19251 test_loss : 0.15631 train_metric : 0.75000 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 120 =====\n",
      " loss : 0.10902 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10902 test_loss : 0.15427 train_metric : 0.84375 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 121 =====\n",
      " loss : 0.15809 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.15809 test_loss : 0.14741 train_metric : 0.81250 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 122 =====\n",
      " loss : 0.23462 metric0 : 0.68750\n",
      "\n",
      " train_loss : 0.23462 test_loss : 0.14655 train_metric : 0.68750 test_metric : 0.81250\n",
      "\n",
      "=====Epoch : 123 =====\n",
      " loss : 0.13097 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13097 test_loss : 0.15575 train_metric : 0.81250 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 124 =====\n",
      " loss : 0.09545 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09545 test_loss : 0.16161 train_metric : 0.87500 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 125 =====\n",
      " loss : 0.08297 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08297 test_loss : 0.15795 train_metric : 0.90625 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 126 =====\n",
      " loss : 0.12766 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.12766 test_loss : 0.16123 train_metric : 0.87500 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 127 =====\n",
      " loss : 0.13441 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.13441 test_loss : 0.15593 train_metric : 0.78125 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 128 =====\n",
      " loss : 0.10381 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.10381 test_loss : 0.15968 train_metric : 0.93750 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 129 =====\n",
      " loss : 0.06770 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06770 test_loss : 0.15879 train_metric : 0.90625 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 130 =====\n",
      " loss : 0.05800 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05800 test_loss : 0.15722 train_metric : 0.93750 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 131 =====\n",
      " loss : 0.03424 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.03424 test_loss : 0.15054 train_metric : 0.96875 test_metric : 0.81086\n",
      "\n",
      "=====Epoch : 132 =====\n",
      " loss : 0.12989 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.12989 test_loss : 0.15321 train_metric : 0.87500 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 133 =====\n",
      " loss : 0.12584 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12584 test_loss : 0.15864 train_metric : 0.84375 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 134 =====\n",
      " loss : 0.16339 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.16339 test_loss : 0.15486 train_metric : 0.81250 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 135 =====\n",
      " loss : 0.12677 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12677 test_loss : 0.15163 train_metric : 0.81250 test_metric : 0.81743\n",
      "\n",
      "=====Epoch : 136 =====\n",
      " loss : 0.08198 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08198 test_loss : 0.15932 train_metric : 0.87500 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 137 =====\n",
      " loss : 0.03844 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.03844 test_loss : 0.15853 train_metric : 0.93750 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 138 =====\n",
      " loss : 0.08386 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08386 test_loss : 0.14960 train_metric : 0.90625 test_metric : 0.80592\n",
      "\n",
      "=====Epoch : 139 =====\n",
      " loss : 0.09496 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09496 test_loss : 0.16420 train_metric : 0.84375 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 140 =====\n",
      " loss : 0.11566 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11566 test_loss : 0.16106 train_metric : 0.84375 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 141 =====\n",
      " loss : 0.08787 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.08787 test_loss : 0.17080 train_metric : 0.84375 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 142 =====\n",
      " loss : 0.12197 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.12197 test_loss : 0.15928 train_metric : 0.87500 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 143 =====\n",
      " loss : 0.07591 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07591 test_loss : 0.16925 train_metric : 0.93750 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 144 =====\n",
      " loss : 0.08274 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.08274 test_loss : 0.15775 train_metric : 0.93750 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 145 =====\n",
      " loss : 0.09814 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09814 test_loss : 0.16973 train_metric : 0.90625 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 146 =====\n",
      " loss : 0.14004 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.14004 test_loss : 0.14948 train_metric : 0.78125 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 147 =====\n",
      " loss : 0.07714 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07714 test_loss : 0.15248 train_metric : 0.90625 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 148 =====\n",
      " loss : 0.05990 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05990 test_loss : 0.15708 train_metric : 0.93750 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 149 =====\n",
      " loss : 0.09066 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09066 test_loss : 0.16187 train_metric : 0.87500 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 150 =====\n",
      " loss : 0.09816 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.09816 test_loss : 0.17002 train_metric : 0.81250 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 151 =====\n",
      " loss : 0.07640 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.07640 test_loss : 0.15608 train_metric : 0.87500 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 152 =====\n",
      " loss : 0.08710 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08710 test_loss : 0.16460 train_metric : 0.87500 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 153 =====\n",
      " loss : 0.09507 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09507 test_loss : 0.16244 train_metric : 0.87500 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 154 =====\n",
      " loss : 0.04181 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04181 test_loss : 0.14941 train_metric : 0.96875 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 155 =====\n",
      " loss : 0.11991 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.11991 test_loss : 0.16248 train_metric : 0.81250 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 156 =====\n",
      " loss : 0.11627 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11627 test_loss : 0.16244 train_metric : 0.84375 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 157 =====\n",
      " loss : 0.17981 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.17981 test_loss : 0.15908 train_metric : 0.75000 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 158 =====\n",
      " loss : 0.06092 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06092 test_loss : 0.16196 train_metric : 0.90625 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 159 =====\n",
      " loss : 0.13694 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.13694 test_loss : 0.17062 train_metric : 0.84375 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 160 =====\n",
      " loss : 0.08882 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08882 test_loss : 0.16839 train_metric : 0.87500 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 161 =====\n",
      " loss : 0.14044 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.14044 test_loss : 0.16217 train_metric : 0.75000 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 162 =====\n",
      " loss : 0.09834 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09834 test_loss : 0.16647 train_metric : 0.87500 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 163 =====\n",
      " loss : 0.12700 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12700 test_loss : 0.16748 train_metric : 0.84375 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 164 =====\n",
      " loss : 0.09494 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09494 test_loss : 0.15540 train_metric : 0.90625 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 165 =====\n",
      " loss : 0.17684 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.17684 test_loss : 0.15241 train_metric : 0.81250 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 166 =====\n",
      " loss : 0.05774 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.05774 test_loss : 0.16703 train_metric : 0.90625 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 167 =====\n",
      " loss : 0.06369 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06369 test_loss : 0.17073 train_metric : 0.93750 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 168 =====\n",
      " loss : 0.14212 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14212 test_loss : 0.16336 train_metric : 0.84375 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 169 =====\n",
      " loss : 0.06419 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06419 test_loss : 0.14969 train_metric : 0.90625 test_metric : 0.81414\n",
      "\n",
      "=====Epoch : 170 =====\n",
      " loss : 0.05070 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05070 test_loss : 0.17118 train_metric : 0.93750 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 171 =====\n",
      " loss : 0.11456 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.11456 test_loss : 0.17069 train_metric : 0.90625 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 172 =====\n",
      " loss : 0.04632 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.04632 test_loss : 0.15041 train_metric : 0.93750 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 173 =====\n",
      " loss : 0.10602 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.10602 test_loss : 0.16172 train_metric : 0.90625 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 174 =====\n",
      " loss : 0.05325 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05325 test_loss : 0.15573 train_metric : 0.93750 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 175 =====\n",
      " loss : 0.07862 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07862 test_loss : 0.16125 train_metric : 0.90625 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 176 =====\n",
      " loss : 0.14110 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.14110 test_loss : 0.16951 train_metric : 0.87500 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 177 =====\n",
      " loss : 0.15439 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.15439 test_loss : 0.16438 train_metric : 0.75000 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 178 =====\n",
      " loss : 0.10750 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10750 test_loss : 0.16050 train_metric : 0.87500 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 179 =====\n",
      " loss : 0.10283 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10283 test_loss : 0.15980 train_metric : 0.87500 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 180 =====\n",
      " loss : 0.16875 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.16875 test_loss : 0.15788 train_metric : 0.75000 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 181 =====\n",
      " loss : 0.08928 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08928 test_loss : 0.16850 train_metric : 0.90625 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 182 =====\n",
      " loss : 0.09010 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09010 test_loss : 0.15506 train_metric : 0.87500 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 183 =====\n",
      " loss : 0.09519 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09519 test_loss : 0.16105 train_metric : 0.87500 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 184 =====\n",
      " loss : 0.07192 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07192 test_loss : 0.15674 train_metric : 0.90625 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 185 =====\n",
      " loss : 0.06378 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06378 test_loss : 0.15578 train_metric : 0.93750 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 186 =====\n",
      " loss : 0.11922 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11922 test_loss : 0.16093 train_metric : 0.87500 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 187 =====\n",
      " loss : 0.11719 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.11719 test_loss : 0.16618 train_metric : 0.81250 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 188 =====\n",
      " loss : 0.09524 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09524 test_loss : 0.16106 train_metric : 0.84375 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 189 =====\n",
      " loss : 0.09658 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09658 test_loss : 0.17841 train_metric : 0.87500 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 190 =====\n",
      " loss : 0.05889 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.05889 test_loss : 0.16588 train_metric : 0.90625 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 191 =====\n",
      " loss : 0.09006 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09006 test_loss : 0.16397 train_metric : 0.87500 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 192 =====\n",
      " loss : 0.11009 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11009 test_loss : 0.16322 train_metric : 0.84375 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 193 =====\n",
      " loss : 0.11251 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11251 test_loss : 0.16036 train_metric : 0.87500 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 194 =====\n",
      " loss : 0.10827 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10827 test_loss : 0.17495 train_metric : 0.87500 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 195 =====\n",
      " loss : 0.07366 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07366 test_loss : 0.17228 train_metric : 0.93750 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 196 =====\n",
      " loss : 0.19836 metric0 : 0.71875\n",
      "\n",
      " train_loss : 0.19836 test_loss : 0.15930 train_metric : 0.71875 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 197 =====\n",
      " loss : 0.10944 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10944 test_loss : 0.15544 train_metric : 0.87500 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 198 =====\n",
      " loss : 0.09493 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09493 test_loss : 0.16772 train_metric : 0.87500 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 199 =====\n",
      " loss : 0.11480 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11480 test_loss : 0.17206 train_metric : 0.84375 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 200 =====\n",
      " loss : 0.15952 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.15952 test_loss : 0.16158 train_metric : 0.75000 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 201 =====\n",
      " loss : 0.11996 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11996 test_loss : 0.15954 train_metric : 0.84375 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 202 =====\n",
      " loss : 0.04620 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.04620 test_loss : 0.16981 train_metric : 0.93750 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 203 =====\n",
      " loss : 0.19309 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.19309 test_loss : 0.17972 train_metric : 0.78125 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 204 =====\n",
      " loss : 0.09621 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09621 test_loss : 0.18375 train_metric : 0.90625 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 205 =====\n",
      " loss : 0.13932 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.13932 test_loss : 0.16215 train_metric : 0.84375 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 206 =====\n",
      " loss : 0.09766 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09766 test_loss : 0.17294 train_metric : 0.84375 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 207 =====\n",
      " loss : 0.19389 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.19389 test_loss : 0.15946 train_metric : 0.75000 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 208 =====\n",
      " loss : 0.12505 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12505 test_loss : 0.16645 train_metric : 0.84375 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 209 =====\n",
      " loss : 0.10248 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.10248 test_loss : 0.16321 train_metric : 0.93750 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 210 =====\n",
      " loss : 0.14208 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14208 test_loss : 0.15781 train_metric : 0.84375 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 211 =====\n",
      " loss : 0.11051 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11051 test_loss : 0.16717 train_metric : 0.84375 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 212 =====\n",
      " loss : 0.04800 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04800 test_loss : 0.16864 train_metric : 0.96875 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 213 =====\n",
      " loss : 0.09475 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09475 test_loss : 0.17313 train_metric : 0.84375 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 214 =====\n",
      " loss : 0.11754 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11754 test_loss : 0.16416 train_metric : 0.87500 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 215 =====\n",
      " loss : 0.05237 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05237 test_loss : 0.17816 train_metric : 0.93750 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 216 =====\n",
      " loss : 0.11974 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.11974 test_loss : 0.15834 train_metric : 0.81250 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 217 =====\n",
      " loss : 0.11281 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11281 test_loss : 0.16295 train_metric : 0.87500 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 218 =====\n",
      " loss : 0.08719 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08719 test_loss : 0.16963 train_metric : 0.87500 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 219 =====\n",
      " loss : 0.11246 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.11246 test_loss : 0.17828 train_metric : 0.90625 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 220 =====\n",
      " loss : 0.20368 metric0 : 0.68750\n",
      "\n",
      " train_loss : 0.20368 test_loss : 0.16321 train_metric : 0.68750 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 221 =====\n",
      " loss : 0.10889 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10889 test_loss : 0.16536 train_metric : 0.84375 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 222 =====\n",
      " loss : 0.08234 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.08234 test_loss : 0.17392 train_metric : 0.93750 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 223 =====\n",
      " loss : 0.06456 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06456 test_loss : 0.18025 train_metric : 0.93750 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 224 =====\n",
      " loss : 0.13096 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.13096 test_loss : 0.17397 train_metric : 0.78125 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 225 =====\n",
      " loss : 0.09057 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09057 test_loss : 0.17353 train_metric : 0.90625 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 226 =====\n",
      " loss : 0.07688 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07688 test_loss : 0.16902 train_metric : 0.93750 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 227 =====\n",
      " loss : 0.06061 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06061 test_loss : 0.17515 train_metric : 0.90625 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 228 =====\n",
      " loss : 0.06770 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.06770 test_loss : 0.17130 train_metric : 0.87500 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 229 =====\n",
      " loss : 0.07258 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.07258 test_loss : 0.17440 train_metric : 0.87500 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 230 =====\n",
      " loss : 0.09971 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09971 test_loss : 0.16153 train_metric : 0.84375 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 231 =====\n",
      " loss : 0.08226 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.08226 test_loss : 0.16817 train_metric : 0.81250 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 232 =====\n",
      " loss : 0.04161 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.04161 test_loss : 0.16933 train_metric : 0.93750 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 233 =====\n",
      " loss : 0.05360 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05360 test_loss : 0.16579 train_metric : 0.93750 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 234 =====\n",
      " loss : 0.10884 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10884 test_loss : 0.15989 train_metric : 0.84375 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 235 =====\n",
      " loss : 0.07760 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07760 test_loss : 0.16883 train_metric : 0.93750 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 236 =====\n",
      " loss : 0.11970 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11970 test_loss : 0.17465 train_metric : 0.87500 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 237 =====\n",
      " loss : 0.14365 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14365 test_loss : 0.17064 train_metric : 0.81250 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 238 =====\n",
      " loss : 0.09347 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09347 test_loss : 0.18061 train_metric : 0.87500 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 239 =====\n",
      " loss : 0.05644 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05644 test_loss : 0.17393 train_metric : 0.93750 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 240 =====\n",
      " loss : 0.14102 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14102 test_loss : 0.17889 train_metric : 0.84375 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 241 =====\n",
      " loss : 0.07084 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07084 test_loss : 0.17070 train_metric : 0.93750 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 242 =====\n",
      " loss : 0.09234 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09234 test_loss : 0.17297 train_metric : 0.90625 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 243 =====\n",
      " loss : 0.09208 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09208 test_loss : 0.17722 train_metric : 0.87500 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 244 =====\n",
      " loss : 0.07857 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07857 test_loss : 0.17397 train_metric : 0.90625 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 245 =====\n",
      " loss : 0.09635 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09635 test_loss : 0.17096 train_metric : 0.90625 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 246 =====\n",
      " loss : 0.12790 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12790 test_loss : 0.17774 train_metric : 0.81250 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 247 =====\n",
      " loss : 0.02749 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02749 test_loss : 0.16967 train_metric : 1.00000 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 248 =====\n",
      " loss : 0.11587 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11587 test_loss : 0.17459 train_metric : 0.84375 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 249 =====\n",
      " loss : 0.11189 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11189 test_loss : 0.16858 train_metric : 0.87500 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 250 =====\n",
      " loss : 0.12104 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12104 test_loss : 0.18260 train_metric : 0.84375 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 251 =====\n",
      " loss : 0.11913 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11913 test_loss : 0.17658 train_metric : 0.84375 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 252 =====\n",
      " loss : 0.09411 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.09411 test_loss : 0.16771 train_metric : 0.78125 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 253 =====\n",
      " loss : 0.08882 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08882 test_loss : 0.17036 train_metric : 0.90625 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 254 =====\n",
      " loss : 0.08988 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08988 test_loss : 0.16916 train_metric : 0.90625 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 255 =====\n",
      " loss : 0.13552 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.13552 test_loss : 0.17286 train_metric : 0.87500 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 256 =====\n",
      " loss : 0.06758 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06758 test_loss : 0.17851 train_metric : 0.90625 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 257 =====\n",
      " loss : 0.08415 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08415 test_loss : 0.17542 train_metric : 0.90625 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 258 =====\n",
      " loss : 0.07066 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07066 test_loss : 0.17235 train_metric : 0.93750 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 259 =====\n",
      " loss : 0.06867 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.06867 test_loss : 0.17418 train_metric : 0.96875 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 260 =====\n",
      " loss : 0.11232 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11232 test_loss : 0.16522 train_metric : 0.87500 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 261 =====\n",
      " loss : 0.09758 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09758 test_loss : 0.16626 train_metric : 0.90625 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 262 =====\n",
      " loss : 0.14705 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14705 test_loss : 0.16870 train_metric : 0.81250 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 263 =====\n",
      " loss : 0.07736 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07736 test_loss : 0.17041 train_metric : 0.90625 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 264 =====\n",
      " loss : 0.08976 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.08976 test_loss : 0.17774 train_metric : 0.93750 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 265 =====\n",
      " loss : 0.06519 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06519 test_loss : 0.17760 train_metric : 0.90625 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 266 =====\n",
      " loss : 0.09383 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09383 test_loss : 0.17881 train_metric : 0.84375 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 267 =====\n",
      " loss : 0.13830 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.13830 test_loss : 0.18301 train_metric : 0.78125 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 268 =====\n",
      " loss : 0.06588 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06588 test_loss : 0.17151 train_metric : 0.93750 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 269 =====\n",
      " loss : 0.12092 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.12092 test_loss : 0.17712 train_metric : 0.87500 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 270 =====\n",
      " loss : 0.09059 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09059 test_loss : 0.17370 train_metric : 0.87500 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 271 =====\n",
      " loss : 0.08818 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.08818 test_loss : 0.18373 train_metric : 0.93750 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 272 =====\n",
      " loss : 0.21249 metric0 : 0.68750\n",
      "\n",
      " train_loss : 0.21249 test_loss : 0.16328 train_metric : 0.68750 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 273 =====\n",
      " loss : 0.14647 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14647 test_loss : 0.16976 train_metric : 0.81250 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 274 =====\n",
      " loss : 0.08276 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.08276 test_loss : 0.16870 train_metric : 0.93750 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 275 =====\n",
      " loss : 0.17266 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.17266 test_loss : 0.17686 train_metric : 0.81250 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 276 =====\n",
      " loss : 0.13303 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.13303 test_loss : 0.17339 train_metric : 0.90625 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 277 =====\n",
      " loss : 0.08683 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08683 test_loss : 0.17468 train_metric : 0.87500 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 278 =====\n",
      " loss : 0.10490 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10490 test_loss : 0.17929 train_metric : 0.84375 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 279 =====\n",
      " loss : 0.07903 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07903 test_loss : 0.17691 train_metric : 0.90625 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 280 =====\n",
      " loss : 0.09055 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09055 test_loss : 0.19612 train_metric : 0.87500 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 281 =====\n",
      " loss : 0.08122 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08122 test_loss : 0.16087 train_metric : 0.90625 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 282 =====\n",
      " loss : 0.07788 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.07788 test_loss : 0.17530 train_metric : 0.84375 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 283 =====\n",
      " loss : 0.07554 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07554 test_loss : 0.17719 train_metric : 0.93750 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 284 =====\n",
      " loss : 0.06627 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06627 test_loss : 0.17442 train_metric : 0.90625 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 285 =====\n",
      " loss : 0.08956 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08956 test_loss : 0.17374 train_metric : 0.87500 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 286 =====\n",
      " loss : 0.10670 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.10670 test_loss : 0.17562 train_metric : 0.90625 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 287 =====\n",
      " loss : 0.07876 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.07876 test_loss : 0.17037 train_metric : 0.87500 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 288 =====\n",
      " loss : 0.14207 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14207 test_loss : 0.17655 train_metric : 0.84375 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 289 =====\n",
      " loss : 0.04970 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04970 test_loss : 0.18148 train_metric : 0.96875 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 290 =====\n",
      " loss : 0.04917 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04917 test_loss : 0.17425 train_metric : 0.96875 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 291 =====\n",
      " loss : 0.05806 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05806 test_loss : 0.18157 train_metric : 0.93750 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 292 =====\n",
      " loss : 0.09047 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.09047 test_loss : 0.16869 train_metric : 0.81250 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 293 =====\n",
      " loss : 0.10441 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10441 test_loss : 0.17871 train_metric : 0.87500 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 294 =====\n",
      " loss : 0.10808 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10808 test_loss : 0.17076 train_metric : 0.87500 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 295 =====\n",
      " loss : 0.06742 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06742 test_loss : 0.16833 train_metric : 0.90625 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 296 =====\n",
      " loss : 0.07005 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07005 test_loss : 0.17234 train_metric : 0.93750 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 297 =====\n",
      " loss : 0.08391 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08391 test_loss : 0.17793 train_metric : 0.87500 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 298 =====\n",
      " loss : 0.07258 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07258 test_loss : 0.18053 train_metric : 0.93750 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 299 =====\n",
      " loss : 0.12090 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12090 test_loss : 0.17130 train_metric : 0.84375 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 300 =====\n",
      " loss : 0.04620 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.04620 test_loss : 0.17436 train_metric : 0.93750 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 301 =====\n",
      " loss : 0.08710 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08710 test_loss : 0.17096 train_metric : 0.87500 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 302 =====\n",
      " loss : 0.06647 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06647 test_loss : 0.17733 train_metric : 0.93750 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 303 =====\n",
      " loss : 0.02491 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.02491 test_loss : 0.17723 train_metric : 0.96875 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 304 =====\n",
      " loss : 0.07629 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07629 test_loss : 0.17527 train_metric : 0.90625 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 305 =====\n",
      " loss : 0.11357 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11357 test_loss : 0.18823 train_metric : 0.84375 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 306 =====\n",
      " loss : 0.09901 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09901 test_loss : 0.18634 train_metric : 0.87500 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 307 =====\n",
      " loss : 0.10579 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10579 test_loss : 0.18383 train_metric : 0.87500 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 308 =====\n",
      " loss : 0.05744 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05744 test_loss : 0.18145 train_metric : 0.93750 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 309 =====\n",
      " loss : 0.05569 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05569 test_loss : 0.18275 train_metric : 0.93750 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 310 =====\n",
      " loss : 0.03065 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.03065 test_loss : 0.16496 train_metric : 0.96875 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 311 =====\n",
      " loss : 0.12052 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12052 test_loss : 0.17322 train_metric : 0.84375 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 312 =====\n",
      " loss : 0.08802 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.08802 test_loss : 0.16902 train_metric : 0.84375 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 313 =====\n",
      " loss : 0.18342 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.18342 test_loss : 0.17979 train_metric : 0.75000 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 314 =====\n",
      " loss : 0.08964 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08964 test_loss : 0.16951 train_metric : 0.90625 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 315 =====\n",
      " loss : 0.08832 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08832 test_loss : 0.17433 train_metric : 0.90625 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 316 =====\n",
      " loss : 0.14237 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14237 test_loss : 0.17796 train_metric : 0.81250 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 317 =====\n",
      " loss : 0.07127 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.07127 test_loss : 0.17385 train_metric : 0.87500 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 318 =====\n",
      " loss : 0.16580 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.16580 test_loss : 0.17270 train_metric : 0.75000 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 319 =====\n",
      " loss : 0.05450 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.05450 test_loss : 0.17095 train_metric : 0.96875 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 320 =====\n",
      " loss : 0.07140 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07140 test_loss : 0.17283 train_metric : 0.93750 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 321 =====\n",
      " loss : 0.11815 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11815 test_loss : 0.18027 train_metric : 0.87500 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 322 =====\n",
      " loss : 0.09378 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09378 test_loss : 0.15908 train_metric : 0.87500 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 323 =====\n",
      " loss : 0.12423 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12423 test_loss : 0.16587 train_metric : 0.84375 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 324 =====\n",
      " loss : 0.08874 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.08874 test_loss : 0.17314 train_metric : 0.84375 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 325 =====\n",
      " loss : 0.07608 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07608 test_loss : 0.17212 train_metric : 0.90625 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 326 =====\n",
      " loss : 0.06634 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06634 test_loss : 0.17743 train_metric : 0.93750 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 327 =====\n",
      " loss : 0.14630 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14630 test_loss : 0.17629 train_metric : 0.81250 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 328 =====\n",
      " loss : 0.04460 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04460 test_loss : 0.17390 train_metric : 0.96875 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 329 =====\n",
      " loss : 0.10360 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.10360 test_loss : 0.17028 train_metric : 0.90625 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 330 =====\n",
      " loss : 0.02154 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02154 test_loss : 0.18047 train_metric : 1.00000 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 331 =====\n",
      " loss : 0.08718 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08718 test_loss : 0.18269 train_metric : 0.90625 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 332 =====\n",
      " loss : 0.08449 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08449 test_loss : 0.17625 train_metric : 0.87500 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 333 =====\n",
      " loss : 0.07817 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07817 test_loss : 0.17998 train_metric : 0.90625 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 334 =====\n",
      " loss : 0.04672 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04672 test_loss : 0.17513 train_metric : 0.96875 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 335 =====\n",
      " loss : 0.09142 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09142 test_loss : 0.17553 train_metric : 0.90625 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 336 =====\n",
      " loss : 0.11730 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11730 test_loss : 0.17026 train_metric : 0.84375 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 337 =====\n",
      " loss : 0.04028 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.04028 test_loss : 0.17188 train_metric : 0.93750 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 338 =====\n",
      " loss : 0.08768 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08768 test_loss : 0.18213 train_metric : 0.90625 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 339 =====\n",
      " loss : 0.09250 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09250 test_loss : 0.17806 train_metric : 0.90625 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 340 =====\n",
      " loss : 0.08608 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08608 test_loss : 0.16875 train_metric : 0.87500 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 341 =====\n",
      " loss : 0.10731 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10731 test_loss : 0.17985 train_metric : 0.87500 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 342 =====\n",
      " loss : 0.04186 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04186 test_loss : 0.16435 train_metric : 0.96875 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 343 =====\n",
      " loss : 0.06223 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.06223 test_loss : 0.17519 train_metric : 0.87500 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 344 =====\n",
      " loss : 0.03058 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03058 test_loss : 0.18707 train_metric : 1.00000 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 345 =====\n",
      " loss : 0.13992 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.13992 test_loss : 0.18070 train_metric : 0.75000 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 346 =====\n",
      " loss : 0.11968 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11968 test_loss : 0.17801 train_metric : 0.84375 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 347 =====\n",
      " loss : 0.02889 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.02889 test_loss : 0.17909 train_metric : 0.96875 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 348 =====\n",
      " loss : 0.05928 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05928 test_loss : 0.17716 train_metric : 0.93750 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 349 =====\n",
      " loss : 0.06082 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06082 test_loss : 0.18089 train_metric : 0.90625 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 350 =====\n",
      " loss : 0.08871 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08871 test_loss : 0.17443 train_metric : 0.87500 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 351 =====\n",
      " loss : 0.06334 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.06334 test_loss : 0.18127 train_metric : 0.87500 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 352 =====\n",
      " loss : 0.07262 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07262 test_loss : 0.18404 train_metric : 0.93750 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 353 =====\n",
      " loss : 0.11306 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11306 test_loss : 0.17985 train_metric : 0.84375 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 354 =====\n",
      " loss : 0.13131 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.13131 test_loss : 0.18980 train_metric : 0.84375 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 355 =====\n",
      " loss : 0.13110 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13110 test_loss : 0.18957 train_metric : 0.81250 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 356 =====\n",
      " loss : 0.05892 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.05892 test_loss : 0.17718 train_metric : 0.90625 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 357 =====\n",
      " loss : 0.07722 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07722 test_loss : 0.18259 train_metric : 0.90625 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 358 =====\n",
      " loss : 0.08333 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08333 test_loss : 0.18695 train_metric : 0.90625 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 359 =====\n",
      " loss : 0.04347 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04347 test_loss : 0.16367 train_metric : 0.96875 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 360 =====\n",
      " loss : 0.10895 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10895 test_loss : 0.17327 train_metric : 0.84375 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 361 =====\n",
      " loss : 0.16285 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.16285 test_loss : 0.18125 train_metric : 0.84375 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 362 =====\n",
      " loss : 0.05449 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05449 test_loss : 0.18420 train_metric : 0.93750 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 363 =====\n",
      " loss : 0.10927 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10927 test_loss : 0.18436 train_metric : 0.84375 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 364 =====\n",
      " loss : 0.07446 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.07446 test_loss : 0.17506 train_metric : 0.87500 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 365 =====\n",
      " loss : 0.14287 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14287 test_loss : 0.18418 train_metric : 0.84375 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 366 =====\n",
      " loss : 0.13806 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13806 test_loss : 0.18505 train_metric : 0.81250 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 367 =====\n",
      " loss : 0.05089 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05089 test_loss : 0.17983 train_metric : 0.93750 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 368 =====\n",
      " loss : 0.10453 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10453 test_loss : 0.18046 train_metric : 0.84375 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 369 =====\n",
      " loss : 0.13121 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13121 test_loss : 0.19155 train_metric : 0.81250 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 370 =====\n",
      " loss : 0.03919 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.03919 test_loss : 0.18483 train_metric : 0.96875 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 371 =====\n",
      " loss : 0.08105 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08105 test_loss : 0.17608 train_metric : 0.90625 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 372 =====\n",
      " loss : 0.09079 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09079 test_loss : 0.18506 train_metric : 0.87500 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 373 =====\n",
      " loss : 0.07104 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07104 test_loss : 0.18047 train_metric : 0.93750 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 374 =====\n",
      " loss : 0.07965 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.07965 test_loss : 0.17717 train_metric : 0.84375 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 375 =====\n",
      " loss : 0.05570 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05570 test_loss : 0.18263 train_metric : 0.93750 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 376 =====\n",
      " loss : 0.03409 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.03409 test_loss : 0.17653 train_metric : 0.96875 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 377 =====\n",
      " loss : 0.04228 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04228 test_loss : 0.18136 train_metric : 0.96875 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 378 =====\n",
      " loss : 0.12788 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12788 test_loss : 0.16325 train_metric : 0.84375 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 379 =====\n",
      " loss : 0.11848 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11848 test_loss : 0.19009 train_metric : 0.87500 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 380 =====\n",
      " loss : 0.14611 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14611 test_loss : 0.16054 train_metric : 0.84375 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 381 =====\n",
      " loss : 0.14645 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14645 test_loss : 0.16653 train_metric : 0.84375 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 382 =====\n",
      " loss : 0.08919 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08919 test_loss : 0.17724 train_metric : 0.90625 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 383 =====\n",
      " loss : 0.14106 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14106 test_loss : 0.18029 train_metric : 0.81250 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 384 =====\n",
      " loss : 0.07879 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07879 test_loss : 0.17972 train_metric : 0.93750 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 385 =====\n",
      " loss : 0.09307 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09307 test_loss : 0.17841 train_metric : 0.87500 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 386 =====\n",
      " loss : 0.10809 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10809 test_loss : 0.17549 train_metric : 0.87500 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 387 =====\n",
      " loss : 0.12850 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12850 test_loss : 0.17513 train_metric : 0.81250 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 388 =====\n",
      " loss : 0.11313 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11313 test_loss : 0.17077 train_metric : 0.84375 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 389 =====\n",
      " loss : 0.13903 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.13903 test_loss : 0.19135 train_metric : 0.78125 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 390 =====\n",
      " loss : 0.10918 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10918 test_loss : 0.18716 train_metric : 0.87500 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 391 =====\n",
      " loss : 0.03746 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.03746 test_loss : 0.17405 train_metric : 0.96875 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 392 =====\n",
      " loss : 0.09923 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09923 test_loss : 0.17482 train_metric : 0.87500 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 393 =====\n",
      " loss : 0.09032 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09032 test_loss : 0.17760 train_metric : 0.90625 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 394 =====\n",
      " loss : 0.08847 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08847 test_loss : 0.17608 train_metric : 0.87500 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 395 =====\n",
      " loss : 0.06679 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06679 test_loss : 0.18815 train_metric : 0.90625 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 396 =====\n",
      " loss : 0.07311 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07311 test_loss : 0.18533 train_metric : 0.93750 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 397 =====\n",
      " loss : 0.06731 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.06731 test_loss : 0.18249 train_metric : 0.87500 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 398 =====\n",
      " loss : 0.04796 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.04796 test_loss : 0.17293 train_metric : 0.93750 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 399 =====\n",
      " loss : 0.14482 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.14482 test_loss : 0.17984 train_metric : 0.78125 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 400 =====\n",
      " loss : 0.18273 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.18273 test_loss : 0.18435 train_metric : 0.75000 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 401 =====\n",
      " loss : 0.10861 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.10861 test_loss : 0.18207 train_metric : 0.81250 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 402 =====\n",
      " loss : 0.04145 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.04145 test_loss : 0.16882 train_metric : 0.93750 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 403 =====\n",
      " loss : 0.16694 metric0 : 0.71875\n",
      "\n",
      " train_loss : 0.16694 test_loss : 0.17427 train_metric : 0.71875 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 404 =====\n",
      " loss : 0.13852 metric0 : 0.71875\n",
      "\n",
      " train_loss : 0.13852 test_loss : 0.18560 train_metric : 0.71875 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 405 =====\n",
      " loss : 0.10882 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10882 test_loss : 0.17635 train_metric : 0.87500 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 406 =====\n",
      " loss : 0.13129 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.13129 test_loss : 0.17180 train_metric : 0.87500 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 407 =====\n",
      " loss : 0.03406 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.03406 test_loss : 0.17910 train_metric : 0.93750 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 408 =====\n",
      " loss : 0.06479 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06479 test_loss : 0.17142 train_metric : 0.90625 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 409 =====\n",
      " loss : 0.04284 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04284 test_loss : 0.17003 train_metric : 0.96875 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 410 =====\n",
      " loss : 0.09616 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09616 test_loss : 0.17199 train_metric : 0.87500 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 411 =====\n",
      " loss : 0.12374 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12374 test_loss : 0.17575 train_metric : 0.84375 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 412 =====\n",
      " loss : 0.08614 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08614 test_loss : 0.19038 train_metric : 0.87500 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 413 =====\n",
      " loss : 0.08858 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08858 test_loss : 0.17424 train_metric : 0.87500 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 414 =====\n",
      " loss : 0.09914 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09914 test_loss : 0.18130 train_metric : 0.84375 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 415 =====\n",
      " loss : 0.06174 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06174 test_loss : 0.16843 train_metric : 0.93750 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 416 =====\n",
      " loss : 0.06185 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06185 test_loss : 0.17217 train_metric : 0.90625 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 417 =====\n",
      " loss : 0.03322 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.03322 test_loss : 0.18151 train_metric : 0.96875 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 418 =====\n",
      " loss : 0.14565 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.14565 test_loss : 0.16395 train_metric : 0.78125 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 419 =====\n",
      " loss : 0.06548 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06548 test_loss : 0.18114 train_metric : 0.93750 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 420 =====\n",
      " loss : 0.06628 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.06628 test_loss : 0.17118 train_metric : 0.84375 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 421 =====\n",
      " loss : 0.13443 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.13443 test_loss : 0.18289 train_metric : 0.84375 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 422 =====\n",
      " loss : 0.07705 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07705 test_loss : 0.18481 train_metric : 0.90625 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 423 =====\n",
      " loss : 0.05873 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05873 test_loss : 0.18157 train_metric : 0.93750 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 424 =====\n",
      " loss : 0.14055 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.14055 test_loss : 0.17973 train_metric : 0.84375 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 425 =====\n",
      " loss : 0.11609 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11609 test_loss : 0.17017 train_metric : 0.87500 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 426 =====\n",
      " loss : 0.07669 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07669 test_loss : 0.17291 train_metric : 0.93750 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 427 =====\n",
      " loss : 0.14963 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.14963 test_loss : 0.17673 train_metric : 0.81250 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 428 =====\n",
      " loss : 0.07870 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07870 test_loss : 0.17544 train_metric : 0.90625 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 429 =====\n",
      " loss : 0.07584 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.07584 test_loss : 0.17828 train_metric : 0.87500 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 430 =====\n",
      " loss : 0.09022 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09022 test_loss : 0.17093 train_metric : 0.84375 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 431 =====\n",
      " loss : 0.07573 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07573 test_loss : 0.17627 train_metric : 0.90625 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 432 =====\n",
      " loss : 0.11665 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11665 test_loss : 0.16796 train_metric : 0.84375 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 433 =====\n",
      " loss : 0.08812 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08812 test_loss : 0.17727 train_metric : 0.90625 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 434 =====\n",
      " loss : 0.12038 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12038 test_loss : 0.18488 train_metric : 0.81250 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 435 =====\n",
      " loss : 0.09280 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09280 test_loss : 0.18729 train_metric : 0.90625 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 436 =====\n",
      " loss : 0.11340 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11340 test_loss : 0.17621 train_metric : 0.87500 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 437 =====\n",
      " loss : 0.11837 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.11837 test_loss : 0.18200 train_metric : 0.87500 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 438 =====\n",
      " loss : 0.05238 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.05238 test_loss : 0.16840 train_metric : 0.90625 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 439 =====\n",
      " loss : 0.10803 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.10803 test_loss : 0.17430 train_metric : 0.81250 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 440 =====\n",
      " loss : 0.09523 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09523 test_loss : 0.17767 train_metric : 0.87500 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 441 =====\n",
      " loss : 0.12716 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.12716 test_loss : 0.17152 train_metric : 0.87500 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 442 =====\n",
      " loss : 0.07300 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07300 test_loss : 0.17577 train_metric : 0.90625 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 443 =====\n",
      " loss : 0.12726 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12726 test_loss : 0.18063 train_metric : 0.81250 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 444 =====\n",
      " loss : 0.15951 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.15951 test_loss : 0.18297 train_metric : 0.75000 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 445 =====\n",
      " loss : 0.05919 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05919 test_loss : 0.17864 train_metric : 0.93750 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 446 =====\n",
      " loss : 0.18067 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.18067 test_loss : 0.17303 train_metric : 0.75000 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 447 =====\n",
      " loss : 0.05936 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05936 test_loss : 0.16770 train_metric : 0.93750 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 448 =====\n",
      " loss : 0.04199 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.04199 test_loss : 0.16885 train_metric : 0.90625 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 449 =====\n",
      " loss : 0.15060 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.15060 test_loss : 0.18312 train_metric : 0.84375 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 450 =====\n",
      " loss : 0.05191 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.05191 test_loss : 0.17040 train_metric : 0.93750 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 451 =====\n",
      " loss : 0.06223 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06223 test_loss : 0.18158 train_metric : 0.93750 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 452 =====\n",
      " loss : 0.10314 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.10314 test_loss : 0.17915 train_metric : 0.90625 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 453 =====\n",
      " loss : 0.07262 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07262 test_loss : 0.17540 train_metric : 0.90625 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 454 =====\n",
      " loss : 0.06057 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06057 test_loss : 0.17435 train_metric : 0.93750 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 455 =====\n",
      " loss : 0.08202 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.08202 test_loss : 0.17802 train_metric : 0.93750 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 456 =====\n",
      " loss : 0.08523 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08523 test_loss : 0.18062 train_metric : 0.90625 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 457 =====\n",
      " loss : 0.10648 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.10648 test_loss : 0.17281 train_metric : 0.90625 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 458 =====\n",
      " loss : 0.15201 metric0 : 0.78125\n",
      "\n",
      " train_loss : 0.15201 test_loss : 0.19159 train_metric : 0.78125 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 459 =====\n",
      " loss : 0.06834 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06834 test_loss : 0.16966 train_metric : 0.90625 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 460 =====\n",
      " loss : 0.11692 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.11692 test_loss : 0.19517 train_metric : 0.84375 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 461 =====\n",
      " loss : 0.04987 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04987 test_loss : 0.17715 train_metric : 0.96875 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 462 =====\n",
      " loss : 0.06250 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.06250 test_loss : 0.18171 train_metric : 0.87500 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 463 =====\n",
      " loss : 0.10170 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10170 test_loss : 0.17088 train_metric : 0.84375 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 464 =====\n",
      " loss : 0.12325 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12325 test_loss : 0.17860 train_metric : 0.81250 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 465 =====\n",
      " loss : 0.03372 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.03372 test_loss : 0.18044 train_metric : 0.96875 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 466 =====\n",
      " loss : 0.07121 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.07121 test_loss : 0.17608 train_metric : 0.93750 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 467 =====\n",
      " loss : 0.13606 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13606 test_loss : 0.16926 train_metric : 0.81250 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 468 =====\n",
      " loss : 0.04477 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.04477 test_loss : 0.17795 train_metric : 0.93750 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 469 =====\n",
      " loss : 0.08736 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.08736 test_loss : 0.17919 train_metric : 0.90625 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 470 =====\n",
      " loss : 0.06387 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.06387 test_loss : 0.17291 train_metric : 0.93750 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 471 =====\n",
      " loss : 0.12294 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.12294 test_loss : 0.17379 train_metric : 0.87500 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 472 =====\n",
      " loss : 0.10048 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10048 test_loss : 0.18039 train_metric : 0.87500 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 473 =====\n",
      " loss : 0.07443 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.07443 test_loss : 0.16627 train_metric : 0.87500 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 474 =====\n",
      " loss : 0.04505 metric0 : 0.93750\n",
      "\n",
      " train_loss : 0.04505 test_loss : 0.16173 train_metric : 0.93750 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 475 =====\n",
      " loss : 0.09358 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09358 test_loss : 0.16997 train_metric : 0.87500 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 476 =====\n",
      " loss : 0.06280 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.06280 test_loss : 0.18414 train_metric : 0.96875 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 477 =====\n",
      " loss : 0.13209 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13209 test_loss : 0.17278 train_metric : 0.81250 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 478 =====\n",
      " loss : 0.15217 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.15217 test_loss : 0.17511 train_metric : 0.84375 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 479 =====\n",
      " loss : 0.16110 metric0 : 0.75000\n",
      "\n",
      " train_loss : 0.16110 test_loss : 0.17425 train_metric : 0.75000 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 480 =====\n",
      " loss : 0.09465 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09465 test_loss : 0.17821 train_metric : 0.90625 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 481 =====\n",
      " loss : 0.06842 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.06842 test_loss : 0.17616 train_metric : 0.87500 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 482 =====\n",
      " loss : 0.05512 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.05512 test_loss : 0.19599 train_metric : 0.96875 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 483 =====\n",
      " loss : 0.11162 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.11162 test_loss : 0.16826 train_metric : 0.81250 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 484 =====\n",
      " loss : 0.09656 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.09656 test_loss : 0.16550 train_metric : 0.87500 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 485 =====\n",
      " loss : 0.07917 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.07917 test_loss : 0.17101 train_metric : 0.90625 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 486 =====\n",
      " loss : 0.09244 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09244 test_loss : 0.17904 train_metric : 0.90625 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 487 =====\n",
      " loss : 0.05674 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.05674 test_loss : 0.18030 train_metric : 0.96875 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 488 =====\n",
      " loss : 0.12850 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.12850 test_loss : 0.17929 train_metric : 0.81250 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 489 =====\n",
      " loss : 0.06741 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.06741 test_loss : 0.17972 train_metric : 0.90625 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 490 =====\n",
      " loss : 0.12091 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.12091 test_loss : 0.17362 train_metric : 0.84375 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 491 =====\n",
      " loss : 0.13976 metric0 : 0.81250\n",
      "\n",
      " train_loss : 0.13976 test_loss : 0.17145 train_metric : 0.81250 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 492 =====\n",
      " loss : 0.09933 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.09933 test_loss : 0.16527 train_metric : 0.84375 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 493 =====\n",
      " loss : 0.09395 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09395 test_loss : 0.16855 train_metric : 0.90625 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 494 =====\n",
      " loss : 0.10767 metric0 : 0.84375\n",
      "\n",
      " train_loss : 0.10767 test_loss : 0.17016 train_metric : 0.84375 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 495 =====\n",
      " loss : 0.10354 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.10354 test_loss : 0.17285 train_metric : 0.87500 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 496 =====\n",
      " loss : 0.09215 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09215 test_loss : 0.18448 train_metric : 0.90625 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 497 =====\n",
      " loss : 0.04053 metric0 : 0.96875\n",
      "\n",
      " train_loss : 0.04053 test_loss : 0.17457 train_metric : 0.96875 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 498 =====\n",
      " loss : 0.08817 metric0 : 0.87500\n",
      "\n",
      " train_loss : 0.08817 test_loss : 0.17536 train_metric : 0.87500 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 499 =====\n",
      " loss : 0.01741 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01741 test_loss : 0.19303 train_metric : 1.00000 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 500 =====\n",
      " loss : 0.09074 metric0 : 0.90625\n",
      "\n",
      " train_loss : 0.09074 test_loss : 0.16937 train_metric : 0.90625 test_metric : 0.77961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fcnqe = NQE(n_feature=4, mode='FC')\n",
    "fcnqe_train = NQE_Train(fcnqe, criterion, train_loader, test_loader, [accuarcy])\n",
    "trained_fcnqe = fcnqe_train.train(500, seq_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_fcnqe.state_dict(), \"./models/pca_FC_NQE_loss169.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KANQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "=====Epoch : 1 =====\n",
      " loss : 0.62202 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.62202 test_loss : 0.59552 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 2 =====\n",
      " loss : 0.70507 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.70507 test_loss : 0.59520 train_metric : 0.25000 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 3 =====\n",
      " loss : 0.47348 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.47348 test_loss : 0.60730 train_metric : 0.46875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 4 =====\n",
      " loss : 0.62969 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62969 test_loss : 0.58993 train_metric : 0.31250 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 5 =====\n",
      " loss : 0.43554 metric0 : 0.53125\n",
      "\n",
      " train_loss : 0.43554 test_loss : 0.59000 train_metric : 0.53125 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 6 =====\n",
      " loss : 0.71426 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.71426 test_loss : 0.59110 train_metric : 0.21875 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 7 =====\n",
      " loss : 0.61452 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61452 test_loss : 0.59645 train_metric : 0.31250 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 8 =====\n",
      " loss : 0.50676 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.50676 test_loss : 0.59639 train_metric : 0.40625 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 9 =====\n",
      " loss : 0.60279 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60279 test_loss : 0.60271 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 10 =====\n",
      " loss : 0.71217 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.71217 test_loss : 0.59792 train_metric : 0.21875 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 11 =====\n",
      " loss : 0.49484 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.49484 test_loss : 0.59672 train_metric : 0.43750 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 12 =====\n",
      " loss : 0.67119 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.67119 test_loss : 0.59874 train_metric : 0.18750 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 13 =====\n",
      " loss : 0.59724 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59724 test_loss : 0.59816 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 14 =====\n",
      " loss : 0.60983 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.60983 test_loss : 0.59998 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 15 =====\n",
      " loss : 0.63938 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63938 test_loss : 0.59687 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 16 =====\n",
      " loss : 0.59491 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59491 test_loss : 0.59901 train_metric : 0.34375 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 17 =====\n",
      " loss : 0.48047 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.48047 test_loss : 0.59654 train_metric : 0.46875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 18 =====\n",
      " loss : 0.59126 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59126 test_loss : 0.59026 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 19 =====\n",
      " loss : 0.70521 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.70521 test_loss : 0.59799 train_metric : 0.21875 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 20 =====\n",
      " loss : 0.57228 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.57228 test_loss : 0.59478 train_metric : 0.34375 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 21 =====\n",
      " loss : 0.65525 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.65525 test_loss : 0.59652 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 22 =====\n",
      " loss : 0.56284 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56284 test_loss : 0.60061 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 23 =====\n",
      " loss : 0.65878 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65878 test_loss : 0.58734 train_metric : 0.25000 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 24 =====\n",
      " loss : 0.65360 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65360 test_loss : 0.60166 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 25 =====\n",
      " loss : 0.60359 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60359 test_loss : 0.59895 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 26 =====\n",
      " loss : 0.55368 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55368 test_loss : 0.59933 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 27 =====\n",
      " loss : 0.53172 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53172 test_loss : 0.58889 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 28 =====\n",
      " loss : 0.52704 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.52704 test_loss : 0.58603 train_metric : 0.40625 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 29 =====\n",
      " loss : 0.68372 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.68372 test_loss : 0.60271 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 30 =====\n",
      " loss : 0.70200 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.70200 test_loss : 0.59398 train_metric : 0.18750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 31 =====\n",
      " loss : 0.55222 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55222 test_loss : 0.59980 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 32 =====\n",
      " loss : 0.55040 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55040 test_loss : 0.59923 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 33 =====\n",
      " loss : 0.63002 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.63002 test_loss : 0.59917 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 34 =====\n",
      " loss : 0.53066 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.53066 test_loss : 0.59907 train_metric : 0.43750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 35 =====\n",
      " loss : 0.55806 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55806 test_loss : 0.59311 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 36 =====\n",
      " loss : 0.60593 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60593 test_loss : 0.59850 train_metric : 0.34375 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 37 =====\n",
      " loss : 0.62713 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.62713 test_loss : 0.59656 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 38 =====\n",
      " loss : 0.54147 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54147 test_loss : 0.60479 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 39 =====\n",
      " loss : 0.76260 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.76260 test_loss : 0.60024 train_metric : 0.18750 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 40 =====\n",
      " loss : 0.54575 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54575 test_loss : 0.59792 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 41 =====\n",
      " loss : 0.69196 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.69196 test_loss : 0.59577 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 42 =====\n",
      " loss : 0.54533 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54533 test_loss : 0.59596 train_metric : 0.40625 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 43 =====\n",
      " loss : 0.50003 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.50003 test_loss : 0.59702 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 44 =====\n",
      " loss : 0.64230 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64230 test_loss : 0.59698 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 45 =====\n",
      " loss : 0.51531 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.51531 test_loss : 0.59797 train_metric : 0.43750 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 46 =====\n",
      " loss : 0.56773 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56773 test_loss : 0.59380 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 47 =====\n",
      " loss : 0.58789 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.58789 test_loss : 0.59287 train_metric : 0.31250 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 48 =====\n",
      " loss : 0.49519 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.49519 test_loss : 0.60905 train_metric : 0.40625 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 49 =====\n",
      " loss : 0.67011 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.67011 test_loss : 0.59591 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 50 =====\n",
      " loss : 0.60385 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60385 test_loss : 0.59471 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 51 =====\n",
      " loss : 0.75567 metric0 : 0.12500\n",
      "\n",
      " train_loss : 0.75567 test_loss : 0.60438 train_metric : 0.12500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 52 =====\n",
      " loss : 0.57353 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.57353 test_loss : 0.59767 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 53 =====\n",
      " loss : 0.53967 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53967 test_loss : 0.59765 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 54 =====\n",
      " loss : 0.65282 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65282 test_loss : 0.59858 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 55 =====\n",
      " loss : 0.79171 metric0 : 0.12500\n",
      "\n",
      " train_loss : 0.79171 test_loss : 0.59377 train_metric : 0.12500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 56 =====\n",
      " loss : 0.65307 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65307 test_loss : 0.59964 train_metric : 0.28125 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 57 =====\n",
      " loss : 0.54514 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54514 test_loss : 0.59641 train_metric : 0.37500 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 58 =====\n",
      " loss : 0.55780 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55780 test_loss : 0.59480 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 59 =====\n",
      " loss : 0.63755 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63755 test_loss : 0.59567 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 60 =====\n",
      " loss : 0.71217 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.71217 test_loss : 0.60589 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 61 =====\n",
      " loss : 0.59692 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59692 test_loss : 0.59495 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 62 =====\n",
      " loss : 0.53713 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53713 test_loss : 0.59456 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 63 =====\n",
      " loss : 0.62316 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62316 test_loss : 0.59495 train_metric : 0.31250 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 64 =====\n",
      " loss : 0.65500 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65500 test_loss : 0.59911 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 65 =====\n",
      " loss : 0.56226 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56226 test_loss : 0.58902 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 66 =====\n",
      " loss : 0.62048 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62048 test_loss : 0.59398 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 67 =====\n",
      " loss : 0.59224 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.59224 test_loss : 0.58674 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 68 =====\n",
      " loss : 0.65577 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65577 test_loss : 0.59360 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 69 =====\n",
      " loss : 0.72488 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.72488 test_loss : 0.59824 train_metric : 0.18750 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 70 =====\n",
      " loss : 0.52153 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.52153 test_loss : 0.59683 train_metric : 0.43750 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 71 =====\n",
      " loss : 0.60046 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60046 test_loss : 0.59432 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 72 =====\n",
      " loss : 0.55209 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55209 test_loss : 0.59837 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 73 =====\n",
      " loss : 0.52753 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.52753 test_loss : 0.59702 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 74 =====\n",
      " loss : 0.57858 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.57858 test_loss : 0.59493 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 75 =====\n",
      " loss : 0.45026 metric0 : 0.50000\n",
      "\n",
      " train_loss : 0.45026 test_loss : 0.60374 train_metric : 0.50000 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 76 =====\n",
      " loss : 0.70178 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.70178 test_loss : 0.60391 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 77 =====\n",
      " loss : 0.64875 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64875 test_loss : 0.59580 train_metric : 0.28125 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 78 =====\n",
      " loss : 0.59535 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59535 test_loss : 0.59277 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 79 =====\n",
      " loss : 0.51131 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.51131 test_loss : 0.59211 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 80 =====\n",
      " loss : 0.44180 metric0 : 0.50000\n",
      "\n",
      " train_loss : 0.44180 test_loss : 0.59356 train_metric : 0.50000 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 81 =====\n",
      " loss : 0.61617 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61617 test_loss : 0.59624 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 82 =====\n",
      " loss : 0.64866 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.64866 test_loss : 0.59603 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 83 =====\n",
      " loss : 0.71316 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.71316 test_loss : 0.60128 train_metric : 0.21875 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 84 =====\n",
      " loss : 0.59863 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59863 test_loss : 0.59202 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 85 =====\n",
      " loss : 0.57668 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.57668 test_loss : 0.60006 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 86 =====\n",
      " loss : 0.62380 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.62380 test_loss : 0.60107 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 87 =====\n",
      " loss : 0.59105 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59105 test_loss : 0.60088 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 88 =====\n",
      " loss : 0.74051 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.74051 test_loss : 0.59663 train_metric : 0.18750 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 89 =====\n",
      " loss : 0.47607 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.47607 test_loss : 0.59125 train_metric : 0.43750 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 90 =====\n",
      " loss : 0.72578 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.72578 test_loss : 0.59831 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 91 =====\n",
      " loss : 0.68473 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.68473 test_loss : 0.59869 train_metric : 0.21875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 92 =====\n",
      " loss : 0.69704 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.69704 test_loss : 0.58442 train_metric : 0.25000 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 93 =====\n",
      " loss : 0.47735 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.47735 test_loss : 0.60207 train_metric : 0.46875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 94 =====\n",
      " loss : 0.53331 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.53331 test_loss : 0.59602 train_metric : 0.43750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 95 =====\n",
      " loss : 0.65813 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65813 test_loss : 0.58893 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 96 =====\n",
      " loss : 0.63250 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.63250 test_loss : 0.60122 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 97 =====\n",
      " loss : 0.50478 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.50478 test_loss : 0.60334 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 98 =====\n",
      " loss : 0.66529 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66529 test_loss : 0.59296 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 99 =====\n",
      " loss : 0.57516 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.57516 test_loss : 0.58820 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 100 =====\n",
      " loss : 0.50889 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.50889 test_loss : 0.60710 train_metric : 0.40625 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 101 =====\n",
      " loss : 0.36803 metric0 : 0.59375\n",
      "\n",
      " train_loss : 0.36803 test_loss : 0.59616 train_metric : 0.59375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 102 =====\n",
      " loss : 0.61078 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.61078 test_loss : 0.59893 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 103 =====\n",
      " loss : 0.64350 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64350 test_loss : 0.59679 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 104 =====\n",
      " loss : 0.80006 metric0 : 0.12500\n",
      "\n",
      " train_loss : 0.80006 test_loss : 0.59909 train_metric : 0.12500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 105 =====\n",
      " loss : 0.66805 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.66805 test_loss : 0.59272 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 106 =====\n",
      " loss : 0.63976 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.63976 test_loss : 0.60339 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 107 =====\n",
      " loss : 0.62390 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62390 test_loss : 0.60237 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 108 =====\n",
      " loss : 0.65311 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65311 test_loss : 0.59444 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 109 =====\n",
      " loss : 0.67372 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.67372 test_loss : 0.59930 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 110 =====\n",
      " loss : 0.56572 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56572 test_loss : 0.59922 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 111 =====\n",
      " loss : 0.61504 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61504 test_loss : 0.60042 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 112 =====\n",
      " loss : 0.64867 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64867 test_loss : 0.60162 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 113 =====\n",
      " loss : 0.55823 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55823 test_loss : 0.60307 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 114 =====\n",
      " loss : 0.45111 metric0 : 0.50000\n",
      "\n",
      " train_loss : 0.45111 test_loss : 0.59908 train_metric : 0.50000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 115 =====\n",
      " loss : 0.51845 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.51845 test_loss : 0.60003 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 116 =====\n",
      " loss : 0.69288 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.69288 test_loss : 0.60853 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 117 =====\n",
      " loss : 0.66399 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66399 test_loss : 0.60357 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 118 =====\n",
      " loss : 0.55953 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.55953 test_loss : 0.59799 train_metric : 0.34375 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 119 =====\n",
      " loss : 0.54759 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54759 test_loss : 0.59622 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 120 =====\n",
      " loss : 0.53596 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53596 test_loss : 0.59301 train_metric : 0.37500 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 121 =====\n",
      " loss : 0.55533 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55533 test_loss : 0.60245 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 122 =====\n",
      " loss : 0.59090 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59090 test_loss : 0.59375 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 123 =====\n",
      " loss : 0.65796 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65796 test_loss : 0.59327 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 124 =====\n",
      " loss : 0.56718 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56718 test_loss : 0.59458 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 125 =====\n",
      " loss : 0.65562 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65562 test_loss : 0.60756 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 126 =====\n",
      " loss : 0.66118 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66118 test_loss : 0.59577 train_metric : 0.25000 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 127 =====\n",
      " loss : 0.54247 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54247 test_loss : 0.60030 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 128 =====\n",
      " loss : 0.65700 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65700 test_loss : 0.59801 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 129 =====\n",
      " loss : 0.70661 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.70661 test_loss : 0.59634 train_metric : 0.18750 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 130 =====\n",
      " loss : 0.69013 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.69013 test_loss : 0.59599 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 131 =====\n",
      " loss : 0.69021 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.69021 test_loss : 0.59567 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 132 =====\n",
      " loss : 0.58303 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58303 test_loss : 0.59811 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 133 =====\n",
      " loss : 0.55676 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55676 test_loss : 0.59856 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 134 =====\n",
      " loss : 0.66818 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66818 test_loss : 0.60141 train_metric : 0.25000 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 135 =====\n",
      " loss : 0.61035 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.61035 test_loss : 0.59802 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 136 =====\n",
      " loss : 0.63336 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.63336 test_loss : 0.59958 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 137 =====\n",
      " loss : 0.57551 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.57551 test_loss : 0.59611 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 138 =====\n",
      " loss : 0.50642 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.50642 test_loss : 0.59840 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 139 =====\n",
      " loss : 0.61491 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61491 test_loss : 0.59345 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 140 =====\n",
      " loss : 0.66506 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66506 test_loss : 0.58778 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 141 =====\n",
      " loss : 0.54751 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54751 test_loss : 0.59827 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 142 =====\n",
      " loss : 0.68759 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.68759 test_loss : 0.59813 train_metric : 0.21875 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 143 =====\n",
      " loss : 0.42428 metric0 : 0.53125\n",
      "\n",
      " train_loss : 0.42428 test_loss : 0.59452 train_metric : 0.53125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 144 =====\n",
      " loss : 0.63283 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63283 test_loss : 0.60191 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 145 =====\n",
      " loss : 0.41344 metric0 : 0.53125\n",
      "\n",
      " train_loss : 0.41344 test_loss : 0.60394 train_metric : 0.53125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 146 =====\n",
      " loss : 0.47108 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.47108 test_loss : 0.59364 train_metric : 0.46875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 147 =====\n",
      " loss : 0.53529 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53529 test_loss : 0.59662 train_metric : 0.40625 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 148 =====\n",
      " loss : 0.69337 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.69337 test_loss : 0.60016 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 149 =====\n",
      " loss : 0.61680 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61680 test_loss : 0.59993 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 150 =====\n",
      " loss : 0.56765 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56765 test_loss : 0.60241 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 151 =====\n",
      " loss : 0.50891 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.50891 test_loss : 0.60716 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 152 =====\n",
      " loss : 0.64466 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64466 test_loss : 0.59641 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 153 =====\n",
      " loss : 0.44113 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.44113 test_loss : 0.60070 train_metric : 0.43750 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 154 =====\n",
      " loss : 0.63382 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63382 test_loss : 0.59498 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 155 =====\n",
      " loss : 0.67082 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.67082 test_loss : 0.58960 train_metric : 0.25000 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 156 =====\n",
      " loss : 0.72517 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.72517 test_loss : 0.59987 train_metric : 0.21875 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 157 =====\n",
      " loss : 0.64464 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64464 test_loss : 0.60143 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 158 =====\n",
      " loss : 0.55694 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.55694 test_loss : 0.59356 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 159 =====\n",
      " loss : 0.53626 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53626 test_loss : 0.59486 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 160 =====\n",
      " loss : 0.64185 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.64185 test_loss : 0.59897 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 161 =====\n",
      " loss : 0.62856 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62856 test_loss : 0.59843 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 162 =====\n",
      " loss : 0.61923 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61923 test_loss : 0.59165 train_metric : 0.31250 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 163 =====\n",
      " loss : 0.69590 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.69590 test_loss : 0.60083 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 164 =====\n",
      " loss : 0.51522 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.51522 test_loss : 0.59398 train_metric : 0.43750 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 165 =====\n",
      " loss : 0.78120 metric0 : 0.15625\n",
      "\n",
      " train_loss : 0.78120 test_loss : 0.59517 train_metric : 0.15625 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 166 =====\n",
      " loss : 0.65710 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65710 test_loss : 0.60434 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 167 =====\n",
      " loss : 0.73292 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.73292 test_loss : 0.59586 train_metric : 0.18750 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 168 =====\n",
      " loss : 0.51245 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.51245 test_loss : 0.59978 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 169 =====\n",
      " loss : 0.51080 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.51080 test_loss : 0.59566 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 170 =====\n",
      " loss : 0.47011 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.47011 test_loss : 0.59739 train_metric : 0.43750 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 171 =====\n",
      " loss : 0.51818 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.51818 test_loss : 0.59543 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 172 =====\n",
      " loss : 0.65940 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65940 test_loss : 0.59786 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 173 =====\n",
      " loss : 0.55511 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55511 test_loss : 0.59358 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 174 =====\n",
      " loss : 0.62340 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.62340 test_loss : 0.59637 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 175 =====\n",
      " loss : 0.55826 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55826 test_loss : 0.59883 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 176 =====\n",
      " loss : 0.56647 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56647 test_loss : 0.60258 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 177 =====\n",
      " loss : 0.72374 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.72374 test_loss : 0.58879 train_metric : 0.18750 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 178 =====\n",
      " loss : 0.65939 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65939 test_loss : 0.59671 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 179 =====\n",
      " loss : 0.58634 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58634 test_loss : 0.59434 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 180 =====\n",
      " loss : 0.63557 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63557 test_loss : 0.59631 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 181 =====\n",
      " loss : 0.63849 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63849 test_loss : 0.59594 train_metric : 0.28125 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 182 =====\n",
      " loss : 0.53942 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53942 test_loss : 0.59708 train_metric : 0.37500 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 183 =====\n",
      " loss : 0.71549 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.71549 test_loss : 0.58722 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 184 =====\n",
      " loss : 0.56149 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56149 test_loss : 0.59574 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 185 =====\n",
      " loss : 0.60881 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60881 test_loss : 0.59982 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 186 =====\n",
      " loss : 0.64477 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.64477 test_loss : 0.59214 train_metric : 0.25000 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 187 =====\n",
      " loss : 0.76699 metric0 : 0.15625\n",
      "\n",
      " train_loss : 0.76699 test_loss : 0.60108 train_metric : 0.15625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 188 =====\n",
      " loss : 0.57587 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.57587 test_loss : 0.59696 train_metric : 0.37500 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 189 =====\n",
      " loss : 0.60676 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60676 test_loss : 0.59734 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 190 =====\n",
      " loss : 0.57543 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.57543 test_loss : 0.59315 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 191 =====\n",
      " loss : 0.52517 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.52517 test_loss : 0.59745 train_metric : 0.43750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 192 =====\n",
      " loss : 0.57819 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.57819 test_loss : 0.60153 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 193 =====\n",
      " loss : 0.45508 metric0 : 0.50000\n",
      "\n",
      " train_loss : 0.45508 test_loss : 0.59632 train_metric : 0.50000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 194 =====\n",
      " loss : 0.62458 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.62458 test_loss : 0.59763 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 195 =====\n",
      " loss : 0.66833 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.66833 test_loss : 0.58858 train_metric : 0.21875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 196 =====\n",
      " loss : 0.61983 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61983 test_loss : 0.59830 train_metric : 0.31250 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 197 =====\n",
      " loss : 0.68972 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.68972 test_loss : 0.59731 train_metric : 0.21875 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 198 =====\n",
      " loss : 0.60256 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60256 test_loss : 0.59293 train_metric : 0.31250 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 199 =====\n",
      " loss : 0.52611 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.52611 test_loss : 0.59797 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 200 =====\n",
      " loss : 0.64864 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64864 test_loss : 0.59677 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 201 =====\n",
      " loss : 0.58003 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.58003 test_loss : 0.59190 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 202 =====\n",
      " loss : 0.53221 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53221 test_loss : 0.59500 train_metric : 0.40625 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 203 =====\n",
      " loss : 0.61474 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.61474 test_loss : 0.58971 train_metric : 0.34375 test_metric : 0.33717\n",
      "\n",
      "=====Epoch : 204 =====\n",
      " loss : 0.52000 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.52000 test_loss : 0.60015 train_metric : 0.43750 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 205 =====\n",
      " loss : 0.56842 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56842 test_loss : 0.59720 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 206 =====\n",
      " loss : 0.63180 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63180 test_loss : 0.60146 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 207 =====\n",
      " loss : 0.56584 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56584 test_loss : 0.59820 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 208 =====\n",
      " loss : 0.55219 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55219 test_loss : 0.59853 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 209 =====\n",
      " loss : 0.65061 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65061 test_loss : 0.59164 train_metric : 0.25000 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 210 =====\n",
      " loss : 0.60337 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60337 test_loss : 0.59706 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 211 =====\n",
      " loss : 0.67637 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.67637 test_loss : 0.59291 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 212 =====\n",
      " loss : 0.56337 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56337 test_loss : 0.58800 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 213 =====\n",
      " loss : 0.68907 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.68907 test_loss : 0.59865 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 214 =====\n",
      " loss : 0.52891 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.52891 test_loss : 0.59886 train_metric : 0.40625 test_metric : 0.33717\n",
      "\n",
      "=====Epoch : 215 =====\n",
      " loss : 0.63493 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63493 test_loss : 0.59513 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 216 =====\n",
      " loss : 0.61961 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61961 test_loss : 0.60386 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 217 =====\n",
      " loss : 0.57013 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.57013 test_loss : 0.60666 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 218 =====\n",
      " loss : 0.61012 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61012 test_loss : 0.59752 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 219 =====\n",
      " loss : 0.53668 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53668 test_loss : 0.59572 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 220 =====\n",
      " loss : 0.66018 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.66018 test_loss : 0.59790 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 221 =====\n",
      " loss : 0.62537 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62537 test_loss : 0.60036 train_metric : 0.31250 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 222 =====\n",
      " loss : 0.58216 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.58216 test_loss : 0.58959 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 223 =====\n",
      " loss : 0.50318 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.50318 test_loss : 0.60367 train_metric : 0.43750 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 224 =====\n",
      " loss : 0.70687 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.70687 test_loss : 0.59227 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 225 =====\n",
      " loss : 0.58600 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58600 test_loss : 0.58550 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 226 =====\n",
      " loss : 0.59510 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59510 test_loss : 0.59751 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 227 =====\n",
      " loss : 0.53593 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53593 test_loss : 0.59465 train_metric : 0.37500 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 228 =====\n",
      " loss : 0.55407 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.55407 test_loss : 0.58810 train_metric : 0.34375 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 229 =====\n",
      " loss : 0.68920 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.68920 test_loss : 0.59859 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 230 =====\n",
      " loss : 0.60038 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60038 test_loss : 0.60284 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 231 =====\n",
      " loss : 0.53547 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53547 test_loss : 0.60490 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 232 =====\n",
      " loss : 0.54492 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54492 test_loss : 0.60132 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 233 =====\n",
      " loss : 0.49003 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.49003 test_loss : 0.59269 train_metric : 0.46875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 234 =====\n",
      " loss : 0.60272 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60272 test_loss : 0.59566 train_metric : 0.34375 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 235 =====\n",
      " loss : 0.47281 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.47281 test_loss : 0.59232 train_metric : 0.43750 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 236 =====\n",
      " loss : 0.64715 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64715 test_loss : 0.59712 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 237 =====\n",
      " loss : 0.60640 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60640 test_loss : 0.59399 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 238 =====\n",
      " loss : 0.64261 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64261 test_loss : 0.60080 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 239 =====\n",
      " loss : 0.62216 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62216 test_loss : 0.59379 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 240 =====\n",
      " loss : 0.72451 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.72451 test_loss : 0.59388 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 241 =====\n",
      " loss : 0.63949 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63949 test_loss : 0.59953 train_metric : 0.28125 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 242 =====\n",
      " loss : 0.69674 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.69674 test_loss : 0.60374 train_metric : 0.21875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 243 =====\n",
      " loss : 0.60113 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60113 test_loss : 0.60685 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 244 =====\n",
      " loss : 0.51232 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.51232 test_loss : 0.60431 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 245 =====\n",
      " loss : 0.59711 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.59711 test_loss : 0.59812 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 246 =====\n",
      " loss : 0.61586 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.61586 test_loss : 0.60138 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 247 =====\n",
      " loss : 0.66618 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66618 test_loss : 0.59610 train_metric : 0.25000 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 248 =====\n",
      " loss : 0.56069 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56069 test_loss : 0.59687 train_metric : 0.37500 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 249 =====\n",
      " loss : 0.57584 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.57584 test_loss : 0.59602 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 250 =====\n",
      " loss : 0.67573 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.67573 test_loss : 0.59619 train_metric : 0.21875 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 251 =====\n",
      " loss : 0.63720 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.63720 test_loss : 0.60209 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 252 =====\n",
      " loss : 0.61482 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.61482 test_loss : 0.58981 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 253 =====\n",
      " loss : 0.62325 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.62325 test_loss : 0.59668 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 254 =====\n",
      " loss : 0.61392 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61392 test_loss : 0.59401 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 255 =====\n",
      " loss : 0.59501 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59501 test_loss : 0.59870 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 256 =====\n",
      " loss : 0.56141 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56141 test_loss : 0.58709 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 257 =====\n",
      " loss : 0.54895 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54895 test_loss : 0.60059 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 258 =====\n",
      " loss : 0.60227 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60227 test_loss : 0.60081 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 259 =====\n",
      " loss : 0.51617 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.51617 test_loss : 0.59736 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 260 =====\n",
      " loss : 0.61247 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61247 test_loss : 0.59731 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 261 =====\n",
      " loss : 0.57460 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.57460 test_loss : 0.59852 train_metric : 0.37500 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 262 =====\n",
      " loss : 0.58295 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58295 test_loss : 0.59791 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 263 =====\n",
      " loss : 0.72520 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.72520 test_loss : 0.59393 train_metric : 0.18750 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 264 =====\n",
      " loss : 0.59034 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59034 test_loss : 0.59708 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 265 =====\n",
      " loss : 0.57198 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.57198 test_loss : 0.59475 train_metric : 0.34375 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 266 =====\n",
      " loss : 0.63099 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63099 test_loss : 0.58991 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 267 =====\n",
      " loss : 0.49795 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.49795 test_loss : 0.58921 train_metric : 0.43750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 268 =====\n",
      " loss : 0.53047 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53047 test_loss : 0.60123 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 269 =====\n",
      " loss : 0.60187 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.60187 test_loss : 0.60461 train_metric : 0.25000 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 270 =====\n",
      " loss : 0.67971 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.67971 test_loss : 0.60344 train_metric : 0.21875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 271 =====\n",
      " loss : 0.54016 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54016 test_loss : 0.60036 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 272 =====\n",
      " loss : 0.58982 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.58982 test_loss : 0.59288 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 273 =====\n",
      " loss : 0.58312 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58312 test_loss : 0.59456 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 274 =====\n",
      " loss : 0.52963 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.52963 test_loss : 0.59791 train_metric : 0.43750 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 275 =====\n",
      " loss : 0.57451 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.57451 test_loss : 0.60245 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 276 =====\n",
      " loss : 0.54263 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54263 test_loss : 0.59623 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 277 =====\n",
      " loss : 0.73672 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.73672 test_loss : 0.59641 train_metric : 0.18750 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 278 =====\n",
      " loss : 0.66602 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.66602 test_loss : 0.59519 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 279 =====\n",
      " loss : 0.62790 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62790 test_loss : 0.59942 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 280 =====\n",
      " loss : 0.60606 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.60606 test_loss : 0.60026 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 281 =====\n",
      " loss : 0.51897 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.51897 test_loss : 0.58986 train_metric : 0.40625 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 282 =====\n",
      " loss : 0.64700 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64700 test_loss : 0.60282 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 283 =====\n",
      " loss : 0.59021 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59021 test_loss : 0.59726 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 284 =====\n",
      " loss : 0.68299 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.68299 test_loss : 0.59221 train_metric : 0.21875 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 285 =====\n",
      " loss : 0.53106 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53106 test_loss : 0.59925 train_metric : 0.40625 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 286 =====\n",
      " loss : 0.71236 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.71236 test_loss : 0.60206 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 287 =====\n",
      " loss : 0.63376 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63376 test_loss : 0.59554 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 288 =====\n",
      " loss : 0.52541 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.52541 test_loss : 0.58447 train_metric : 0.43750 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 289 =====\n",
      " loss : 0.56037 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56037 test_loss : 0.60072 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 290 =====\n",
      " loss : 0.63775 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.63775 test_loss : 0.58715 train_metric : 0.25000 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 291 =====\n",
      " loss : 0.59430 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59430 test_loss : 0.59732 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 292 =====\n",
      " loss : 0.55853 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55853 test_loss : 0.60309 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 293 =====\n",
      " loss : 0.65269 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65269 test_loss : 0.59823 train_metric : 0.25000 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 294 =====\n",
      " loss : 0.60122 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60122 test_loss : 0.59179 train_metric : 0.34375 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 295 =====\n",
      " loss : 0.43449 metric0 : 0.50000\n",
      "\n",
      " train_loss : 0.43449 test_loss : 0.59789 train_metric : 0.50000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 296 =====\n",
      " loss : 0.54718 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54718 test_loss : 0.60544 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 297 =====\n",
      " loss : 0.61007 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61007 test_loss : 0.58348 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 298 =====\n",
      " loss : 0.54715 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54715 test_loss : 0.59629 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 299 =====\n",
      " loss : 0.53254 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53254 test_loss : 0.59679 train_metric : 0.40625 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 300 =====\n",
      " loss : 0.51160 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.51160 test_loss : 0.59915 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 301 =====\n",
      " loss : 0.79253 metric0 : 0.12500\n",
      "\n",
      " train_loss : 0.79253 test_loss : 0.59772 train_metric : 0.12500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 302 =====\n",
      " loss : 0.64537 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.64537 test_loss : 0.60186 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 303 =====\n",
      " loss : 0.65334 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.65334 test_loss : 0.58727 train_metric : 0.21875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 304 =====\n",
      " loss : 0.57661 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.57661 test_loss : 0.59878 train_metric : 0.37500 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 305 =====\n",
      " loss : 0.61796 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.61796 test_loss : 0.59733 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 306 =====\n",
      " loss : 0.57200 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.57200 test_loss : 0.59524 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 307 =====\n",
      " loss : 0.64599 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64599 test_loss : 0.59459 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 308 =====\n",
      " loss : 0.67482 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.67482 test_loss : 0.60078 train_metric : 0.25000 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 309 =====\n",
      " loss : 0.65620 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65620 test_loss : 0.60277 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 310 =====\n",
      " loss : 0.61556 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.61556 test_loss : 0.59992 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 311 =====\n",
      " loss : 0.65925 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65925 test_loss : 0.59077 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 312 =====\n",
      " loss : 0.47303 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.47303 test_loss : 0.59702 train_metric : 0.46875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 313 =====\n",
      " loss : 0.51956 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.51956 test_loss : 0.59609 train_metric : 0.43750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 314 =====\n",
      " loss : 0.72026 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.72026 test_loss : 0.60574 train_metric : 0.18750 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 315 =====\n",
      " loss : 0.57773 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.57773 test_loss : 0.60099 train_metric : 0.34375 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 316 =====\n",
      " loss : 0.61417 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.61417 test_loss : 0.59401 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 317 =====\n",
      " loss : 0.55144 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55144 test_loss : 0.59242 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 318 =====\n",
      " loss : 0.65050 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65050 test_loss : 0.59587 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 319 =====\n",
      " loss : 0.60481 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.60481 test_loss : 0.59697 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 320 =====\n",
      " loss : 0.60955 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60955 test_loss : 0.59569 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 321 =====\n",
      " loss : 0.52946 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.52946 test_loss : 0.59664 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 322 =====\n",
      " loss : 0.63124 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63124 test_loss : 0.60317 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 323 =====\n",
      " loss : 0.66372 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66372 test_loss : 0.59138 train_metric : 0.25000 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 324 =====\n",
      " loss : 0.62945 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62945 test_loss : 0.59922 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 325 =====\n",
      " loss : 0.56507 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56507 test_loss : 0.59128 train_metric : 0.37500 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 326 =====\n",
      " loss : 0.50564 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.50564 test_loss : 0.60480 train_metric : 0.43750 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 327 =====\n",
      " loss : 0.64568 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.64568 test_loss : 0.59736 train_metric : 0.25000 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 328 =====\n",
      " loss : 0.63318 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63318 test_loss : 0.60319 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 329 =====\n",
      " loss : 0.56030 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56030 test_loss : 0.59748 train_metric : 0.37500 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 330 =====\n",
      " loss : 0.61002 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.61002 test_loss : 0.59880 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 331 =====\n",
      " loss : 0.60981 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60981 test_loss : 0.59125 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 332 =====\n",
      " loss : 0.59354 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59354 test_loss : 0.60429 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 333 =====\n",
      " loss : 0.59907 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59907 test_loss : 0.60088 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 334 =====\n",
      " loss : 0.60260 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60260 test_loss : 0.60071 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 335 =====\n",
      " loss : 0.67668 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.67668 test_loss : 0.58997 train_metric : 0.21875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 336 =====\n",
      " loss : 0.53255 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53255 test_loss : 0.59400 train_metric : 0.40625 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 337 =====\n",
      " loss : 0.66413 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66413 test_loss : 0.59145 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 338 =====\n",
      " loss : 0.71936 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.71936 test_loss : 0.59560 train_metric : 0.18750 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 339 =====\n",
      " loss : 0.56728 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56728 test_loss : 0.59482 train_metric : 0.37500 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 340 =====\n",
      " loss : 0.62069 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62069 test_loss : 0.59461 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 341 =====\n",
      " loss : 0.61550 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61550 test_loss : 0.58718 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 342 =====\n",
      " loss : 0.51065 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.51065 test_loss : 0.59969 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 343 =====\n",
      " loss : 0.55398 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55398 test_loss : 0.60227 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 344 =====\n",
      " loss : 0.54973 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54973 test_loss : 0.59173 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 345 =====\n",
      " loss : 0.54442 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54442 test_loss : 0.59319 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 346 =====\n",
      " loss : 0.64600 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.64600 test_loss : 0.59786 train_metric : 0.25000 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 347 =====\n",
      " loss : 0.56430 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56430 test_loss : 0.59668 train_metric : 0.37500 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 348 =====\n",
      " loss : 0.72558 metric0 : 0.15625\n",
      "\n",
      " train_loss : 0.72558 test_loss : 0.59144 train_metric : 0.15625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 349 =====\n",
      " loss : 0.59793 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59793 test_loss : 0.60053 train_metric : 0.34375 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 350 =====\n",
      " loss : 0.54904 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54904 test_loss : 0.59176 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 351 =====\n",
      " loss : 0.54592 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54592 test_loss : 0.60217 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 352 =====\n",
      " loss : 0.68499 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.68499 test_loss : 0.59350 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 353 =====\n",
      " loss : 0.59418 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59418 test_loss : 0.59745 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 354 =====\n",
      " loss : 0.66783 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66783 test_loss : 0.59513 train_metric : 0.25000 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 355 =====\n",
      " loss : 0.62453 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.62453 test_loss : 0.59674 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 356 =====\n",
      " loss : 0.79094 metric0 : 0.12500\n",
      "\n",
      " train_loss : 0.79094 test_loss : 0.59673 train_metric : 0.12500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 357 =====\n",
      " loss : 0.58578 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.58578 test_loss : 0.59726 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 358 =====\n",
      " loss : 0.66409 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66409 test_loss : 0.59146 train_metric : 0.25000 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 359 =====\n",
      " loss : 0.54320 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54320 test_loss : 0.59727 train_metric : 0.40625 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 360 =====\n",
      " loss : 0.46585 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.46585 test_loss : 0.59547 train_metric : 0.46875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 361 =====\n",
      " loss : 0.67082 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.67082 test_loss : 0.58798 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 362 =====\n",
      " loss : 0.65737 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.65737 test_loss : 0.60334 train_metric : 0.21875 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 363 =====\n",
      " loss : 0.66414 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.66414 test_loss : 0.59942 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 364 =====\n",
      " loss : 0.56637 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56637 test_loss : 0.59990 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 365 =====\n",
      " loss : 0.72776 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.72776 test_loss : 0.60008 train_metric : 0.21875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 366 =====\n",
      " loss : 0.68221 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.68221 test_loss : 0.60612 train_metric : 0.21875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 367 =====\n",
      " loss : 0.50971 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.50971 test_loss : 0.59794 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 368 =====\n",
      " loss : 0.65549 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65549 test_loss : 0.59991 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 369 =====\n",
      " loss : 0.55802 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55802 test_loss : 0.59474 train_metric : 0.37500 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 370 =====\n",
      " loss : 0.62221 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62221 test_loss : 0.60526 train_metric : 0.31250 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 371 =====\n",
      " loss : 0.60711 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60711 test_loss : 0.60329 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 372 =====\n",
      " loss : 0.56130 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56130 test_loss : 0.59354 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 373 =====\n",
      " loss : 0.54498 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54498 test_loss : 0.59722 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 374 =====\n",
      " loss : 0.65648 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65648 test_loss : 0.60571 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 375 =====\n",
      " loss : 0.62713 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62713 test_loss : 0.60033 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 376 =====\n",
      " loss : 0.65180 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65180 test_loss : 0.60467 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 377 =====\n",
      " loss : 0.68289 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.68289 test_loss : 0.59699 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 378 =====\n",
      " loss : 0.70878 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.70878 test_loss : 0.59098 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 379 =====\n",
      " loss : 0.55025 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55025 test_loss : 0.59835 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 380 =====\n",
      " loss : 0.66505 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.66505 test_loss : 0.58542 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 381 =====\n",
      " loss : 0.61266 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.61266 test_loss : 0.60355 train_metric : 0.28125 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 382 =====\n",
      " loss : 0.58316 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58316 test_loss : 0.59491 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 383 =====\n",
      " loss : 0.57353 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.57353 test_loss : 0.60305 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 384 =====\n",
      " loss : 0.62088 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62088 test_loss : 0.58767 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 385 =====\n",
      " loss : 0.61705 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61705 test_loss : 0.59877 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 386 =====\n",
      " loss : 0.48110 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.48110 test_loss : 0.60488 train_metric : 0.43750 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 387 =====\n",
      " loss : 0.73290 metric0 : 0.15625\n",
      "\n",
      " train_loss : 0.73290 test_loss : 0.59528 train_metric : 0.15625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 388 =====\n",
      " loss : 0.53862 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53862 test_loss : 0.59269 train_metric : 0.40625 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 389 =====\n",
      " loss : 0.48973 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.48973 test_loss : 0.59816 train_metric : 0.46875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 390 =====\n",
      " loss : 0.66291 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66291 test_loss : 0.60070 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 391 =====\n",
      " loss : 0.52969 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.52969 test_loss : 0.59829 train_metric : 0.37500 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 392 =====\n",
      " loss : 0.53350 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53350 test_loss : 0.59833 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 393 =====\n",
      " loss : 0.47446 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.47446 test_loss : 0.60025 train_metric : 0.43750 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 394 =====\n",
      " loss : 0.77844 metric0 : 0.15625\n",
      "\n",
      " train_loss : 0.77844 test_loss : 0.59742 train_metric : 0.15625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 395 =====\n",
      " loss : 0.62292 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62292 test_loss : 0.59396 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 396 =====\n",
      " loss : 0.51014 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.51014 test_loss : 0.59868 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 397 =====\n",
      " loss : 0.50196 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.50196 test_loss : 0.59734 train_metric : 0.43750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 398 =====\n",
      " loss : 0.63838 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63838 test_loss : 0.59629 train_metric : 0.28125 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 399 =====\n",
      " loss : 0.61857 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61857 test_loss : 0.58785 train_metric : 0.31250 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 400 =====\n",
      " loss : 0.58175 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58175 test_loss : 0.59567 train_metric : 0.34375 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 401 =====\n",
      " loss : 0.62141 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62141 test_loss : 0.59301 train_metric : 0.31250 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 402 =====\n",
      " loss : 0.57738 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.57738 test_loss : 0.60373 train_metric : 0.31250 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 403 =====\n",
      " loss : 0.63238 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63238 test_loss : 0.60442 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 404 =====\n",
      " loss : 0.49827 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.49827 test_loss : 0.59946 train_metric : 0.46875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 405 =====\n",
      " loss : 0.69263 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.69263 test_loss : 0.59746 train_metric : 0.21875 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 406 =====\n",
      " loss : 0.66368 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66368 test_loss : 0.59478 train_metric : 0.25000 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 407 =====\n",
      " loss : 0.70166 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.70166 test_loss : 0.59908 train_metric : 0.21875 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 408 =====\n",
      " loss : 0.64397 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64397 test_loss : 0.59329 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 409 =====\n",
      " loss : 0.75726 metric0 : 0.15625\n",
      "\n",
      " train_loss : 0.75726 test_loss : 0.59370 train_metric : 0.15625 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 410 =====\n",
      " loss : 0.63594 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.63594 test_loss : 0.59680 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 411 =====\n",
      " loss : 0.53849 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53849 test_loss : 0.60321 train_metric : 0.40625 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 412 =====\n",
      " loss : 0.67239 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.67239 test_loss : 0.59844 train_metric : 0.25000 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 413 =====\n",
      " loss : 0.70159 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.70159 test_loss : 0.60383 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 414 =====\n",
      " loss : 0.55746 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55746 test_loss : 0.59451 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 415 =====\n",
      " loss : 0.55111 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55111 test_loss : 0.59413 train_metric : 0.37500 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 416 =====\n",
      " loss : 0.61772 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.61772 test_loss : 0.59406 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 417 =====\n",
      " loss : 0.53179 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.53179 test_loss : 0.59712 train_metric : 0.34375 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 418 =====\n",
      " loss : 0.61972 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61972 test_loss : 0.59599 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 419 =====\n",
      " loss : 0.48387 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.48387 test_loss : 0.59232 train_metric : 0.46875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 420 =====\n",
      " loss : 0.60894 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60894 test_loss : 0.59796 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 421 =====\n",
      " loss : 0.54394 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54394 test_loss : 0.59442 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 422 =====\n",
      " loss : 0.47440 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.47440 test_loss : 0.59908 train_metric : 0.43750 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 423 =====\n",
      " loss : 0.59844 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59844 test_loss : 0.59541 train_metric : 0.34375 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 424 =====\n",
      " loss : 0.63187 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.63187 test_loss : 0.60104 train_metric : 0.25000 test_metric : 0.32401\n",
      "\n",
      "=====Epoch : 425 =====\n",
      " loss : 0.54257 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54257 test_loss : 0.59324 train_metric : 0.40625 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 426 =====\n",
      " loss : 0.62625 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.62625 test_loss : 0.59308 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 427 =====\n",
      " loss : 0.56759 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56759 test_loss : 0.60014 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 428 =====\n",
      " loss : 0.62555 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.62555 test_loss : 0.59406 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 429 =====\n",
      " loss : 0.58882 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58882 test_loss : 0.59742 train_metric : 0.34375 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 430 =====\n",
      " loss : 0.62640 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.62640 test_loss : 0.59967 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 431 =====\n",
      " loss : 0.73085 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.73085 test_loss : 0.59863 train_metric : 0.18750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 432 =====\n",
      " loss : 0.50718 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.50718 test_loss : 0.59702 train_metric : 0.43750 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 433 =====\n",
      " loss : 0.64485 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64485 test_loss : 0.59709 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 434 =====\n",
      " loss : 0.69572 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.69572 test_loss : 0.59968 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 435 =====\n",
      " loss : 0.55040 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.55040 test_loss : 0.59455 train_metric : 0.40625 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 436 =====\n",
      " loss : 0.66684 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66684 test_loss : 0.59102 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 437 =====\n",
      " loss : 0.54636 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.54636 test_loss : 0.60021 train_metric : 0.40625 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 438 =====\n",
      " loss : 0.65403 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65403 test_loss : 0.58911 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 439 =====\n",
      " loss : 0.61196 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61196 test_loss : 0.59457 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 440 =====\n",
      " loss : 0.53987 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53987 test_loss : 0.59761 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 441 =====\n",
      " loss : 0.45400 metric0 : 0.50000\n",
      "\n",
      " train_loss : 0.45400 test_loss : 0.60127 train_metric : 0.50000 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 442 =====\n",
      " loss : 0.56597 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56597 test_loss : 0.59363 train_metric : 0.37500 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 443 =====\n",
      " loss : 0.63723 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63723 test_loss : 0.60399 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 444 =====\n",
      " loss : 0.70984 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.70984 test_loss : 0.60017 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 445 =====\n",
      " loss : 0.65805 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65805 test_loss : 0.60779 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 446 =====\n",
      " loss : 0.68959 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.68959 test_loss : 0.60368 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 447 =====\n",
      " loss : 0.75218 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.75218 test_loss : 0.60124 train_metric : 0.18750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 448 =====\n",
      " loss : 0.66059 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66059 test_loss : 0.60198 train_metric : 0.25000 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 449 =====\n",
      " loss : 0.63427 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.63427 test_loss : 0.59803 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 450 =====\n",
      " loss : 0.56225 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56225 test_loss : 0.59571 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 451 =====\n",
      " loss : 0.62792 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.62792 test_loss : 0.59929 train_metric : 0.28125 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 452 =====\n",
      " loss : 0.69375 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.69375 test_loss : 0.59787 train_metric : 0.21875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 453 =====\n",
      " loss : 0.66535 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66535 test_loss : 0.59828 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 454 =====\n",
      " loss : 0.63772 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63772 test_loss : 0.59274 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 455 =====\n",
      " loss : 0.68121 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.68121 test_loss : 0.60464 train_metric : 0.21875 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 456 =====\n",
      " loss : 0.65579 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.65579 test_loss : 0.59383 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 457 =====\n",
      " loss : 0.59545 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.59545 test_loss : 0.59289 train_metric : 0.28125 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 458 =====\n",
      " loss : 0.67379 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.67379 test_loss : 0.59537 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 459 =====\n",
      " loss : 0.70375 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.70375 test_loss : 0.59930 train_metric : 0.21875 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 460 =====\n",
      " loss : 0.55849 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55849 test_loss : 0.59797 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 461 =====\n",
      " loss : 0.68225 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.68225 test_loss : 0.59510 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 462 =====\n",
      " loss : 0.55905 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55905 test_loss : 0.58955 train_metric : 0.37500 test_metric : 0.33388\n",
      "\n",
      "=====Epoch : 463 =====\n",
      " loss : 0.53631 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.53631 test_loss : 0.60148 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 464 =====\n",
      " loss : 0.67091 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.67091 test_loss : 0.59345 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 465 =====\n",
      " loss : 0.60616 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60616 test_loss : 0.60391 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 466 =====\n",
      " loss : 0.65797 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.65797 test_loss : 0.59610 train_metric : 0.25000 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 467 =====\n",
      " loss : 0.56854 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56854 test_loss : 0.59565 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 468 =====\n",
      " loss : 0.66960 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.66960 test_loss : 0.59622 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 469 =====\n",
      " loss : 0.66144 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.66144 test_loss : 0.59902 train_metric : 0.28125 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 470 =====\n",
      " loss : 0.60240 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.60240 test_loss : 0.60344 train_metric : 0.34375 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 471 =====\n",
      " loss : 0.73502 metric0 : 0.18750\n",
      "\n",
      " train_loss : 0.73502 test_loss : 0.59818 train_metric : 0.18750 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 472 =====\n",
      " loss : 0.55926 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55926 test_loss : 0.59879 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 473 =====\n",
      " loss : 0.58436 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.58436 test_loss : 0.59549 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 474 =====\n",
      " loss : 0.72096 metric0 : 0.15625\n",
      "\n",
      " train_loss : 0.72096 test_loss : 0.59907 train_metric : 0.15625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 475 =====\n",
      " loss : 0.58090 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58090 test_loss : 0.59469 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 476 =====\n",
      " loss : 0.59202 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.59202 test_loss : 0.59819 train_metric : 0.34375 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 477 =====\n",
      " loss : 0.53433 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.53433 test_loss : 0.59817 train_metric : 0.40625 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 478 =====\n",
      " loss : 0.59005 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.59005 test_loss : 0.59749 train_metric : 0.31250 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 479 =====\n",
      " loss : 0.56972 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.56972 test_loss : 0.59427 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 480 =====\n",
      " loss : 0.50407 metric0 : 0.43750\n",
      "\n",
      " train_loss : 0.50407 test_loss : 0.59423 train_metric : 0.43750 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 481 =====\n",
      " loss : 0.67741 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.67741 test_loss : 0.59920 train_metric : 0.21875 test_metric : 0.32895\n",
      "\n",
      "=====Epoch : 482 =====\n",
      " loss : 0.60696 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60696 test_loss : 0.59633 train_metric : 0.31250 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 483 =====\n",
      " loss : 0.56416 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.56416 test_loss : 0.58965 train_metric : 0.37500 test_metric : 0.33717\n",
      "\n",
      "=====Epoch : 484 =====\n",
      " loss : 0.61919 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.61919 test_loss : 0.59101 train_metric : 0.31250 test_metric : 0.32566\n",
      "\n",
      "=====Epoch : 485 =====\n",
      " loss : 0.62565 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.62565 test_loss : 0.59042 train_metric : 0.28125 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 486 =====\n",
      " loss : 0.50483 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.50483 test_loss : 0.59445 train_metric : 0.40625 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 487 =====\n",
      " loss : 0.58869 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58869 test_loss : 0.59461 train_metric : 0.34375 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 488 =====\n",
      " loss : 0.55245 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.55245 test_loss : 0.59888 train_metric : 0.37500 test_metric : 0.32730\n",
      "\n",
      "=====Epoch : 489 =====\n",
      " loss : 0.64132 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.64132 test_loss : 0.59888 train_metric : 0.31250 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 490 =====\n",
      " loss : 0.49355 metric0 : 0.46875\n",
      "\n",
      " train_loss : 0.49355 test_loss : 0.59418 train_metric : 0.46875 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 491 =====\n",
      " loss : 0.64573 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.64573 test_loss : 0.59693 train_metric : 0.28125 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 492 =====\n",
      " loss : 0.63377 metric0 : 0.28125\n",
      "\n",
      " train_loss : 0.63377 test_loss : 0.59556 train_metric : 0.28125 test_metric : 0.33717\n",
      "\n",
      "=====Epoch : 493 =====\n",
      " loss : 0.66635 metric0 : 0.25000\n",
      "\n",
      " train_loss : 0.66635 test_loss : 0.59410 train_metric : 0.25000 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 494 =====\n",
      " loss : 0.58744 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58744 test_loss : 0.59137 train_metric : 0.34375 test_metric : 0.33553\n",
      "\n",
      "=====Epoch : 495 =====\n",
      " loss : 0.58705 metric0 : 0.34375\n",
      "\n",
      " train_loss : 0.58705 test_loss : 0.59549 train_metric : 0.34375 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 496 =====\n",
      " loss : 0.48952 metric0 : 0.40625\n",
      "\n",
      " train_loss : 0.48952 test_loss : 0.59167 train_metric : 0.40625 test_metric : 0.33224\n",
      "\n",
      "=====Epoch : 497 =====\n",
      " loss : 0.67001 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.67001 test_loss : 0.59851 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 498 =====\n",
      " loss : 0.66268 metric0 : 0.21875\n",
      "\n",
      " train_loss : 0.66268 test_loss : 0.59544 train_metric : 0.21875 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 499 =====\n",
      " loss : 0.54590 metric0 : 0.37500\n",
      "\n",
      " train_loss : 0.54590 test_loss : 0.60054 train_metric : 0.37500 test_metric : 0.33059\n",
      "\n",
      "=====Epoch : 500 =====\n",
      " loss : 0.60069 metric0 : 0.31250\n",
      "\n",
      " train_loss : 0.60069 test_loss : 0.59570 train_metric : 0.31250 test_metric : 0.32895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kanqe = NQE(n_feature=4, mode='KAN')\n",
    "kanqe_train = NQE_Train(kanqe, criterion, train_loader, test_loader, [accuarcy])\n",
    "trained_kanqe = kanqe_train.train(500, seq_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(trained_kanqe.state_dict(), \"./models/pca_KAN_NQE_loss{loss}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch : 1 =====\n",
      " loss : 0.17818 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17818 test_loss : 0.20344 train_metric : 0.81481 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 2 =====\n",
      " loss : 0.08048 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08048 test_loss : 0.17104 train_metric : 0.88889 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 3 =====\n",
      " loss : 0.14420 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14420 test_loss : 0.15398 train_metric : 0.85185 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 4 =====\n",
      " loss : 0.11538 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11538 test_loss : 0.16264 train_metric : 0.85185 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 5 =====\n",
      " loss : 0.12779 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12779 test_loss : 0.17849 train_metric : 0.81481 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 6 =====\n",
      " loss : 0.15799 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15799 test_loss : 0.16072 train_metric : 0.77778 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 7 =====\n",
      " loss : 0.21228 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.21228 test_loss : 0.17420 train_metric : 0.74074 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 8 =====\n",
      " loss : 0.12996 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.12996 test_loss : 0.15803 train_metric : 0.77778 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 9 =====\n",
      " loss : 0.15438 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15438 test_loss : 0.14848 train_metric : 0.81481 test_metric : 0.81250\n",
      "\n",
      "=====Epoch : 10 =====\n",
      " loss : 0.04012 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04012 test_loss : 0.16144 train_metric : 0.96296 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 11 =====\n",
      " loss : 0.11797 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11797 test_loss : 0.16447 train_metric : 0.85185 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 12 =====\n",
      " loss : 0.16910 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16910 test_loss : 0.16438 train_metric : 0.81481 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 13 =====\n",
      " loss : 0.11647 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.11647 test_loss : 0.17421 train_metric : 0.77778 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 14 =====\n",
      " loss : 0.06301 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06301 test_loss : 0.15076 train_metric : 0.92593 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 15 =====\n",
      " loss : 0.08314 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08314 test_loss : 0.15738 train_metric : 0.88889 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 16 =====\n",
      " loss : 0.10687 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10687 test_loss : 0.16403 train_metric : 0.85185 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 17 =====\n",
      " loss : 0.12487 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12487 test_loss : 0.16985 train_metric : 0.85185 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 18 =====\n",
      " loss : 0.13343 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13343 test_loss : 0.15910 train_metric : 0.81481 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 19 =====\n",
      " loss : 0.12771 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12771 test_loss : 0.15856 train_metric : 0.85185 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 20 =====\n",
      " loss : 0.04964 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04964 test_loss : 0.15771 train_metric : 0.92593 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 21 =====\n",
      " loss : 0.12970 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12970 test_loss : 0.14883 train_metric : 0.85185 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 22 =====\n",
      " loss : 0.06931 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06931 test_loss : 0.16326 train_metric : 0.92593 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 23 =====\n",
      " loss : 0.07070 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07070 test_loss : 0.16361 train_metric : 0.92593 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 24 =====\n",
      " loss : 0.11035 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11035 test_loss : 0.16980 train_metric : 0.81481 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 25 =====\n",
      " loss : 0.20951 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.20951 test_loss : 0.16155 train_metric : 0.70370 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 26 =====\n",
      " loss : 0.08738 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08738 test_loss : 0.16581 train_metric : 0.88889 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 27 =====\n",
      " loss : 0.10951 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10951 test_loss : 0.16609 train_metric : 0.85185 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 28 =====\n",
      " loss : 0.06730 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06730 test_loss : 0.16716 train_metric : 0.88889 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 29 =====\n",
      " loss : 0.07621 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07621 test_loss : 0.17583 train_metric : 0.92593 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 30 =====\n",
      " loss : 0.08122 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08122 test_loss : 0.16579 train_metric : 0.88889 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 31 =====\n",
      " loss : 0.02564 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02564 test_loss : 0.18432 train_metric : 0.96296 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 32 =====\n",
      " loss : 0.04029 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04029 test_loss : 0.17617 train_metric : 0.96296 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 33 =====\n",
      " loss : 0.09644 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09644 test_loss : 0.16997 train_metric : 0.88889 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 34 =====\n",
      " loss : 0.04778 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04778 test_loss : 0.17684 train_metric : 0.96296 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 35 =====\n",
      " loss : 0.11488 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11488 test_loss : 0.16966 train_metric : 0.85185 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 36 =====\n",
      " loss : 0.05515 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05515 test_loss : 0.17382 train_metric : 0.96296 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 37 =====\n",
      " loss : 0.01880 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01880 test_loss : 0.17311 train_metric : 1.00000 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 38 =====\n",
      " loss : 0.14498 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14498 test_loss : 0.16422 train_metric : 0.77778 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 39 =====\n",
      " loss : 0.06524 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06524 test_loss : 0.17493 train_metric : 0.92593 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 40 =====\n",
      " loss : 0.06028 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06028 test_loss : 0.15969 train_metric : 0.92593 test_metric : 0.79605\n",
      "\n",
      "=====Epoch : 41 =====\n",
      " loss : 0.07033 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07033 test_loss : 0.18091 train_metric : 0.92593 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 42 =====\n",
      " loss : 0.03601 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03601 test_loss : 0.18510 train_metric : 0.92593 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 43 =====\n",
      " loss : 0.09096 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09096 test_loss : 0.16968 train_metric : 0.88889 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 44 =====\n",
      " loss : 0.02917 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02917 test_loss : 0.16861 train_metric : 1.00000 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 45 =====\n",
      " loss : 0.05687 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05687 test_loss : 0.17044 train_metric : 0.96296 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 46 =====\n",
      " loss : 0.08065 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08065 test_loss : 0.17259 train_metric : 0.92593 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 47 =====\n",
      " loss : 0.04133 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04133 test_loss : 0.18302 train_metric : 0.96296 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 48 =====\n",
      " loss : 0.01230 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01230 test_loss : 0.19514 train_metric : 1.00000 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 49 =====\n",
      " loss : 0.08246 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08246 test_loss : 0.17984 train_metric : 0.92593 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 50 =====\n",
      " loss : 0.07562 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07562 test_loss : 0.18301 train_metric : 0.92593 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 51 =====\n",
      " loss : 0.03984 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03984 test_loss : 0.17759 train_metric : 0.92593 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 52 =====\n",
      " loss : 0.02453 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02453 test_loss : 0.18366 train_metric : 0.96296 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 53 =====\n",
      " loss : 0.03524 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03524 test_loss : 0.18344 train_metric : 1.00000 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 54 =====\n",
      " loss : 0.07558 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07558 test_loss : 0.18441 train_metric : 0.85185 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 55 =====\n",
      " loss : 0.04215 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04215 test_loss : 0.19362 train_metric : 0.92593 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 56 =====\n",
      " loss : 0.01280 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01280 test_loss : 0.17776 train_metric : 1.00000 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 57 =====\n",
      " loss : 0.13514 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13514 test_loss : 0.18212 train_metric : 0.85185 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 58 =====\n",
      " loss : 0.03601 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03601 test_loss : 0.18254 train_metric : 1.00000 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 59 =====\n",
      " loss : 0.11448 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11448 test_loss : 0.18981 train_metric : 0.85185 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 60 =====\n",
      " loss : 0.08598 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08598 test_loss : 0.18001 train_metric : 0.88889 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 61 =====\n",
      " loss : 0.01815 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01815 test_loss : 0.18051 train_metric : 1.00000 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 62 =====\n",
      " loss : 0.11310 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11310 test_loss : 0.18978 train_metric : 0.81481 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 63 =====\n",
      " loss : 0.12503 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12503 test_loss : 0.19292 train_metric : 0.81481 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 64 =====\n",
      " loss : 0.02299 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02299 test_loss : 0.18679 train_metric : 0.96296 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 65 =====\n",
      " loss : 0.08739 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08739 test_loss : 0.18501 train_metric : 0.92593 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 66 =====\n",
      " loss : 0.12084 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12084 test_loss : 0.18157 train_metric : 0.85185 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 67 =====\n",
      " loss : 0.11110 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11110 test_loss : 0.17151 train_metric : 0.88889 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 68 =====\n",
      " loss : 0.02525 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02525 test_loss : 0.18827 train_metric : 0.96296 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 69 =====\n",
      " loss : 0.03162 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03162 test_loss : 0.18224 train_metric : 1.00000 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 70 =====\n",
      " loss : 0.03416 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03416 test_loss : 0.18782 train_metric : 0.92593 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 71 =====\n",
      " loss : 0.02512 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02512 test_loss : 0.18635 train_metric : 0.96296 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 72 =====\n",
      " loss : 0.05627 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05627 test_loss : 0.19008 train_metric : 0.88889 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 73 =====\n",
      " loss : 0.09570 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09570 test_loss : 0.18202 train_metric : 0.88889 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 74 =====\n",
      " loss : 0.07353 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07353 test_loss : 0.19266 train_metric : 0.92593 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 75 =====\n",
      " loss : 0.05329 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05329 test_loss : 0.18819 train_metric : 0.92593 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 76 =====\n",
      " loss : 0.15907 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15907 test_loss : 0.19262 train_metric : 0.81481 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 77 =====\n",
      " loss : 0.04199 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04199 test_loss : 0.18469 train_metric : 0.96296 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 78 =====\n",
      " loss : 0.09851 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09851 test_loss : 0.17920 train_metric : 0.85185 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 79 =====\n",
      " loss : 0.05560 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05560 test_loss : 0.19486 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 80 =====\n",
      " loss : 0.04303 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04303 test_loss : 0.19551 train_metric : 0.96296 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 81 =====\n",
      " loss : 0.07635 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07635 test_loss : 0.18674 train_metric : 0.92593 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 82 =====\n",
      " loss : 0.03970 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03970 test_loss : 0.18369 train_metric : 0.96296 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 83 =====\n",
      " loss : 0.05399 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05399 test_loss : 0.20152 train_metric : 0.92593 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 84 =====\n",
      " loss : 0.01627 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01627 test_loss : 0.18938 train_metric : 0.96296 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 85 =====\n",
      " loss : 0.08166 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08166 test_loss : 0.20119 train_metric : 0.88889 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 86 =====\n",
      " loss : 0.02427 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02427 test_loss : 0.19106 train_metric : 1.00000 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 87 =====\n",
      " loss : 0.02830 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02830 test_loss : 0.18402 train_metric : 0.96296 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 88 =====\n",
      " loss : 0.04851 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04851 test_loss : 0.18720 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 89 =====\n",
      " loss : 0.06208 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06208 test_loss : 0.17891 train_metric : 0.92593 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 90 =====\n",
      " loss : 0.04384 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04384 test_loss : 0.18292 train_metric : 0.96296 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 91 =====\n",
      " loss : 0.08084 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08084 test_loss : 0.18585 train_metric : 0.88889 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 92 =====\n",
      " loss : 0.02508 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02508 test_loss : 0.18838 train_metric : 1.00000 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 93 =====\n",
      " loss : 0.02784 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02784 test_loss : 0.19507 train_metric : 0.96296 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 94 =====\n",
      " loss : 0.03751 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03751 test_loss : 0.19336 train_metric : 0.96296 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 95 =====\n",
      " loss : 0.03974 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.03974 test_loss : 0.19565 train_metric : 0.92593 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 96 =====\n",
      " loss : 0.06467 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06467 test_loss : 0.18423 train_metric : 0.92593 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 97 =====\n",
      " loss : 0.02580 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02580 test_loss : 0.20256 train_metric : 1.00000 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 98 =====\n",
      " loss : 0.00832 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00832 test_loss : 0.19994 train_metric : 1.00000 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 99 =====\n",
      " loss : 0.03830 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03830 test_loss : 0.19179 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 100 =====\n",
      " loss : 0.07097 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07097 test_loss : 0.18882 train_metric : 0.88889 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 101 =====\n",
      " loss : 0.07116 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07116 test_loss : 0.19008 train_metric : 0.88889 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 102 =====\n",
      " loss : 0.04043 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04043 test_loss : 0.19007 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 103 =====\n",
      " loss : 0.07196 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07196 test_loss : 0.19026 train_metric : 0.92593 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 104 =====\n",
      " loss : 0.02414 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02414 test_loss : 0.20658 train_metric : 0.96296 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 105 =====\n",
      " loss : 0.02761 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02761 test_loss : 0.19427 train_metric : 0.96296 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 106 =====\n",
      " loss : 0.03372 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03372 test_loss : 0.19109 train_metric : 0.96296 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 107 =====\n",
      " loss : 0.07069 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07069 test_loss : 0.21459 train_metric : 0.92593 test_metric : 0.71875\n",
      "\n",
      "=====Epoch : 108 =====\n",
      " loss : 0.04651 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04651 test_loss : 0.19830 train_metric : 0.96296 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 109 =====\n",
      " loss : 0.09004 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09004 test_loss : 0.19920 train_metric : 0.92593 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 110 =====\n",
      " loss : 0.01261 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01261 test_loss : 0.20847 train_metric : 1.00000 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 111 =====\n",
      " loss : 0.04696 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04696 test_loss : 0.21694 train_metric : 0.96296 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 112 =====\n",
      " loss : 0.09030 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09030 test_loss : 0.19941 train_metric : 0.88889 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 113 =====\n",
      " loss : 0.08173 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08173 test_loss : 0.19758 train_metric : 0.92593 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 114 =====\n",
      " loss : 0.02025 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02025 test_loss : 0.20233 train_metric : 1.00000 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 115 =====\n",
      " loss : 0.08855 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08855 test_loss : 0.21119 train_metric : 0.88889 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 116 =====\n",
      " loss : 0.05943 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05943 test_loss : 0.19354 train_metric : 0.92593 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 117 =====\n",
      " loss : 0.00773 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.00773 test_loss : 0.19131 train_metric : 1.00000 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 118 =====\n",
      " loss : 0.01907 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.01907 test_loss : 0.19863 train_metric : 0.96296 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 119 =====\n",
      " loss : 0.08995 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08995 test_loss : 0.19847 train_metric : 0.88889 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 120 =====\n",
      " loss : 0.07028 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07028 test_loss : 0.19787 train_metric : 0.92593 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 121 =====\n",
      " loss : 0.06230 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06230 test_loss : 0.19493 train_metric : 0.92593 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 122 =====\n",
      " loss : 0.14329 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14329 test_loss : 0.20579 train_metric : 0.81481 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 123 =====\n",
      " loss : 0.20999 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20999 test_loss : 0.24402 train_metric : 0.74074 test_metric : 0.69408\n",
      "\n",
      "=====Epoch : 124 =====\n",
      " loss : 0.23717 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.23717 test_loss : 0.26816 train_metric : 0.70370 test_metric : 0.67434\n",
      "\n",
      "=====Epoch : 125 =====\n",
      " loss : 0.16682 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16682 test_loss : 0.23895 train_metric : 0.74074 test_metric : 0.69243\n",
      "\n",
      "=====Epoch : 126 =====\n",
      " loss : 0.12368 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12368 test_loss : 0.22381 train_metric : 0.85185 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 127 =====\n",
      " loss : 0.04161 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04161 test_loss : 0.19794 train_metric : 0.96296 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 128 =====\n",
      " loss : 0.15017 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15017 test_loss : 0.19961 train_metric : 0.85185 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 129 =====\n",
      " loss : 0.19565 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.19565 test_loss : 0.19194 train_metric : 0.74074 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 130 =====\n",
      " loss : 0.13628 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13628 test_loss : 0.19856 train_metric : 0.81481 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 131 =====\n",
      " loss : 0.10416 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10416 test_loss : 0.19035 train_metric : 0.85185 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 132 =====\n",
      " loss : 0.15491 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15491 test_loss : 0.18995 train_metric : 0.81481 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 133 =====\n",
      " loss : 0.04496 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04496 test_loss : 0.19116 train_metric : 0.96296 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 134 =====\n",
      " loss : 0.13143 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13143 test_loss : 0.18339 train_metric : 0.85185 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 135 =====\n",
      " loss : 0.22564 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.22564 test_loss : 0.16557 train_metric : 0.74074 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 136 =====\n",
      " loss : 0.15251 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15251 test_loss : 0.18568 train_metric : 0.85185 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 137 =====\n",
      " loss : 0.24538 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.24538 test_loss : 0.18670 train_metric : 0.70370 test_metric : 0.79770\n",
      "\n",
      "=====Epoch : 138 =====\n",
      " loss : 0.11980 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11980 test_loss : 0.17548 train_metric : 0.85185 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 139 =====\n",
      " loss : 0.15575 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15575 test_loss : 0.15699 train_metric : 0.81481 test_metric : 0.80921\n",
      "\n",
      "=====Epoch : 140 =====\n",
      " loss : 0.07869 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07869 test_loss : 0.15380 train_metric : 0.92593 test_metric : 0.80428\n",
      "\n",
      "=====Epoch : 141 =====\n",
      " loss : 0.19011 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.19011 test_loss : 0.17487 train_metric : 0.70370 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 142 =====\n",
      " loss : 0.30915 metric0 : 0.55556\n",
      "\n",
      " train_loss : 0.30915 test_loss : 0.16479 train_metric : 0.55556 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 143 =====\n",
      " loss : 0.20997 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20997 test_loss : 0.17713 train_metric : 0.74074 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 144 =====\n",
      " loss : 0.05422 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05422 test_loss : 0.16699 train_metric : 0.88889 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 145 =====\n",
      " loss : 0.10287 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10287 test_loss : 0.16132 train_metric : 0.85185 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 146 =====\n",
      " loss : 0.18391 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18391 test_loss : 0.15564 train_metric : 0.77778 test_metric : 0.80921\n",
      "\n",
      "=====Epoch : 147 =====\n",
      " loss : 0.10957 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10957 test_loss : 0.17187 train_metric : 0.85185 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 148 =====\n",
      " loss : 0.11512 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11512 test_loss : 0.15417 train_metric : 0.88889 test_metric : 0.81743\n",
      "\n",
      "=====Epoch : 149 =====\n",
      " loss : 0.12414 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12414 test_loss : 0.15613 train_metric : 0.81481 test_metric : 0.80428\n",
      "\n",
      "=====Epoch : 150 =====\n",
      " loss : 0.14092 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14092 test_loss : 0.16897 train_metric : 0.85185 test_metric : 0.78125\n",
      "\n",
      "=====Epoch : 151 =====\n",
      " loss : 0.20548 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20548 test_loss : 0.16834 train_metric : 0.77778 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 152 =====\n",
      " loss : 0.12933 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12933 test_loss : 0.19906 train_metric : 0.81481 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 153 =====\n",
      " loss : 0.19204 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19204 test_loss : 0.17984 train_metric : 0.77778 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 154 =====\n",
      " loss : 0.14459 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14459 test_loss : 0.17185 train_metric : 0.85185 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 155 =====\n",
      " loss : 0.20265 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20265 test_loss : 0.17862 train_metric : 0.74074 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 156 =====\n",
      " loss : 0.24265 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.24265 test_loss : 0.15954 train_metric : 0.66667 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 157 =====\n",
      " loss : 0.13756 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13756 test_loss : 0.15464 train_metric : 0.81481 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 158 =====\n",
      " loss : 0.20988 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20988 test_loss : 0.15789 train_metric : 0.74074 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 159 =====\n",
      " loss : 0.10471 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10471 test_loss : 0.14426 train_metric : 0.85185 test_metric : 0.83224\n",
      "\n",
      "=====Epoch : 160 =====\n",
      " loss : 0.11482 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11482 test_loss : 0.14110 train_metric : 0.85185 test_metric : 0.82730\n",
      "\n",
      "=====Epoch : 161 =====\n",
      " loss : 0.07979 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07979 test_loss : 0.15311 train_metric : 0.88889 test_metric : 0.81414\n",
      "\n",
      "=====Epoch : 162 =====\n",
      " loss : 0.12057 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12057 test_loss : 0.15948 train_metric : 0.88889 test_metric : 0.79276\n",
      "\n",
      "=====Epoch : 163 =====\n",
      " loss : 0.19094 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.19094 test_loss : 0.17621 train_metric : 0.74074 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 164 =====\n",
      " loss : 0.17645 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.17645 test_loss : 0.16094 train_metric : 0.74074 test_metric : 0.80757\n",
      "\n",
      "=====Epoch : 165 =====\n",
      " loss : 0.18220 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18220 test_loss : 0.16388 train_metric : 0.74074 test_metric : 0.80921\n",
      "\n",
      "=====Epoch : 166 =====\n",
      " loss : 0.21887 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.21887 test_loss : 0.14731 train_metric : 0.70370 test_metric : 0.81908\n",
      "\n",
      "=====Epoch : 167 =====\n",
      " loss : 0.14225 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14225 test_loss : 0.15867 train_metric : 0.77778 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 168 =====\n",
      " loss : 0.13085 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13085 test_loss : 0.14307 train_metric : 0.85185 test_metric : 0.82237\n",
      "\n",
      "=====Epoch : 169 =====\n",
      " loss : 0.17816 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.17816 test_loss : 0.15511 train_metric : 0.74074 test_metric : 0.79441\n",
      "\n",
      "=====Epoch : 170 =====\n",
      " loss : 0.06220 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06220 test_loss : 0.14294 train_metric : 0.92593 test_metric : 0.80757\n",
      "\n",
      "=====Epoch : 171 =====\n",
      " loss : 0.13495 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13495 test_loss : 0.17735 train_metric : 0.85185 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 172 =====\n",
      " loss : 0.20363 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.20363 test_loss : 0.16073 train_metric : 0.70370 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 173 =====\n",
      " loss : 0.28268 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.28268 test_loss : 0.16913 train_metric : 0.66667 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 174 =====\n",
      " loss : 0.22394 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.22394 test_loss : 0.16106 train_metric : 0.70370 test_metric : 0.80263\n",
      "\n",
      "=====Epoch : 175 =====\n",
      " loss : 0.14448 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14448 test_loss : 0.16720 train_metric : 0.77778 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 176 =====\n",
      " loss : 0.11002 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11002 test_loss : 0.18656 train_metric : 0.85185 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 177 =====\n",
      " loss : 0.10442 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10442 test_loss : 0.18419 train_metric : 0.88889 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 178 =====\n",
      " loss : 0.25852 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.25852 test_loss : 0.18390 train_metric : 0.74074 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 179 =====\n",
      " loss : 0.19615 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19615 test_loss : 0.18382 train_metric : 0.77778 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 180 =====\n",
      " loss : 0.22854 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.22854 test_loss : 0.20576 train_metric : 0.74074 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 181 =====\n",
      " loss : 0.23302 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.23302 test_loss : 0.20032 train_metric : 0.70370 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 182 =====\n",
      " loss : 0.15765 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15765 test_loss : 0.19686 train_metric : 0.77778 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 183 =====\n",
      " loss : 0.21195 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.21195 test_loss : 0.20382 train_metric : 0.74074 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 184 =====\n",
      " loss : 0.17742 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17742 test_loss : 0.20343 train_metric : 0.77778 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 185 =====\n",
      " loss : 0.14613 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14613 test_loss : 0.18621 train_metric : 0.81481 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 186 =====\n",
      " loss : 0.24317 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.24317 test_loss : 0.18296 train_metric : 0.70370 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 187 =====\n",
      " loss : 0.09616 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09616 test_loss : 0.17996 train_metric : 0.88889 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 188 =====\n",
      " loss : 0.17534 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17534 test_loss : 0.18783 train_metric : 0.77778 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 189 =====\n",
      " loss : 0.24073 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.24073 test_loss : 0.19816 train_metric : 0.70370 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 190 =====\n",
      " loss : 0.18593 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18593 test_loss : 0.20162 train_metric : 0.74074 test_metric : 0.71875\n",
      "\n",
      "=====Epoch : 191 =====\n",
      " loss : 0.16122 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16122 test_loss : 0.18819 train_metric : 0.74074 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 192 =====\n",
      " loss : 0.08019 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.08019 test_loss : 0.19125 train_metric : 0.85185 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 193 =====\n",
      " loss : 0.17708 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17708 test_loss : 0.17945 train_metric : 0.77778 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 194 =====\n",
      " loss : 0.18801 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18801 test_loss : 0.17992 train_metric : 0.74074 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 195 =====\n",
      " loss : 0.09391 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09391 test_loss : 0.18217 train_metric : 0.92593 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 196 =====\n",
      " loss : 0.13416 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13416 test_loss : 0.17499 train_metric : 0.85185 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 197 =====\n",
      " loss : 0.26725 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.26725 test_loss : 0.18536 train_metric : 0.66667 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 198 =====\n",
      " loss : 0.15099 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15099 test_loss : 0.16970 train_metric : 0.81481 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 199 =====\n",
      " loss : 0.08452 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08452 test_loss : 0.17874 train_metric : 0.88889 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 200 =====\n",
      " loss : 0.13141 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13141 test_loss : 0.17449 train_metric : 0.81481 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 201 =====\n",
      " loss : 0.13162 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13162 test_loss : 0.16824 train_metric : 0.85185 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 202 =====\n",
      " loss : 0.19694 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19694 test_loss : 0.16125 train_metric : 0.77778 test_metric : 0.80099\n",
      "\n",
      "=====Epoch : 203 =====\n",
      " loss : 0.09485 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.09485 test_loss : 0.16187 train_metric : 0.81481 test_metric : 0.78783\n",
      "\n",
      "=====Epoch : 204 =====\n",
      " loss : 0.09845 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09845 test_loss : 0.16985 train_metric : 0.88889 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 205 =====\n",
      " loss : 0.15771 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15771 test_loss : 0.17977 train_metric : 0.81481 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 206 =====\n",
      " loss : 0.23568 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.23568 test_loss : 0.16324 train_metric : 0.66667 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 207 =====\n",
      " loss : 0.25010 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.25010 test_loss : 0.17533 train_metric : 0.74074 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 208 =====\n",
      " loss : 0.20985 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20985 test_loss : 0.17225 train_metric : 0.74074 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 209 =====\n",
      " loss : 0.20000 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20000 test_loss : 0.16884 train_metric : 0.77778 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 210 =====\n",
      " loss : 0.14564 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.14564 test_loss : 0.16414 train_metric : 0.74074 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 211 =====\n",
      " loss : 0.11088 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11088 test_loss : 0.17319 train_metric : 0.88889 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 212 =====\n",
      " loss : 0.17939 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17939 test_loss : 0.16434 train_metric : 0.81481 test_metric : 0.78947\n",
      "\n",
      "=====Epoch : 213 =====\n",
      " loss : 0.21533 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.21533 test_loss : 0.16639 train_metric : 0.70370 test_metric : 0.78618\n",
      "\n",
      "=====Epoch : 214 =====\n",
      " loss : 0.12559 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12559 test_loss : 0.17109 train_metric : 0.85185 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 215 =====\n",
      " loss : 0.11432 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11432 test_loss : 0.17448 train_metric : 0.85185 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 216 =====\n",
      " loss : 0.16689 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16689 test_loss : 0.19168 train_metric : 0.77778 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 217 =====\n",
      " loss : 0.11135 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11135 test_loss : 0.19480 train_metric : 0.85185 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 218 =====\n",
      " loss : 0.17687 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17687 test_loss : 0.17875 train_metric : 0.77778 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 219 =====\n",
      " loss : 0.19749 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.19749 test_loss : 0.17686 train_metric : 0.70370 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 220 =====\n",
      " loss : 0.18145 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18145 test_loss : 0.18331 train_metric : 0.74074 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 221 =====\n",
      " loss : 0.10515 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10515 test_loss : 0.18185 train_metric : 0.88889 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 222 =====\n",
      " loss : 0.13488 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13488 test_loss : 0.20020 train_metric : 0.81481 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 223 =====\n",
      " loss : 0.04641 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04641 test_loss : 0.19514 train_metric : 0.96296 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 224 =====\n",
      " loss : 0.14519 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14519 test_loss : 0.18902 train_metric : 0.85185 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 225 =====\n",
      " loss : 0.07600 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07600 test_loss : 0.18256 train_metric : 0.92593 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 226 =====\n",
      " loss : 0.05711 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05711 test_loss : 0.19535 train_metric : 0.92593 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 227 =====\n",
      " loss : 0.18298 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18298 test_loss : 0.18967 train_metric : 0.74074 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 228 =====\n",
      " loss : 0.19400 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19400 test_loss : 0.18314 train_metric : 0.77778 test_metric : 0.77961\n",
      "\n",
      "=====Epoch : 229 =====\n",
      " loss : 0.11146 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11146 test_loss : 0.16350 train_metric : 0.85185 test_metric : 0.78289\n",
      "\n",
      "=====Epoch : 230 =====\n",
      " loss : 0.11840 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11840 test_loss : 0.17068 train_metric : 0.85185 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 231 =====\n",
      " loss : 0.13317 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13317 test_loss : 0.17737 train_metric : 0.81481 test_metric : 0.77796\n",
      "\n",
      "=====Epoch : 232 =====\n",
      " loss : 0.19617 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.19617 test_loss : 0.16582 train_metric : 0.74074 test_metric : 0.79934\n",
      "\n",
      "=====Epoch : 233 =====\n",
      " loss : 0.03823 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03823 test_loss : 0.15888 train_metric : 0.96296 test_metric : 0.81908\n",
      "\n",
      "=====Epoch : 234 =====\n",
      " loss : 0.14534 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14534 test_loss : 0.15709 train_metric : 0.85185 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 235 =====\n",
      " loss : 0.16304 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16304 test_loss : 0.17380 train_metric : 0.81481 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 236 =====\n",
      " loss : 0.19304 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.19304 test_loss : 0.17371 train_metric : 0.74074 test_metric : 0.79112\n",
      "\n",
      "=====Epoch : 237 =====\n",
      " loss : 0.13587 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13587 test_loss : 0.17823 train_metric : 0.85185 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 238 =====\n",
      " loss : 0.15498 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15498 test_loss : 0.17501 train_metric : 0.81481 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 239 =====\n",
      " loss : 0.09589 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09589 test_loss : 0.18041 train_metric : 0.85185 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 240 =====\n",
      " loss : 0.13461 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13461 test_loss : 0.17672 train_metric : 0.81481 test_metric : 0.77303\n",
      "\n",
      "=====Epoch : 241 =====\n",
      " loss : 0.18605 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18605 test_loss : 0.16941 train_metric : 0.74074 test_metric : 0.78454\n",
      "\n",
      "=====Epoch : 242 =====\n",
      " loss : 0.15854 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.15854 test_loss : 0.17736 train_metric : 0.74074 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 243 =====\n",
      " loss : 0.18997 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18997 test_loss : 0.18225 train_metric : 0.77778 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 244 =====\n",
      " loss : 0.19446 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.19446 test_loss : 0.18220 train_metric : 0.70370 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 245 =====\n",
      " loss : 0.24830 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.24830 test_loss : 0.18281 train_metric : 0.70370 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 246 =====\n",
      " loss : 0.17959 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17959 test_loss : 0.18746 train_metric : 0.77778 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 247 =====\n",
      " loss : 0.11123 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.11123 test_loss : 0.18513 train_metric : 0.77778 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 248 =====\n",
      " loss : 0.22925 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.22925 test_loss : 0.18602 train_metric : 0.66667 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 249 =====\n",
      " loss : 0.10537 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10537 test_loss : 0.19803 train_metric : 0.85185 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 250 =====\n",
      " loss : 0.12211 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12211 test_loss : 0.20513 train_metric : 0.81481 test_metric : 0.71217\n",
      "\n",
      "=====Epoch : 251 =====\n",
      " loss : 0.11776 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11776 test_loss : 0.19695 train_metric : 0.85185 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 252 =====\n",
      " loss : 0.05042 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05042 test_loss : 0.19004 train_metric : 0.92593 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 253 =====\n",
      " loss : 0.20134 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20134 test_loss : 0.18567 train_metric : 0.77778 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 254 =====\n",
      " loss : 0.16509 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.16509 test_loss : 0.21856 train_metric : 0.70370 test_metric : 0.68421\n",
      "\n",
      "=====Epoch : 255 =====\n",
      " loss : 0.27068 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.27068 test_loss : 0.20392 train_metric : 0.70370 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 256 =====\n",
      " loss : 0.20489 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20489 test_loss : 0.20299 train_metric : 0.74074 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 257 =====\n",
      " loss : 0.28282 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.28282 test_loss : 0.22686 train_metric : 0.66667 test_metric : 0.69737\n",
      "\n",
      "=====Epoch : 258 =====\n",
      " loss : 0.29065 metric0 : 0.55556\n",
      "\n",
      " train_loss : 0.29065 test_loss : 0.21947 train_metric : 0.55556 test_metric : 0.71053\n",
      "\n",
      "=====Epoch : 259 =====\n",
      " loss : 0.20589 metric0 : 0.62963\n",
      "\n",
      " train_loss : 0.20589 test_loss : 0.21623 train_metric : 0.62963 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 260 =====\n",
      " loss : 0.19381 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.19381 test_loss : 0.22483 train_metric : 0.74074 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 261 =====\n",
      " loss : 0.20622 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20622 test_loss : 0.19275 train_metric : 0.74074 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 262 =====\n",
      " loss : 0.15186 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15186 test_loss : 0.21891 train_metric : 0.81481 test_metric : 0.70888\n",
      "\n",
      "=====Epoch : 263 =====\n",
      " loss : 0.24820 metric0 : 0.62963\n",
      "\n",
      " train_loss : 0.24820 test_loss : 0.22383 train_metric : 0.62963 test_metric : 0.70724\n",
      "\n",
      "=====Epoch : 264 =====\n",
      " loss : 0.17300 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17300 test_loss : 0.23862 train_metric : 0.77778 test_metric : 0.68092\n",
      "\n",
      "=====Epoch : 265 =====\n",
      " loss : 0.16930 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16930 test_loss : 0.22589 train_metric : 0.81481 test_metric : 0.70559\n",
      "\n",
      "=====Epoch : 266 =====\n",
      " loss : 0.13046 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13046 test_loss : 0.23208 train_metric : 0.85185 test_metric : 0.68750\n",
      "\n",
      "=====Epoch : 267 =====\n",
      " loss : 0.27568 metric0 : 0.59259\n",
      "\n",
      " train_loss : 0.27568 test_loss : 0.23267 train_metric : 0.59259 test_metric : 0.68750\n",
      "\n",
      "=====Epoch : 268 =====\n",
      " loss : 0.19557 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19557 test_loss : 0.22312 train_metric : 0.77778 test_metric : 0.71217\n",
      "\n",
      "=====Epoch : 269 =====\n",
      " loss : 0.22860 metric0 : 0.59259\n",
      "\n",
      " train_loss : 0.22860 test_loss : 0.23829 train_metric : 0.59259 test_metric : 0.67434\n",
      "\n",
      "=====Epoch : 270 =====\n",
      " loss : 0.16510 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16510 test_loss : 0.20854 train_metric : 0.77778 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 271 =====\n",
      " loss : 0.36145 metric0 : 0.51852\n",
      "\n",
      " train_loss : 0.36145 test_loss : 0.22914 train_metric : 0.51852 test_metric : 0.69079\n",
      "\n",
      "=====Epoch : 272 =====\n",
      " loss : 0.12286 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12286 test_loss : 0.22414 train_metric : 0.81481 test_metric : 0.70888\n",
      "\n",
      "=====Epoch : 273 =====\n",
      " loss : 0.09124 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09124 test_loss : 0.22035 train_metric : 0.85185 test_metric : 0.71382\n",
      "\n",
      "=====Epoch : 274 =====\n",
      " loss : 0.31695 metric0 : 0.62963\n",
      "\n",
      " train_loss : 0.31695 test_loss : 0.23700 train_metric : 0.62963 test_metric : 0.67434\n",
      "\n",
      "=====Epoch : 275 =====\n",
      " loss : 0.09825 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09825 test_loss : 0.23504 train_metric : 0.88889 test_metric : 0.69243\n",
      "\n",
      "=====Epoch : 276 =====\n",
      " loss : 0.10525 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10525 test_loss : 0.22920 train_metric : 0.85185 test_metric : 0.70395\n",
      "\n",
      "=====Epoch : 277 =====\n",
      " loss : 0.20724 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20724 test_loss : 0.22925 train_metric : 0.74074 test_metric : 0.71217\n",
      "\n",
      "=====Epoch : 278 =====\n",
      " loss : 0.22944 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.22944 test_loss : 0.22726 train_metric : 0.66667 test_metric : 0.70724\n",
      "\n",
      "=====Epoch : 279 =====\n",
      " loss : 0.16037 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16037 test_loss : 0.22904 train_metric : 0.77778 test_metric : 0.71382\n",
      "\n",
      "=====Epoch : 280 =====\n",
      " loss : 0.19066 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19066 test_loss : 0.21358 train_metric : 0.77778 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 281 =====\n",
      " loss : 0.14174 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14174 test_loss : 0.21843 train_metric : 0.85185 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 282 =====\n",
      " loss : 0.20758 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.20758 test_loss : 0.21398 train_metric : 0.70370 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 283 =====\n",
      " loss : 0.14920 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14920 test_loss : 0.20481 train_metric : 0.81481 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 284 =====\n",
      " loss : 0.24176 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.24176 test_loss : 0.21116 train_metric : 0.66667 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 285 =====\n",
      " loss : 0.16965 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.16965 test_loss : 0.20971 train_metric : 0.74074 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 286 =====\n",
      " loss : 0.19682 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.19682 test_loss : 0.21016 train_metric : 0.74074 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 287 =====\n",
      " loss : 0.21057 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.21057 test_loss : 0.22841 train_metric : 0.77778 test_metric : 0.71053\n",
      "\n",
      "=====Epoch : 288 =====\n",
      " loss : 0.10748 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10748 test_loss : 0.21150 train_metric : 0.85185 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 289 =====\n",
      " loss : 0.11608 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11608 test_loss : 0.20683 train_metric : 0.88889 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 290 =====\n",
      " loss : 0.19537 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.19537 test_loss : 0.20585 train_metric : 0.70370 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 291 =====\n",
      " loss : 0.10897 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10897 test_loss : 0.23034 train_metric : 0.85185 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 292 =====\n",
      " loss : 0.06198 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06198 test_loss : 0.21277 train_metric : 0.92593 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 293 =====\n",
      " loss : 0.11464 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11464 test_loss : 0.19984 train_metric : 0.85185 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 294 =====\n",
      " loss : 0.26111 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.26111 test_loss : 0.20143 train_metric : 0.70370 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 295 =====\n",
      " loss : 0.08300 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08300 test_loss : 0.20275 train_metric : 0.88889 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 296 =====\n",
      " loss : 0.15690 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15690 test_loss : 0.20844 train_metric : 0.81481 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 297 =====\n",
      " loss : 0.09051 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09051 test_loss : 0.21693 train_metric : 0.92593 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 298 =====\n",
      " loss : 0.13643 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13643 test_loss : 0.19921 train_metric : 0.81481 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 299 =====\n",
      " loss : 0.19765 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19765 test_loss : 0.19281 train_metric : 0.77778 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 300 =====\n",
      " loss : 0.28582 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.28582 test_loss : 0.19078 train_metric : 0.66667 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 301 =====\n",
      " loss : 0.12980 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12980 test_loss : 0.20018 train_metric : 0.81481 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 302 =====\n",
      " loss : 0.13787 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13787 test_loss : 0.20540 train_metric : 0.85185 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 303 =====\n",
      " loss : 0.25495 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.25495 test_loss : 0.22216 train_metric : 0.74074 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 304 =====\n",
      " loss : 0.24661 metric0 : 0.59259\n",
      "\n",
      " train_loss : 0.24661 test_loss : 0.21057 train_metric : 0.59259 test_metric : 0.71546\n",
      "\n",
      "=====Epoch : 305 =====\n",
      " loss : 0.15087 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15087 test_loss : 0.21777 train_metric : 0.81481 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 306 =====\n",
      " loss : 0.14426 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14426 test_loss : 0.21591 train_metric : 0.81481 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 307 =====\n",
      " loss : 0.20637 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.20637 test_loss : 0.21923 train_metric : 0.66667 test_metric : 0.71546\n",
      "\n",
      "=====Epoch : 308 =====\n",
      " loss : 0.23465 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.23465 test_loss : 0.22094 train_metric : 0.74074 test_metric : 0.72204\n",
      "\n",
      "=====Epoch : 309 =====\n",
      " loss : 0.14988 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14988 test_loss : 0.21208 train_metric : 0.81481 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 310 =====\n",
      " loss : 0.16457 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.16457 test_loss : 0.22293 train_metric : 0.85185 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 311 =====\n",
      " loss : 0.09848 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09848 test_loss : 0.21468 train_metric : 0.85185 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 312 =====\n",
      " loss : 0.11309 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11309 test_loss : 0.22119 train_metric : 0.85185 test_metric : 0.72039\n",
      "\n",
      "=====Epoch : 313 =====\n",
      " loss : 0.05703 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05703 test_loss : 0.20376 train_metric : 0.96296 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 314 =====\n",
      " loss : 0.04714 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04714 test_loss : 0.22643 train_metric : 0.96296 test_metric : 0.71711\n",
      "\n",
      "=====Epoch : 315 =====\n",
      " loss : 0.26508 metric0 : 0.59259\n",
      "\n",
      " train_loss : 0.26508 test_loss : 0.21259 train_metric : 0.59259 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 316 =====\n",
      " loss : 0.16257 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16257 test_loss : 0.21162 train_metric : 0.81481 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 317 =====\n",
      " loss : 0.18654 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.18654 test_loss : 0.21024 train_metric : 0.81481 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 318 =====\n",
      " loss : 0.21199 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.21199 test_loss : 0.21482 train_metric : 0.74074 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 319 =====\n",
      " loss : 0.16827 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16827 test_loss : 0.21479 train_metric : 0.81481 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 320 =====\n",
      " loss : 0.04709 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04709 test_loss : 0.21433 train_metric : 0.92593 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 321 =====\n",
      " loss : 0.19042 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19042 test_loss : 0.22289 train_metric : 0.77778 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 322 =====\n",
      " loss : 0.26440 metric0 : 0.62963\n",
      "\n",
      " train_loss : 0.26440 test_loss : 0.21488 train_metric : 0.62963 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 323 =====\n",
      " loss : 0.18491 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18491 test_loss : 0.21328 train_metric : 0.77778 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 324 =====\n",
      " loss : 0.06518 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06518 test_loss : 0.21894 train_metric : 0.88889 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 325 =====\n",
      " loss : 0.22043 metric0 : 0.66667\n",
      "\n",
      " train_loss : 0.22043 test_loss : 0.20956 train_metric : 0.66667 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 326 =====\n",
      " loss : 0.19912 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19912 test_loss : 0.20521 train_metric : 0.77778 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 327 =====\n",
      " loss : 0.13192 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13192 test_loss : 0.21545 train_metric : 0.85185 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 328 =====\n",
      " loss : 0.16519 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16519 test_loss : 0.20365 train_metric : 0.77778 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 329 =====\n",
      " loss : 0.11296 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11296 test_loss : 0.20455 train_metric : 0.85185 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 330 =====\n",
      " loss : 0.18378 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18378 test_loss : 0.19472 train_metric : 0.77778 test_metric : 0.76809\n",
      "\n",
      "=====Epoch : 331 =====\n",
      " loss : 0.13311 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13311 test_loss : 0.19653 train_metric : 0.85185 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 332 =====\n",
      " loss : 0.22811 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.22811 test_loss : 0.19746 train_metric : 0.74074 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 333 =====\n",
      " loss : 0.12747 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12747 test_loss : 0.19608 train_metric : 0.85185 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 334 =====\n",
      " loss : 0.23671 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.23671 test_loss : 0.19502 train_metric : 0.74074 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 335 =====\n",
      " loss : 0.08968 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08968 test_loss : 0.20629 train_metric : 0.88889 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 336 =====\n",
      " loss : 0.12610 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12610 test_loss : 0.20307 train_metric : 0.88889 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 337 =====\n",
      " loss : 0.17852 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17852 test_loss : 0.20186 train_metric : 0.77778 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 338 =====\n",
      " loss : 0.07881 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07881 test_loss : 0.21187 train_metric : 0.92593 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 339 =====\n",
      " loss : 0.12236 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12236 test_loss : 0.20597 train_metric : 0.85185 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 340 =====\n",
      " loss : 0.10752 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.10752 test_loss : 0.19874 train_metric : 0.81481 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 341 =====\n",
      " loss : 0.14031 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14031 test_loss : 0.22341 train_metric : 0.85185 test_metric : 0.71382\n",
      "\n",
      "=====Epoch : 342 =====\n",
      " loss : 0.21106 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.21106 test_loss : 0.20532 train_metric : 0.74074 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 343 =====\n",
      " loss : 0.10283 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10283 test_loss : 0.20762 train_metric : 0.85185 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 344 =====\n",
      " loss : 0.09354 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09354 test_loss : 0.21047 train_metric : 0.88889 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 345 =====\n",
      " loss : 0.04612 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04612 test_loss : 0.21166 train_metric : 0.96296 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 346 =====\n",
      " loss : 0.13476 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13476 test_loss : 0.20608 train_metric : 0.85185 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 347 =====\n",
      " loss : 0.22930 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.22930 test_loss : 0.20315 train_metric : 0.70370 test_metric : 0.76316\n",
      "\n",
      "=====Epoch : 348 =====\n",
      " loss : 0.09030 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09030 test_loss : 0.20469 train_metric : 0.92593 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 349 =====\n",
      " loss : 0.12626 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12626 test_loss : 0.20532 train_metric : 0.85185 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 350 =====\n",
      " loss : 0.20082 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20082 test_loss : 0.19609 train_metric : 0.74074 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 351 =====\n",
      " loss : 0.16696 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16696 test_loss : 0.20715 train_metric : 0.77778 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 352 =====\n",
      " loss : 0.19306 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.19306 test_loss : 0.21908 train_metric : 0.70370 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 353 =====\n",
      " loss : 0.16310 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16310 test_loss : 0.20258 train_metric : 0.77778 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 354 =====\n",
      " loss : 0.09461 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.09461 test_loss : 0.20816 train_metric : 0.92593 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 355 =====\n",
      " loss : 0.21081 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.21081 test_loss : 0.21778 train_metric : 0.74074 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 356 =====\n",
      " loss : 0.19190 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.19190 test_loss : 0.20749 train_metric : 0.77778 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 357 =====\n",
      " loss : 0.07722 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07722 test_loss : 0.19975 train_metric : 0.88889 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 358 =====\n",
      " loss : 0.07936 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07936 test_loss : 0.21153 train_metric : 0.92593 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 359 =====\n",
      " loss : 0.13909 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13909 test_loss : 0.20389 train_metric : 0.81481 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 360 =====\n",
      " loss : 0.10469 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10469 test_loss : 0.20326 train_metric : 0.85185 test_metric : 0.76645\n",
      "\n",
      "=====Epoch : 361 =====\n",
      " loss : 0.15072 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15072 test_loss : 0.19858 train_metric : 0.81481 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 362 =====\n",
      " loss : 0.15251 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15251 test_loss : 0.20444 train_metric : 0.81481 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 363 =====\n",
      " loss : 0.13984 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13984 test_loss : 0.20810 train_metric : 0.81481 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 364 =====\n",
      " loss : 0.15821 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15821 test_loss : 0.21122 train_metric : 0.81481 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 365 =====\n",
      " loss : 0.09951 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.09951 test_loss : 0.20816 train_metric : 0.85185 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 366 =====\n",
      " loss : 0.18942 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.18942 test_loss : 0.21474 train_metric : 0.77778 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 367 =====\n",
      " loss : 0.06715 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06715 test_loss : 0.20923 train_metric : 0.96296 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 368 =====\n",
      " loss : 0.13100 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.13100 test_loss : 0.20722 train_metric : 0.77778 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 369 =====\n",
      " loss : 0.07211 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07211 test_loss : 0.21991 train_metric : 0.92593 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 370 =====\n",
      " loss : 0.11703 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11703 test_loss : 0.21495 train_metric : 0.81481 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 371 =====\n",
      " loss : 0.09046 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09046 test_loss : 0.20853 train_metric : 0.88889 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 372 =====\n",
      " loss : 0.11637 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11637 test_loss : 0.20715 train_metric : 0.85185 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 373 =====\n",
      " loss : 0.05826 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.05826 test_loss : 0.19769 train_metric : 0.88889 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 374 =====\n",
      " loss : 0.20692 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20692 test_loss : 0.21257 train_metric : 0.74074 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 375 =====\n",
      " loss : 0.07401 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.07401 test_loss : 0.19623 train_metric : 0.85185 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 376 =====\n",
      " loss : 0.01396 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.01396 test_loss : 0.20201 train_metric : 1.00000 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 377 =====\n",
      " loss : 0.03552 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03552 test_loss : 0.20122 train_metric : 0.96296 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 378 =====\n",
      " loss : 0.17063 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17063 test_loss : 0.20607 train_metric : 0.77778 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 379 =====\n",
      " loss : 0.12746 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.12746 test_loss : 0.20671 train_metric : 0.77778 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 380 =====\n",
      " loss : 0.13559 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13559 test_loss : 0.19993 train_metric : 0.85185 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 381 =====\n",
      " loss : 0.10111 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10111 test_loss : 0.19449 train_metric : 0.88889 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 382 =====\n",
      " loss : 0.21340 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.21340 test_loss : 0.19394 train_metric : 0.74074 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 383 =====\n",
      " loss : 0.03630 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03630 test_loss : 0.21289 train_metric : 0.96296 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 384 =====\n",
      " loss : 0.06990 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.06990 test_loss : 0.19205 train_metric : 0.96296 test_metric : 0.76480\n",
      "\n",
      "=====Epoch : 385 =====\n",
      " loss : 0.08986 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08986 test_loss : 0.19632 train_metric : 0.88889 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 386 =====\n",
      " loss : 0.11178 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11178 test_loss : 0.20751 train_metric : 0.85185 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 387 =====\n",
      " loss : 0.08907 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08907 test_loss : 0.22335 train_metric : 0.88889 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 388 =====\n",
      " loss : 0.20197 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.20197 test_loss : 0.19904 train_metric : 0.77778 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 389 =====\n",
      " loss : 0.11431 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11431 test_loss : 0.20543 train_metric : 0.88889 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 390 =====\n",
      " loss : 0.03519 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.03519 test_loss : 0.19342 train_metric : 1.00000 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 391 =====\n",
      " loss : 0.15457 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.15457 test_loss : 0.19326 train_metric : 0.77778 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 392 =====\n",
      " loss : 0.07613 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07613 test_loss : 0.18849 train_metric : 0.88889 test_metric : 0.77632\n",
      "\n",
      "=====Epoch : 393 =====\n",
      " loss : 0.09909 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09909 test_loss : 0.21216 train_metric : 0.88889 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 394 =====\n",
      " loss : 0.15293 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15293 test_loss : 0.20445 train_metric : 0.81481 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 395 =====\n",
      " loss : 0.11396 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11396 test_loss : 0.20251 train_metric : 0.85185 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 396 =====\n",
      " loss : 0.03434 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03434 test_loss : 0.20274 train_metric : 0.96296 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 397 =====\n",
      " loss : 0.10948 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10948 test_loss : 0.22044 train_metric : 0.85185 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 398 =====\n",
      " loss : 0.11663 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11663 test_loss : 0.20046 train_metric : 0.85185 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 399 =====\n",
      " loss : 0.21133 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.21133 test_loss : 0.20565 train_metric : 0.77778 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 400 =====\n",
      " loss : 0.18032 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18032 test_loss : 0.21442 train_metric : 0.74074 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 401 =====\n",
      " loss : 0.10623 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10623 test_loss : 0.21209 train_metric : 0.88889 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 402 =====\n",
      " loss : 0.11453 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11453 test_loss : 0.21054 train_metric : 0.88889 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 403 =====\n",
      " loss : 0.14521 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14521 test_loss : 0.20921 train_metric : 0.81481 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 404 =====\n",
      " loss : 0.08503 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08503 test_loss : 0.20333 train_metric : 0.88889 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 405 =====\n",
      " loss : 0.07669 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07669 test_loss : 0.19538 train_metric : 0.92593 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 406 =====\n",
      " loss : 0.13346 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13346 test_loss : 0.21174 train_metric : 0.85185 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 407 =====\n",
      " loss : 0.15081 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15081 test_loss : 0.19402 train_metric : 0.85185 test_metric : 0.75987\n",
      "\n",
      "=====Epoch : 408 =====\n",
      " loss : 0.06944 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.06944 test_loss : 0.20154 train_metric : 0.88889 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 409 =====\n",
      " loss : 0.14284 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.14284 test_loss : 0.18888 train_metric : 0.77778 test_metric : 0.77138\n",
      "\n",
      "=====Epoch : 410 =====\n",
      " loss : 0.13994 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13994 test_loss : 0.19565 train_metric : 0.81481 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 411 =====\n",
      " loss : 0.10767 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10767 test_loss : 0.19406 train_metric : 0.88889 test_metric : 0.76974\n",
      "\n",
      "=====Epoch : 412 =====\n",
      " loss : 0.12226 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.12226 test_loss : 0.19219 train_metric : 0.88889 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 413 =====\n",
      " loss : 0.17800 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.17800 test_loss : 0.20391 train_metric : 0.81481 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 414 =====\n",
      " loss : 0.15567 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15567 test_loss : 0.19409 train_metric : 0.81481 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 415 =====\n",
      " loss : 0.13768 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13768 test_loss : 0.19965 train_metric : 0.85185 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 416 =====\n",
      " loss : 0.16550 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16550 test_loss : 0.22192 train_metric : 0.81481 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 417 =====\n",
      " loss : 0.10104 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.10104 test_loss : 0.20465 train_metric : 0.92593 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 418 =====\n",
      " loss : 0.12928 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12928 test_loss : 0.19284 train_metric : 0.85185 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 419 =====\n",
      " loss : 0.12256 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12256 test_loss : 0.20466 train_metric : 0.81481 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 420 =====\n",
      " loss : 0.09220 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09220 test_loss : 0.19891 train_metric : 0.88889 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 421 =====\n",
      " loss : 0.16097 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.16097 test_loss : 0.19615 train_metric : 0.81481 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 422 =====\n",
      " loss : 0.11684 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.11684 test_loss : 0.19312 train_metric : 0.85185 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 423 =====\n",
      " loss : 0.08143 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08143 test_loss : 0.19700 train_metric : 0.92593 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 424 =====\n",
      " loss : 0.12941 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12941 test_loss : 0.21652 train_metric : 0.81481 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 425 =====\n",
      " loss : 0.10807 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10807 test_loss : 0.22033 train_metric : 0.85185 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 426 =====\n",
      " loss : 0.12203 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.12203 test_loss : 0.21633 train_metric : 0.81481 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 427 =====\n",
      " loss : 0.03936 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03936 test_loss : 0.21468 train_metric : 0.96296 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 428 =====\n",
      " loss : 0.11737 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11737 test_loss : 0.20048 train_metric : 0.88889 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 429 =====\n",
      " loss : 0.17159 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.17159 test_loss : 0.22864 train_metric : 0.77778 test_metric : 0.74013\n",
      "\n",
      "=====Epoch : 430 =====\n",
      " loss : 0.06884 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06884 test_loss : 0.21367 train_metric : 0.92593 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 431 =====\n",
      " loss : 0.10129 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10129 test_loss : 0.20916 train_metric : 0.85185 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 432 =====\n",
      " loss : 0.10720 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10720 test_loss : 0.20973 train_metric : 0.88889 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 433 =====\n",
      " loss : 0.05751 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05751 test_loss : 0.21918 train_metric : 0.96296 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 434 =====\n",
      " loss : 0.15562 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15562 test_loss : 0.20798 train_metric : 0.81481 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 435 =====\n",
      " loss : 0.12383 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12383 test_loss : 0.20040 train_metric : 0.85185 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 436 =====\n",
      " loss : 0.20482 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.20482 test_loss : 0.20311 train_metric : 0.70370 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 437 =====\n",
      " loss : 0.15351 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.15351 test_loss : 0.19878 train_metric : 0.85185 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 438 =====\n",
      " loss : 0.12365 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12365 test_loss : 0.20189 train_metric : 0.85185 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 439 =====\n",
      " loss : 0.10255 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10255 test_loss : 0.22055 train_metric : 0.88889 test_metric : 0.72368\n",
      "\n",
      "=====Epoch : 440 =====\n",
      " loss : 0.11512 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.11512 test_loss : 0.20340 train_metric : 0.81481 test_metric : 0.75822\n",
      "\n",
      "=====Epoch : 441 =====\n",
      " loss : 0.27101 metric0 : 0.55556\n",
      "\n",
      " train_loss : 0.27101 test_loss : 0.20505 train_metric : 0.55556 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 442 =====\n",
      " loss : 0.05148 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05148 test_loss : 0.20771 train_metric : 0.96296 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 443 =====\n",
      " loss : 0.04991 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.04991 test_loss : 0.20290 train_metric : 0.92593 test_metric : 0.73849\n",
      "\n",
      "=====Epoch : 444 =====\n",
      " loss : 0.10128 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.10128 test_loss : 0.20452 train_metric : 0.92593 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 445 =====\n",
      " loss : 0.08560 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08560 test_loss : 0.20687 train_metric : 0.88889 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 446 =====\n",
      " loss : 0.08507 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08507 test_loss : 0.21201 train_metric : 0.92593 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 447 =====\n",
      " loss : 0.20272 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.20272 test_loss : 0.21731 train_metric : 0.70370 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 448 =====\n",
      " loss : 0.14260 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14260 test_loss : 0.20043 train_metric : 0.85185 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 449 =====\n",
      " loss : 0.25159 metric0 : 0.62963\n",
      "\n",
      " train_loss : 0.25159 test_loss : 0.20866 train_metric : 0.62963 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 450 =====\n",
      " loss : 0.13915 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13915 test_loss : 0.21378 train_metric : 0.81481 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 451 =====\n",
      " loss : 0.08133 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08133 test_loss : 0.20904 train_metric : 0.88889 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 452 =====\n",
      " loss : 0.19538 metric0 : 0.70370\n",
      "\n",
      " train_loss : 0.19538 test_loss : 0.23340 train_metric : 0.70370 test_metric : 0.71053\n",
      "\n",
      "=====Epoch : 453 =====\n",
      " loss : 0.13587 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13587 test_loss : 0.21154 train_metric : 0.85185 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 454 =====\n",
      " loss : 0.18682 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.18682 test_loss : 0.20638 train_metric : 0.74074 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 455 =====\n",
      " loss : 0.12692 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12692 test_loss : 0.20288 train_metric : 0.85185 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 456 =====\n",
      " loss : 0.03543 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03543 test_loss : 0.21099 train_metric : 0.96296 test_metric : 0.72697\n",
      "\n",
      "=====Epoch : 457 =====\n",
      " loss : 0.04033 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04033 test_loss : 0.21499 train_metric : 0.96296 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 458 =====\n",
      " loss : 0.10459 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10459 test_loss : 0.20728 train_metric : 0.88889 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 459 =====\n",
      " loss : 0.16509 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.16509 test_loss : 0.20909 train_metric : 0.77778 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 460 =====\n",
      " loss : 0.12011 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12011 test_loss : 0.21687 train_metric : 0.85185 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 461 =====\n",
      " loss : 0.16792 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.16792 test_loss : 0.21617 train_metric : 0.85185 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 462 =====\n",
      " loss : 0.12240 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12240 test_loss : 0.20274 train_metric : 0.85185 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 463 =====\n",
      " loss : 0.06835 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.06835 test_loss : 0.20336 train_metric : 0.92593 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 464 =====\n",
      " loss : 0.11890 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11890 test_loss : 0.22024 train_metric : 0.88889 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 465 =====\n",
      " loss : 0.09294 metric0 : 0.77778\n",
      "\n",
      " train_loss : 0.09294 test_loss : 0.21185 train_metric : 0.77778 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 466 =====\n",
      " loss : 0.07614 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07614 test_loss : 0.21295 train_metric : 0.88889 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 467 =====\n",
      " loss : 0.12187 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12187 test_loss : 0.21127 train_metric : 0.85185 test_metric : 0.73026\n",
      "\n",
      "=====Epoch : 468 =====\n",
      " loss : 0.15953 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.15953 test_loss : 0.21070 train_metric : 0.74074 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 469 =====\n",
      " loss : 0.05427 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.05427 test_loss : 0.21041 train_metric : 0.96296 test_metric : 0.73355\n",
      "\n",
      "=====Epoch : 470 =====\n",
      " loss : 0.08086 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08086 test_loss : 0.20580 train_metric : 0.88889 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 471 =====\n",
      " loss : 0.15894 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15894 test_loss : 0.21271 train_metric : 0.81481 test_metric : 0.72862\n",
      "\n",
      "=====Epoch : 472 =====\n",
      " loss : 0.07341 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07341 test_loss : 0.20366 train_metric : 0.92593 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 473 =====\n",
      " loss : 0.17605 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.17605 test_loss : 0.19591 train_metric : 0.74074 test_metric : 0.76151\n",
      "\n",
      "=====Epoch : 474 =====\n",
      " loss : 0.08641 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.08641 test_loss : 0.21330 train_metric : 0.92593 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 475 =====\n",
      " loss : 0.10089 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.10089 test_loss : 0.21349 train_metric : 0.85185 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 476 =====\n",
      " loss : 0.05370 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.05370 test_loss : 0.20663 train_metric : 0.92593 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 477 =====\n",
      " loss : 0.07530 metric0 : 0.92593\n",
      "\n",
      " train_loss : 0.07530 test_loss : 0.20972 train_metric : 0.92593 test_metric : 0.74342\n",
      "\n",
      "=====Epoch : 478 =====\n",
      " loss : 0.14220 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14220 test_loss : 0.20558 train_metric : 0.81481 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 479 =====\n",
      " loss : 0.07469 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.07469 test_loss : 0.21926 train_metric : 0.88889 test_metric : 0.73520\n",
      "\n",
      "=====Epoch : 480 =====\n",
      " loss : 0.03143 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03143 test_loss : 0.20546 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 481 =====\n",
      " loss : 0.02093 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.02093 test_loss : 0.20816 train_metric : 0.96296 test_metric : 0.75658\n",
      "\n",
      "=====Epoch : 482 =====\n",
      " loss : 0.10018 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10018 test_loss : 0.21091 train_metric : 0.88889 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 483 =====\n",
      " loss : 0.09564 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09564 test_loss : 0.20486 train_metric : 0.88889 test_metric : 0.73684\n",
      "\n",
      "=====Epoch : 484 =====\n",
      " loss : 0.13364 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13364 test_loss : 0.20572 train_metric : 0.85185 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 485 =====\n",
      " loss : 0.14915 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14915 test_loss : 0.21348 train_metric : 0.81481 test_metric : 0.74507\n",
      "\n",
      "=====Epoch : 486 =====\n",
      " loss : 0.14242 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.14242 test_loss : 0.19349 train_metric : 0.81481 test_metric : 0.75000\n",
      "\n",
      "=====Epoch : 487 =====\n",
      " loss : 0.03138 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.03138 test_loss : 0.19294 train_metric : 0.96296 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 488 =====\n",
      " loss : 0.04061 metric0 : 0.96296\n",
      "\n",
      " train_loss : 0.04061 test_loss : 0.20148 train_metric : 0.96296 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 489 =====\n",
      " loss : 0.02280 metric0 : 1.00000\n",
      "\n",
      " train_loss : 0.02280 test_loss : 0.19472 train_metric : 1.00000 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 490 =====\n",
      " loss : 0.20507 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.20507 test_loss : 0.20442 train_metric : 0.74074 test_metric : 0.75164\n",
      "\n",
      "=====Epoch : 491 =====\n",
      " loss : 0.13008 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.13008 test_loss : 0.20452 train_metric : 0.81481 test_metric : 0.75329\n",
      "\n",
      "=====Epoch : 492 =====\n",
      " loss : 0.15110 metric0 : 0.81481\n",
      "\n",
      " train_loss : 0.15110 test_loss : 0.20638 train_metric : 0.81481 test_metric : 0.74178\n",
      "\n",
      "=====Epoch : 493 =====\n",
      " loss : 0.17381 metric0 : 0.74074\n",
      "\n",
      " train_loss : 0.17381 test_loss : 0.20508 train_metric : 0.74074 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 494 =====\n",
      " loss : 0.13889 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.13889 test_loss : 0.20923 train_metric : 0.85185 test_metric : 0.72533\n",
      "\n",
      "=====Epoch : 495 =====\n",
      " loss : 0.11333 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.11333 test_loss : 0.20528 train_metric : 0.88889 test_metric : 0.74671\n",
      "\n",
      "=====Epoch : 496 =====\n",
      " loss : 0.14706 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.14706 test_loss : 0.22848 train_metric : 0.85185 test_metric : 0.73191\n",
      "\n",
      "=====Epoch : 497 =====\n",
      " loss : 0.10920 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.10920 test_loss : 0.20266 train_metric : 0.88889 test_metric : 0.75493\n",
      "\n",
      "=====Epoch : 498 =====\n",
      " loss : 0.09489 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.09489 test_loss : 0.18677 train_metric : 0.88889 test_metric : 0.77467\n",
      "\n",
      "=====Epoch : 499 =====\n",
      " loss : 0.08723 metric0 : 0.88889\n",
      "\n",
      " train_loss : 0.08723 test_loss : 0.20832 train_metric : 0.88889 test_metric : 0.74836\n",
      "\n",
      "=====Epoch : 500 =====\n",
      " loss : 0.12930 metric0 : 0.85185\n",
      "\n",
      " train_loss : 0.12930 test_loss : 0.20989 train_metric : 0.85185 test_metric : 0.74013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnnqe = NQE(n_feature=4, mode='RNN', rnn_sequence=5)\n",
    "rnnqe_train = NQE_Train(rnnqe, criterion, rnn_train_loader, rnn_test_loader, [accuarcy])\n",
    "trained_rnnqe = rnnqe_train.train(500, seq_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_rnnqe.state_dict(), \"./models/pca_RNNQE_loss209.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
